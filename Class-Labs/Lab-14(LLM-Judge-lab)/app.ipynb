{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0516c151",
   "metadata": {},
   "source": [
    "# LLM-as-a-Judge Simply Explained: A Complete Guide to Run LLM Evals\n",
    "\n",
    "Recently, the concept of “LLM as a Judge” has been gaining significant traction in the AI and NLP communities. As someone deeply involved in the field of LLM evaluation, I’ve seen firsthand how LLM judges are rapidly becoming the preferred method for evaluating language models. The reasons are clear: compared to traditional human evaluators, LLM judges offer faster, more scalable, and cost-effective assessments—eliminating much of the slow, expensive, and labor-intensive work that comes with manual review.\n",
    "\n",
    "However, it’s important to recognize that LLM judges are not without their own challenges and limitations. Blindly relying on them can lead to misleading results and unnecessary frustration. That’s why, in this guide, I’ll share everything I’ve learned about leveraging LLM judges for system evaluation, including:\n",
    "\n",
    "- The core principles behind LLM-as-a-Judge\n",
    "- The practical benefits and pitfalls of automated evaluation\n",
    "- Step-by-step instructions for setting up and running LLM-based evals \n",
    "\n",
    "---\n",
    "\n",
    "## What exactly is “LLM as a Judge”?\n",
    "\n",
    "“LLM-as-a-Judge” refers to the process of using Large Language Models (LLMs) to evaluate the outputs of other LLM systems. Instead of relying on human evaluators—which can be slow, expensive, and inconsistent—this approach leverages the reasoning and language understanding capabilities of LLMs to provide automated, scalable assessments.\n",
    "\n",
    "The process typically works as follows:\n",
    "1. **Define Evaluation Criteria:** You start by crafting an evaluation prompt that clearly specifies the criteria you want to assess (such as accuracy, relevance, faithfulness, bias, or any custom metric).\n",
    "2. **Present Inputs and Outputs:** The LLM judge is given the original input (e.g., a question or task) and the output generated by the LLM system under evaluation.\n",
    "3. **Automated Scoring:** The LLM judge reviews the information and assigns a score or rating based on the defined criteria.\n",
    "\n",
    "LLM judges are commonly used to power advanced evaluation metrics like G-Eval, answer relevancy, faithfulness, and bias detection. By automating the evaluation process, LLM-as-a-Judge enables faster, more consistent, and more scalable assessments—making it an increasingly popular choice for both research and production environments.\n",
    "\n",
    "---\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Before you get started, please make sure you have the following ready:\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Sample Contract File for Testing\n",
    "\n",
    "To try out the contract analysis workflow, download the sample contract file provided below:\n",
    "\n",
    "- [Download Sample Contract (Google Drive)](https://drive.google.com/file/d/11dCpPvkt1MJqaiFoNQ67ujZ3qdSMmIGw/view?usp=sharing)\n",
    "\n",
    "### 2. OpenAI API Key\n",
    "\n",
    "You’ll need your own OpenAI API key to access the language models used for contract evaluation. If you don’t have one yet, follow this step-by-step guide to generate your API key:\n",
    "\n",
    "- [How to get your own OpenAI API key (Medium article)](https://medium.com/@lorenzozar/how-to-get-your-own-openai-api-key-f4d44e60c327)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61733e35",
   "metadata": {},
   "source": [
    "# Step 1: Install the Dependencies\n",
    "\n",
    "Run the following command in your terminal or Jupyter notebook to install all required packages:\n",
    "\n",
    "```python\n",
    "!pip install gradio langchain openai python-docx PyPDF2 pandas\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "| Package       | Purpose / Use in Project                                                                 |\n",
    "|---------------|-----------------------------------------------------------------------------------------|\n",
    "| **gradio**    | Build interactive web UIs for machine learning and data apps. Lets users upload files, view results, and interact with your tool in a browser. |\n",
    "| **langchain** | Framework for building applications powered by large language models (LLMs). Helps with document loading, processing, and LLM integration.      |\n",
    "| **openai**    | Official Python client for OpenAI’s API. Allows your code to send prompts and receive responses from models like GPT-4.                         |\n",
    "| **python-docx** | Read, write, and extract text from Microsoft Word (.docx) files. Used to process contract documents in Word format.                        |\n",
    "| **PyPDF2**    | Read and extract text from PDF files. Enables your tool to analyze contracts provided as PDFs.                                                  |\n",
    "| **pandas**    | Powerful data analysis and manipulation library. Used to organize, process, and display results in tables (dataframes).                        |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78af67c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: gradio in c:\\users\\sachi\\appdata\\roaming\\python\\python313\\site-packages (5.36.2)\n",
      "Requirement already satisfied: langchain in c:\\users\\sachi\\appdata\\roaming\\python\\python313\\site-packages (0.3.25)\n",
      "Requirement already satisfied: openai in c:\\users\\sachi\\appdata\\roaming\\python\\python313\\site-packages (1.95.1)\n",
      "Requirement already satisfied: python-docx in c:\\users\\sachi\\appdata\\roaming\\python\\python313\\site-packages (1.2.0)\n",
      "Requirement already satisfied: PyPDF2 in c:\\users\\sachi\\appdata\\roaming\\python\\python313\\site-packages (3.0.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\sachi\\appdata\\roaming\\python\\python313\\site-packages (2.3.1)\n",
      "Requirement already satisfied: aiofiles<25.0,>=22.0 in c:\\users\\sachi\\appdata\\roaming\\python\\python313\\site-packages (from gradio) (24.1.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\sachi\\appdata\\roaming\\python\\python313\\site-packages (from gradio) (4.9.0)\n",
      "Requirement already satisfied: audioop-lts<1.0 in c:\\users\\sachi\\appdata\\roaming\\python\\python313\\site-packages (from gradio) (0.2.1)\n",
      "Requirement already satisfied: brotli>=1.1.0 in c:\\users\\sachi\\appdata\\roaming\\python\\python313\\site-packages (from gradio) (1.1.0)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in c:\\users\\sachi\\appdata\\roaming\\python\\python313\\site-packages (from gradio) (0.116.1)\n",
      "Requirement already satisfied: ffmpy in c:\\users\\sachi\\appdata\\roaming\\python\\python313\\site-packages (from gradio) (0.6.0)\n",
      "Requirement already satisfied: gradio-client==1.10.4 in c:\\users\\sachi\\appdata\\roaming\\python\\python313\\site-packages (from gradio) (1.10.4)\n",
      "Requirement already satisfied: groovy~=0.1 in c:\\users\\sachi\\appdata\\roaming\\python\\python313\\site-packages (from gradio) (0.1.2)\n",
      "Requirement already satisfied: httpx<1.0,>=0.24.1 in c:\\users\\sachi\\appdata\\roaming\\python\\python313\\site-packages (from gradio) (0.28.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.28.1 in c:\\users\\sachi\\appdata\\roaming\\python\\python313\\site-packages (from gradio) (0.33.4)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\users\\sachi\\appdata\\roaming\\python\\python313\\site-packages (from gradio) (3.1.6)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in c:\\users\\sachi\\appdata\\roaming\\python\\python313\\site-packages (from gradio) (3.0.2)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in c:\\users\\sachi\\appdata\\roaming\\python\\python313\\site-packages (from gradio) (2.3.1)\n",
      "Requirement already satisfied: orjson~=3.0 in c:\\users\\sachi\\appdata\\roaming\\python\\python313\\site-packages (from gradio) (3.10.16)\n",
      "Requirement already satisfied: packaging in c:\\users\\sachi\\appdata\\roaming\\python\\python313\\site-packages (from gradio) (24.2)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in c:\\users\\sachi\\appdata\\roaming\\python\\python313\\site-packages (from gradio) (11.0.0)\n",
      "Requirement already satisfied: pydantic<2.12,>=2.0 in c:\\users\\sachi\\appdata\\roaming\\python\\python313\\site-packages (from gradio) (2.11.7)\n",
      "Requirement already satisfied: pydub in c:\\users\\sachi\\appdata\\roaming\\python\\python313\\site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in c:\\users\\sachi\\appdata\\roaming\\python\\python313\\site-packages (from gradio) (0.0.20)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\users\\sachi\\appdata\\roaming\\python\\python313\\site-packages (from gradio) (6.0.2)\n",
      "Requirement already satisfied: ruff>=0.9.3 in c:\\users\\sachi\\appdata\\roaming\\python\\python313\\site-packages (from gradio) (0.11.5)\n",
      "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in c:\\users\\sachi\\appdata\\roaming\\python\\python313\\site-packages (from gradio) (0.1.6)\n",
      "Requirement already satisfied: semantic-version~=2.0 in c:\\users\\sachi\\appdata\\roaming\\python\\python313\\site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in c:\\users\\sachi\\appdata\\roaming\\python\\python313\\site-packages (from gradio) (0.46.2)\n",
      "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in c:\\users\\sachi\\appdata\\roaming\\python\\python313\\site-packages (from gradio) (0.13.3)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in c:\\users\\sachi\\appdata\\roaming\\python\\python313\\site-packages (from gradio) (0.15.2)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\sachi\\appdata\\roaming\\python\\python313\\site-packages (from gradio) (4.13.2)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in c:\\users\\sachi\\appdata\\roaming\\python\\python313\\site-packages (from gradio) (0.35.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\sachi\\appdata\\roaming\\python\\python313\\site-packages (from gradio-client==1.10.4->gradio) (2025.5.1)\n",
      "Requirement already satisfied: websockets<16.0,>=10.0 in c:\\users\\sachi\\appdata\\roaming\\python\\python313\\site-packages (from gradio-client==1.10.4->gradio) (15.0.1)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in c:\\users\\sachi\\appdata\\roaming\\python\\python313\\site-packages (from langchain) (0.3.60)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in c:\\users\\sachi\\appdata\\roaming\\python\\python313\\site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in c:\\users\\sachi\\appdata\\roaming\\python\\python313\\site-packages (from langchain) (0.3.30)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\sachi\\appdata\\roaming\\python\\python313\\site-packages (from langchain) (2.0.40)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\sachi\\appdata\\roaming\\python\\python313\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\sachi\\appdata\\roaming\\python\\python313\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\sachi\\appdata\\roaming\\python\\python313\\site-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\sachi\\appdata\\roaming\\python\\python313\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\sachi\\appdata\\roaming\\python\\python313\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: lxml>=3.1.0 in c:\\users\\sachi\\appdata\\roaming\\python\\python313\\site-packages (from python-docx) (6.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\sachi\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sachi\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\sachi\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\sachi\\appdata\\roaming\\python\\python313\\site-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\sachi\\appdata\\roaming\\python\\python313\\site-packages (from httpx<1.0,>=0.24.1->gradio) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\sachi\\appdata\\roaming\\python\\python313\\site-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\sachi\\appdata\\roaming\\python\\python313\\site-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\sachi\\appdata\\roaming\\python\\python313\\site-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\sachi\\appdata\\roaming\\python\\python313\\site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\sachi\\appdata\\roaming\\python\\python313\\site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (1.33)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\sachi\\appdata\\roaming\\python\\python313\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\sachi\\appdata\\roaming\\python\\python313\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\sachi\\appdata\\roaming\\python\\python313\\site-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\sachi\\appdata\\roaming\\python\\python313\\site-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\sachi\\appdata\\roaming\\python\\python313\\site-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sachi\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sachi\\appdata\\roaming\\python\\python313\\site-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sachi\\appdata\\roaming\\python\\python313\\site-packages (from requests<3,>=2->langchain) (2.4.0)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\sachi\\appdata\\roaming\\python\\python313\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\sachi\\appdata\\roaming\\python\\python313\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\sachi\\appdata\\roaming\\python\\python313\\site-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\sachi\\appdata\\roaming\\python\\python313\\site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\sachi\\appdata\\roaming\\python\\python313\\site-packages (from typer<1.0,>=0.12->gradio) (14.0.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\sachi\\appdata\\roaming\\python\\python313\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain) (3.0.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\sachi\\appdata\\roaming\\python\\python313\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\sachi\\appdata\\roaming\\python\\python313\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\sachi\\appdata\\roaming\\python\\python313\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: C:\\Python313\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Install necessary packages\n",
    "! pip install gradio langchain openai python-docx PyPDF2 pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ca2b6a",
   "metadata": {},
   "source": [
    "## After Installing Dependencies: Let's Start Importing!\n",
    "\n",
    "Now that you’ve installed all the necessary libraries, let’s import them into your Python script or notebook. Here’s a summary of each import and its purpose:\n",
    "\n",
    "| Import Statement                                                                 | Purpose / Usage                                                                                                 |\n",
    "|----------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------|\n",
    "| `import gradio as gr`                                                            | Imports Gradio for building interactive web interfaces for your app.                                            |\n",
    "| `from langchain.document_loaders import PyPDFLoader, Docx2txtLoader, TextLoader` | Imports document loaders from LangChain to extract text from PDF, DOCX, and TXT files.                         |\n",
    "| `from openai import OpenAI`                                                      | Imports the OpenAI client to interact with language models like GPT-4 for contract analysis.                    |\n",
    "| `import pandas as pd`                                                            | Imports Pandas for organizing, processing, and displaying results in tables (dataframes).                      |\n",
    "| `import os`                                                                     | Imports Python’s built-in OS module for handling file paths and interacting with the operating system.          |\n",
    "| `import tempfile`                                                               | Imports the tempfile module to safely create and manage temporary files and directories during file processing. |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3da24358",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from langchain.document_loaders import PyPDFLoader, Docx2txtLoader, TextLoader\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import os\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252947bb",
   "metadata": {},
   "source": [
    "## Key Terms and Evaluation Metrics\n",
    "\n",
    "In this section ,  we focus on extracting specific key terms from contract documents and then evaluating the quality of those extractions using a set of well-defined metrics. Here’s a clear overview:\n",
    "\n",
    "---\n",
    "\n",
    "### Key Terms\n",
    "\n",
    "These are the important contract clauses or topics that the tool will automatically search for and extract from uploaded documents:\n",
    "\n",
    "| Key Term                     | Description (Typical Focus in Contracts)                |\n",
    "|------------------------------|--------------------------------------------------------|\n",
    "| Service Warranty             | Guarantees and conditions for services provided        |\n",
    "| Limitation of Liability      | Limits on legal responsibility for damages or losses   |\n",
    "| Governing Law                | Specifies which jurisdiction’s laws apply              |\n",
    "| Termination for Cause        | Conditions under which the contract can be ended early |\n",
    "| Payment Terms                | Details about payment amounts, schedules, and methods  |\n",
    "| Confidentiality Obligations  | Rules about keeping information private                |\n",
    "\n",
    "---\n",
    "\n",
    "### Evaluation Metrics\n",
    "\n",
    "After extracting the key terms, the tool evaluates the quality and accuracy of each extraction using the following metrics:\n",
    "\n",
    "| Evaluation Metric                                               | What It Measures                                                                 |\n",
    "|-----------------------------------------------------------------|----------------------------------------------------------------------------------|\n",
    "| Answer Accuracy                                                 | Is the extracted answer factually correct?                                       |\n",
    "| Citation Accuracy                                               | Are references (like page numbers) correct?                                      |\n",
    "| Was the information extracted as per the question asked?        | Does the answer directly address the key term?                                   |\n",
    "| Was the information complete?                                   | Is all relevant information included?                                            |\n",
    "| Was the information enough to make a conclusive decision?       | Is the answer sufficient for decision-making?                                    |\n",
    "| Were associated red flags covered in the extracted output?      | Are potential issues or risks mentioned?                                         |\n",
    "| Was all information related to the relevant clause captured?    | Is the extraction thorough for the clause?                                       |\n",
    "| Was the extracted information correctly favoring one party?     | Does the answer reflect the contract’s intent regarding parties?                 |\n",
    "| Is the AI reasoning covering all aspects of the key term?       | Is the explanation comprehensive?                                                |\n",
    "| Is the Contract display area highlighting the relevant parts?   | Are important sections visually highlighted?                                     |\n",
    "| Was the information extracted from all relevant clauses?        | Are multiple relevant sections included if needed?                               |\n",
    "| Was the page number of extracted information correct?           | Are page references accurate?                                                    |\n",
    "| Was the AI reasoning discussing the relevant clause?            | Is the explanation focused on the right part?                                    |\n",
    "| Were related provisions highlighted on clicking page numbers?   | Is navigation to related sections effective?                                     |\n",
    "| Was the information extracted from the correct part of a stitched document? | Is the answer from the right section in merged documents?            |\n",
    "| Does the information stay within document scope?                | Is the answer limited to the uploaded contract?                                  |\n",
    "| Were results free from misleading claims?                       | Are there any false or misleading statements?                                    |\n",
    "| Does the tool avoid generic/non-contract answers?               | Is the answer specific to the contract, not generic?                             |\n",
    "| Did the AI avoid illegal or insensitive justifications?         | Are explanations appropriate and lawful?                                         |\n",
    "| Did the tool prevent false claims about people/entities?        | Are there any incorrect statements about parties?                                |\n",
    "| Did the tool context hateful/profane content?                   | Is the output free from inappropriate language?                                  |\n",
    "\n",
    "---\n",
    "\n",
    "**In summary:**  \n",
    "- The **key terms** guide what information is extracted from contracts.\n",
    "- The **evaluation metrics** ensure that the extracted information is accurate, complete, relevant, and presented in a user-friendly and responsible way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9726237",
   "metadata": {},
   "outputs": [],
   "source": [
    "KEY_TERMS = [\n",
    "    \"Service Warranty\",\n",
    "    \"Limitation of Liability\",\n",
    "    \"Governing Law\",\n",
    "    \"Termination for Cause\",\n",
    "    \"Payment Terms\",\n",
    "    \"Confidentiality Obligations\"\n",
    "]\n",
    "\n",
    "EVALUATION_METRICS = [\n",
    "    \"Answer Accuracy\",\n",
    "    \"Citation Accuracy\",\n",
    "    \"Was the information extracted as per the question asked in the key term?\",\n",
    "    \"Was the information complete?\",\n",
    "    \"Was the information enough to make a conclusive decision?\",\n",
    "    \"Were associated red flags covered in the extracted output?\",\n",
    "    \"Was all information related to the relevant clause captured?\",\n",
    "    \"Was the extracted information correctly favoring one party?\",\n",
    "    \"Is the AI reasoning covering all aspects of the key term?\",\n",
    "    \"Is the Contract display area highlighting the relevant parts?\",\n",
    "    \"Was the information extracted from all relevant clauses?\",\n",
    "    \"Was the page number of extracted information correct?\",\n",
    "    \"Was the AI reasoning discussing the relevant clause?\",\n",
    "    \"Were related provisions highlighted on clicking page numbers?\",\n",
    "    \"Was the information extracted from the correct part of a stitched document?\",\n",
    "    \"Does the information stay within document scope?\",\n",
    "    \"Were results free from misleading claims?\",\n",
    "    \"Does the tool avoid generic/non-contract answers?\",\n",
    "    \"Did the AI avoid illegal or insensitive justifications?\",\n",
    "    \"Did the tool prevent false claims about people/entities?\",\n",
    "    \"Did the tool context hateful/profane content?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53a6a43",
   "metadata": {},
   "source": [
    "## Function: `extract_text_from_file`\n",
    "\n",
    "This function is designed to handle the extraction of text from various types of contract files. It supports PDF, Word (DOCX/DOC), and plain text (TXT) formats, making your tool flexible for different document types.\n",
    "\n",
    "---\n",
    "\n",
    "### How It Works\n",
    "\n",
    "| Step | What Happens                                                                                      | Why It’s Important                                  |\n",
    "|------|--------------------------------------------------------------------------------------------------|-----------------------------------------------------|\n",
    "| 1    | Determines the file extension using `os.path.splitext(file_path)[1].lower()`                      | Identifies the type of document being processed     |\n",
    "| 2    | Selects the appropriate loader:                                                                   | Ensures correct extraction method for each format   |\n",
    "|      | - `PyPDFLoader` for PDFs                                                                          |                                                     |\n",
    "|      | - `Docx2txtLoader` for Word documents (`.docx`, `.doc`)                                           |                                                     |\n",
    "|      | - `TextLoader` for plain text files (`.txt`)                                                      |                                                     |\n",
    "| 3    | Raises a `ValueError` if the file type is not supported                                           | Prevents errors from unsupported file formats       |\n",
    "| 4    | Loads the document(s) using the selected loader (`loader.load()`)                                 | Reads the content into a list of document objects   |\n",
    "| 5    | Combines the text from all pages/sections into a single string using `\"\\n\".join([...])`           | Provides a unified text block for further analysis  |\n",
    "| 6    | Returns both the combined text and the list of document objects (`docs`)                          | The text is used for analysis; `docs` can provide page numbers or metadata if needed |\n",
    "\n",
    "---\n",
    "\n",
    "### Example Usage\n",
    "\n",
    "Suppose you have a contract file called `contract.pdf`:\n",
    "\n",
    "```python\n",
    "text, docs = extract_text_from_file(\"contract.pdf\")\n",
    "print(text)  # Prints the full extracted text\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**In summary:**  \n",
    "This function is a robust utility for extracting and preparing contract text from various file formats, setting the stage for further analysis and evaluation in your workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7afea5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_file(file_path):\n",
    "    ext = os.path.splitext(file_path)[1].lower()\n",
    "    if ext == \".pdf\":\n",
    "        loader = PyPDFLoader(file_path)\n",
    "    elif ext in [\".docx\", \".doc\"]:\n",
    "        loader = Docx2txtLoader(file_path)\n",
    "    elif ext in [\".txt\"]:\n",
    "        loader = TextLoader(file_path)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file type\")\n",
    "    docs = loader.load()\n",
    "    # Combine all pages/sections\n",
    "    text = \"\\n\".join([doc.page_content for doc in docs])\n",
    "    return text, docs  # docs for page numbers if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63eb97e5",
   "metadata": {},
   "source": [
    "## Setting Up the OpenAI Client\n",
    "\n",
    "To interact with OpenAI’s language models (such as GPT-4), you need to create a client object using your own API key. This allows your application to send prompts and receive responses from OpenAI’s servers.\n",
    "\n",
    "---\n",
    "\n",
    "### Example Code\n",
    "\n",
    "```python\n",
    "client = OpenAI(api_key='sk-...your-own-api-key-here...')\n",
    "```\n",
    "---\n",
    "\n",
    "### For a Step-by-Step Guide\n",
    "\n",
    "You can follow this detailed tutorial:  \n",
    "[How to get your own OpenAI API key (Medium article)](https://medium.com/@lorenzozar/how-to-get-your-own-openai-api-key-f4d44e60c327)\n",
    "\n",
    "---\n",
    "\n",
    "### Important Note About API Keys\n",
    "\n",
    "- **Security:** Never share your OpenAI API key publicly or commit it to version control (like GitHub). Treat it like a password.\n",
    "- **Personal Key Required:** The API key in the example above is for demonstration only. You must use your own unique API key to access OpenAI services.\n",
    "\n",
    "---\n",
    "\n",
    "**In summary:**  \n",
    "You need your own OpenAI API key to use the language models. Never share your key, and always keep it secure!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "730cfdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key='Place Yor API Key')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca46ca6",
   "metadata": {},
   "source": [
    "## Function: `extract_key_terms`\n",
    "\n",
    "### This function uses an AI language model to automatically extract specific key terms or clauses from a contract document. It is designed to work with a list of key terms (such as \"Service Warranty\" or \"Payment Terms\") and return the relevant sections of the contract for each term.\n",
    "---\n",
    "\n",
    "### How It Works\n",
    "\n",
    "| Step | What Happens                                                                                                    | Why It’s Important                                  |\n",
    "|------|----------------------------------------------------------------------------------------------------------------|-----------------------------------------------------|\n",
    "| 1    | Loops through each key term in the provided list.                                                              | Ensures all important contract clauses are checked.  |\n",
    "| 2    | For each term, constructs a prompt asking the AI to extract relevant sections from the contract text.           | Guides the AI to focus on the specific clause.       |\n",
    "| 3    | Sends the prompt to the OpenAI language model (e.g., GPT-4) for analysis.                                       | Leverages advanced AI for accurate extraction.       |\n",
    "| 4    | Receives the AI’s answer, which should include the relevant text and, if possible, page numbers.                | Provides both the content and its location.          |\n",
    "| 5    | Uses a regular expression to try to extract the page number from the AI’s answer, if mentioned.                 | Helps with citation and navigation in the document.  |\n",
    "| 6    | Stores the answer and page number for each key term in a results dictionary.                                    | Organizes results for easy access and further use.   |\n",
    "| 7    | Returns the dictionary mapping each key term to its extracted answer and page number.                           | Makes the output easy to use in later steps.         |\n",
    "\n",
    "---\n",
    "\n",
    "### Example Usage\n",
    "\n",
    "Suppose you have extracted the text from a contract and want to find the relevant sections for a list of key terms:\n",
    "\n",
    "```python\n",
    "key_terms = [\"Service Warranty\", \"Payment Terms\"]\n",
    "results = extract_key_terms(contract_text, key_terms)\n",
    "print(results[\"Service Warranty\"][\"answer\"])      # Shows the extracted section for Service Warranty\n",
    "print(results[\"Service Warranty\"][\"page_number\"]) # Shows the page number if found\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Why This Matters\n",
    "\n",
    "- **Automates tedious work:** Saves time by letting AI scan and extract key clauses from lengthy contracts.\n",
    "- **Consistent and thorough:** Ensures every key term is checked in the same way, reducing human error.\n",
    "- **Prepares for evaluation:** The extracted answers can be further evaluated for accuracy and completeness using your evaluation metrics.\n",
    "\n",
    "---\n",
    "\n",
    "**In summary:**  \n",
    "This function is a core part of your contract analysis workflow, using AI to quickly and accurately extract the most important sections from any contract document, ready for further review or evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35324c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_key_terms(text, key_terms):\n",
    "    results = {}\n",
    "    for term in key_terms:\n",
    "        prompt = (\n",
    "            f\"You are a legal document analysis assistant. \"\n",
    "            f\"Extract the section(s) of the following contract that pertain to '{term}'. \"\n",
    "            f\"Return the relevant text verbatim, and if possible, the page number(s) where it appears. \"\n",
    "            f\"If not found, say 'Not found'.\\n\\n\"\n",
    "            f\"Document:\\n{text[:4000]}...\"  # Truncate for token limit\n",
    "        )\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4-1106-preview\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a legal contract analysis assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "        answer = completion.choices[0].message.content\n",
    "        # Try to extract page number if mentioned\n",
    "        page_number = None\n",
    "        if \"page\" in answer.lower():\n",
    "            import re\n",
    "            match = re.search(r'page[s]?\\s*(\\d+)', answer, re.IGNORECASE)\n",
    "            if match:\n",
    "                page_number = match.group(1)\n",
    "        results[term] = {\"answer\": answer, \"page_number\": page_number}\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a418c07c",
   "metadata": {},
   "source": [
    "## Function: judge_key_term\n",
    "\n",
    "This function evaluates how well an extracted answer from a contract addresses a specific key term, using a set of evaluation metrics. It leverages an AI model to provide both a numerical score and a brief justification for each metric.\n",
    "\n",
    "---\n",
    "\n",
    "| Step                        | Description                                                                                                                      | Why It’s Important                                                                                 |\n",
    "|-----------------------------|----------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------|\n",
    "| **1. Iterate Over Metrics** | For each evaluation metric (e.g., \"Answer Accuracy\", \"Citation Accuracy\"), the function performs an assessment.                  | Ensures every aspect of the answer is evaluated systematically.                                    |\n",
    "| **2. Prompt Construction**  | Builds a prompt for the AI model, asking it to evaluate the extracted answer for the key term against the current metric.        | Guides the AI to focus on the specific evaluation criteria.                                        |\n",
    "|                             | If a ground truth answer is available, it is included in the prompt for comparison.                                              | Allows for more rigorous and objective evaluation.                                                 |\n",
    "| **3. AI Evaluation**        | Sends the prompt to the OpenAI language model (e.g., GPT-4) and receives a response with:                                       | Leverages advanced AI for consistent and expert-like evaluation.                                   |\n",
    "|                             | - A score from 1 (poor) to 5 (excellent)                                                                                        |                                                                                                    |\n",
    "|                             | - A brief justification (1-2 sentences) explaining the score                                                                    |                                                                                                    |\n",
    "| **4. Parse Response**       | Extracts the score and justification from the AI’s response using regular expressions.                                          | Converts the AI’s output into structured data for further use.                                     |\n",
    "| **5. Compile Results**      | For each metric, creates a result entry containing:                                                                             | Organizes evaluation data for easy analysis and display.                                           |\n",
    "|                             | - Key term name                                                                                                                 |                                                                                                    |\n",
    "|                             | - Extracted answer from the document                                                                                            |                                                                                                    |\n",
    "|                             | - Evaluation metric name                                                                                                        |                                                                                                    |\n",
    "|                             | - Score                                                                                                                         |                                                                                                    |\n",
    "|                             | - Justification                                                                                                                 |                                                                                                    |\n",
    "|                             | - (Page number is included as a placeholder and can be filled in later)                                                         |                                                                                                    |\n",
    "| **6. Return Results**       | After evaluating all metrics, returns a list of these result entries.                                                           | Provides a comprehensive evaluation report for further analysis or display.                        |\n",
    "\n",
    "---\n",
    "\n",
    "### Why This Matters\n",
    "\n",
    "| Benefit                    | Explanation                                                                                      |\n",
    "|----------------------------|--------------------------------------------------------------------------------------------------|\n",
    "| **Objective Assessment**   | Automates the evaluation process, reducing human bias and increasing consistency.                |\n",
    "| **Detailed Feedback**      | Provides both a score and a justification, helping users understand the strengths and weaknesses.|\n",
    "| **Ground Truth Comparison**| If a correct answer is known, enables direct comparison for more rigorous evaluation.            |\n",
    "\n",
    "---\n",
    "\n",
    "**In summary:**  \n",
    "This function is essential for systematically and transparently evaluating the quality of information extracted from contracts, ensuring reliable and actionable results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7abb7fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def judge_key_term(term, llm_answer, metrics, ground_truth=None):\n",
    "    results = []\n",
    "    for metric in metrics:\n",
    "        prompt = (\n",
    "            f\"You are an expert contract evaluator. \"\n",
    "            f\"Evaluate the following extracted answer for the key term '{term}' \"\n",
    "            f\"against the evaluation metric: '{metric}'.\\n\"\n",
    "            f\"Extracted Answer: {llm_answer}\\n\"\n",
    "        )\n",
    "        if ground_truth:\n",
    "            prompt += f\"Ground Truth Answer: {ground_truth}\\n\"\n",
    "        prompt += (\n",
    "            \"For this metric, provide:\\n\"\n",
    "            \"- A score from 1 (poor) to 5 (excellent)\\n\"\n",
    "            \"- A brief justification (1-2 sentences)\\n\"\n",
    "            \"Respond in the format: Score: <number>\\nJustification: <text>\"\n",
    "        )\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4-1106-preview\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a contract evaluation expert.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "        content = completion.choices[0].message.content\n",
    "        import re\n",
    "        score_match = re.search(r\"Score:\\s*(\\d+)\", content)\n",
    "        justification_match = re.search(r\"Justification:\\s*(.*)\", content, re.DOTALL)\n",
    "        score = int(score_match.group(1)) if score_match else None\n",
    "        justification = justification_match.group(1).strip() if justification_match else content\n",
    "        results.append({\n",
    "            \"key_term_name\": term,\n",
    "            \"llm_extracted_ans_from_doc\": llm_answer,\n",
    "            \"page_number\": None,  # Will fill later\n",
    "            \"evulation_metric_name\": metric,\n",
    "            \"score\": score,\n",
    "            \"justification\": justification\n",
    "        })\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebeeb4ba",
   "metadata": {},
   "source": [
    "## Function: process_documents (Version Without Ground Truth)\n",
    "\n",
    "This function manages the main workflow for analyzing a contract document, from extracting its text to evaluating key terms and preparing the results for display. In this version, ground truth comparison is not included.\n",
    "\n",
    "---\n",
    "\n",
    "| Step | Description                                                                                                   | Why It’s Important                                                      |\n",
    "|------|---------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------|\n",
    "| 1    | Extracts text and document objects from the uploaded contract file using `extract_text_from_file`.             | Converts the contract into a format suitable for further analysis.       |\n",
    "| 2    | Extracts key terms from the contract text using `extract_key_terms` and the predefined `KEY_TERMS` list.       | Identifies and isolates the most important clauses in the contract.      |\n",
    "| 3    | (Ground truth loading is commented out in this version.)                                                      | This version does not compare to reference answers.                      |\n",
    "| 4    | For each key term:                                                                                             | Ensures every key term is systematically evaluated.                      |\n",
    "|      | - Retrieves the LLM-extracted answer and page number.                                                          |                                                                         |\n",
    "|      | - Evaluates the extracted answer using `judge_key_term` and the `EVALUATION_METRICS` list.                     | Produces a set of scores and justifications for each metric.             |\n",
    "|      | - Updates the evaluation results with the correct page number.                                                 | Keeps results organized and traceable.                                   |\n",
    "|      | - Collects all evaluation results into a single list.                                                          |                                                                         |\n",
    "| 5    | Converts the results into a Pandas DataFrame for easy display and further analysis.                            | Makes it simple to present and analyze the results in tabular form.      |\n",
    "| 6    | Returns the extracted contract text and the DataFrame of evaluation results.                                   | Provides all necessary outputs for downstream use (e.g., UI display).    |\n",
    "\n",
    "---\n",
    "\n",
    "### Why This Matters\n",
    "\n",
    "- **End-to-End Automation:**  \n",
    "  This function ties together all the core steps of the contract analysis pipeline, making the process seamless for the user.\n",
    "\n",
    "- **Simplicity:**  \n",
    "  By omitting ground truth comparison, this version is ideal for real-world scenarios where reference answers may not be available.\n",
    "\n",
    "- **Structured Output:**  \n",
    "  Returns results in a DataFrame, which is ideal for visualization, reporting, or further processing.\n",
    "\n",
    "---\n",
    "\n",
    "**In summary:**  \n",
    "This version of `process_documents` is the main driver function for contract analysis, handling everything from document ingestion to evaluation, and returning results ready for display or further use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a7cdc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_documents(contract_file, ground_truth_file=None):\n",
    "    # contract_file is a path (str), not a file-like object\n",
    "    text, docs = extract_text_from_file(contract_file)\n",
    "    \n",
    "    # Step 2: Extract key terms\n",
    "    key_term_results = extract_key_terms(text, KEY_TERMS)\n",
    "    \n",
    "    # # Step 3: Load ground truth if provided\n",
    "    # ground_truth = None\n",
    "    # if ground_truth_file is not None:\n",
    "    #     ground_truth = load_ground_truth(ground_truth_file)\n",
    "    \n",
    "    # Step 4: Judge each key term\n",
    "    all_results = []\n",
    "    for term in KEY_TERMS:\n",
    "        llm_ans = key_term_results[term][\"answer\"]\n",
    "        page_number = key_term_results[term][\"page_number\"]\n",
    "        # gt_ans = ground_truth[term] if ground_truth and term in ground_truth else None\n",
    "        evals = judge_key_term(term, llm_ans, EVALUATION_METRICS)\n",
    "        for e in evals:\n",
    "            e[\"page_number\"] = page_number\n",
    "        all_results.extend(evals)\n",
    "    \n",
    "    # Step 5: Prepare DataFrame for display\n",
    "    df = pd.DataFrame(all_results)\n",
    "    return text, df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240b4303",
   "metadata": {},
   "source": [
    "## Gradio App Interface: LLM Contract Judge\n",
    "\n",
    "This section defines the interactive web interface for the contract analysis tool using Gradio. The interface allows users to upload contract files, extract key terms, evaluate them using an LLM, and view the results in a user-friendly format.\n",
    "\n",
    "---\n",
    "\n",
    "| UI Element / Step         | Description                                                                                                   | Why It’s Important                                                      |\n",
    "|---------------------------|---------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------|\n",
    "| **App Container**         | Uses `gr.Blocks()` to create a modular, flexible Gradio app.                                                  | Allows for a clean, organized, and interactive user interface.           |\n",
    "| **Title Markdown**        | Displays a title and brief instructions at the top of the app.                                                | Helps users understand the app’s purpose and how to use it.              |\n",
    "| **Upload & Extract Tab**  | Provides a tab for uploading contract files (PDF, DOCX, TXT).                                                 | Lets users easily provide the documents they want to analyze.            |\n",
    "| **File Upload Widget**    | Allows users to upload a contract file.                                                                       | Supports multiple file formats for flexibility.                          |\n",
    "| **Extract Button**        | A button labeled \"Extract & Evaluate\" to start the analysis process.                                          | Gives users control over when to begin processing.                       |\n",
    "| **Extracted Text Box**    | Displays the extracted text from the uploaded contract.                                                       | Offers transparency and lets users review what was extracted.             |\n",
    "| **Results Table Tab**     | Provides a separate tab to display the evaluation results in a table format.                                  | Organizes results for easy review and comparison.                        |\n",
    "| **Results Dataframe**     | Shows a table with columns for key term, extracted answer, page number, evaluation metric, score, and justification. | Presents detailed evaluation results in a structured, readable way.      |\n",
    "| **run_all Function**      | Defines the function that runs the full analysis pipeline when the button is clicked.                         | Connects the UI to the backend logic for seamless operation.             |\n",
    "| **Button Click Event**    | Links the \"Extract & Evaluate\" button to the `run_all` function, passing the uploaded file as input.          | Ensures user actions trigger the correct processing workflow.            |\n",
    "| **App Launch**            | Calls `demo.launch()` to start the Gradio app and make it accessible in the browser.                          | Makes the tool available for interactive use.                            |\n",
    "\n",
    "---\n",
    "\n",
    "### Why This Matters\n",
    "\n",
    "- **User-Friendly:**  \n",
    "  The Gradio interface makes it easy for users to interact with complex AI-powered contract analysis tools without needing to write code.\n",
    "\n",
    "- **Transparency:**  \n",
    "  Users can see both the raw extracted text and the detailed evaluation results, increasing trust in the tool.\n",
    "\n",
    "- **Efficiency:**  \n",
    "  The app streamlines the workflow from document upload to actionable insights, all in one place.\n",
    "\n",
    "---\n",
    "\n",
    "**In summary:**  \n",
    "This Gradio app provides an accessible, interactive front-end for your contract analysis pipeline, allowing users to upload documents, trigger analysis, and review results with ease."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e524fd68",
   "metadata": {},
   "source": [
    "# When you run the last cell in your notebook, you’ll see a message like the one shown in the image below. Click on the \"Running on local URL\" link—you will be redirected to a new screen where you can interact with the LLM Contract Judge app.\n",
    "\n",
    "![Gradio Local URL Example](Images//img-1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "024957e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sachi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\utils.py:1002: UserWarning: Expected 2 arguments for function <function run_all at 0x000002A3261F9E40>, received 1.\n",
      "  warnings.warn(\n",
      "c:\\Users\\sachi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\utils.py:1006: UserWarning: Expected at least 2 arguments for function <function run_all at 0x000002A3261F9E40>, received 1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sachi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\analytics.py:106: UserWarning: IMPORTANT: You are using gradio version 4.44.0, however version 4.44.1 is available, please upgrade. \n",
      "--------\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sachi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\helpers.py:978: UserWarning: Unexpected argument. Filling with None.\n",
      "  warnings.warn(\"Unexpected argument. Filling with None.\")\n"
     ]
    }
   ],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# 📄 LLM Contract Judge\\nUpload a contract, extract key terms, and evaluate with LLM.\")\n",
    "    with gr.Tab(\"Upload & Extract\"):\n",
    "        contract_file = gr.File(label=\"Upload Contract (PDF, DOCX, TXT)\")\n",
    "        # ground_truth_file = gr.File(label=\"Upload Ground Truth CSV (optional)\", optional=True)\n",
    "        extract_btn = gr.Button(\"Extract & Evaluate\")\n",
    "        extracted_text = gr.Textbox(label=\"Extracted Text\", lines=10)\n",
    "    with gr.Tab(\"Results Table\"):\n",
    "        results_table = gr.Dataframe(headers=[\n",
    "            \"key_term_name\", \"llm_extracted_ans_from_doc\", \"page_number\", \"evulation_metric_name\", \"score\", \"justification\"\n",
    "        ], label=\"Evaluation Results\")\n",
    "    \n",
    "    def run_all(contract_file, ground_truth_file):\n",
    "        text, df = process_documents(contract_file, ground_truth_file)\n",
    "        return text, gr.update(value=df)\n",
    "    \n",
    "    extract_btn.click(\n",
    "        run_all,\n",
    "        inputs=[contract_file],\n",
    "        outputs=[extracted_text, results_table]\n",
    "    )\n",
    "\n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
