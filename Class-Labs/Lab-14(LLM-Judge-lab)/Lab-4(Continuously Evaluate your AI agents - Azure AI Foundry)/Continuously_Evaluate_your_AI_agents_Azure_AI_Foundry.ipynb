{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Overview\n",
        "\n",
        "In this lab, you'll explore **Continuous Evaluation for Agents** ‚Äî a powerful tool that provides near real-time evualteand monitoring for your AI applications. Through hands-on exercises, you'll learn how to implement, configure, and leverage this feature to ensure optimal agent performance.\n",
        "\n",
        "## Introduction\n",
        "\n",
        "Continuous Evaluation enables your AI agents to be evaluate monitored at a defined sampling rate. It provides actionable insights into quality, safety, and performance, with all metrics surfaced in the **Foundry Observability Dashboard**. Evaluations are directly linked to traces, making it easy to troubleshoot issues, perform root cause analysis, and continuously improve your AI workflows.\n",
        "\n",
        "## Key Benefits\n",
        "\n",
        "- **Near Real-Time Monitoring**: Immediate visibility into agent performance\n",
        "- **Quality Assurance**: Continuous evaluation of interaction quality\n",
        "- **Safety Monitoring**: Ongoing tracking of safety-related metrics\n",
        "- **Performance Optimization**: Data-driven insights for enhancing agent efficiency\n",
        "- **Early Issue Detection**: Proactive identification of issues before user impact\n",
        "- **Root Cause Analysis**: Trace-linked evaluations for detailed debugging\n"
      ],
      "metadata": {
        "id": "oV34ar8XJ8SY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Getting Started"
      ],
      "metadata": {
        "id": "uMZTvHPTKPZ1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prerequisites\n",
        "\n",
        "**1 Azure Subscription**: You must have an **Azure subscription with access to Azure OpenAI Service**. A premium subscription is strongly recommended to access all features.\n",
        "\n",
        "**2 Azure AI Foundry Project**: You need an active AI Foundry project. If you don't have one, you can create one using this guide:\n",
        "\n",
        "* **3 Create a Foundry Project**: [https://learn.microsoft.com/en-us/azure/ai-foundry/how-to/create-projects](https://learn.microsoft.com/en-us/azure/ai-foundry/how-to/create-projects?pivots=fdp-project&tabs=ai-foundry)\n",
        "\n",
        "\n",
        "\n",
        "**4 Application Insights**: To monitor your application and view evaluation dashboards, you must connect Application Insights.\n",
        "   - Navigate to your project in **Azure AI Foundry**.\n",
        "   - Select **Monitoring** on the left-hand menu and go to **Application Analytics**.\n",
        "   - Connect your **Application Insights** resource to the project.\n",
        "\n",
        "**5 Dowload the Dummy MSA Document From Here For Testing** [Click Here](https://drive.google.com/file/d/1WMj5L4SNu3FboczMm6k2Qnw6lROed19x/view?usp=drive_link)"
      ],
      "metadata": {
        "id": "EMpMlB-5KXbr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sign into Azure interactively using the Azure CLI\n",
        "\n",
        "To interact with Azure resources directly from your Colab notebook, you first need to install the **Azure CLI** in the Colab environment. Use the command below to install it:\n",
        "**bold text**\n"
      ],
      "metadata": {
        "id": "RFKpy0O2K1_4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6epjjvODA9eX",
        "outputId": "0aab34a3-466a-4899-a076-33a40fe6858d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "\r0% [Connecting to archive.ubuntu.com (185.125.190.83)] [Connecting to security.\r0% [Connecting to archive.ubuntu.com (185.125.190.83)] [Connecting to security.\r                                                                               \rGet:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "\r0% [Waiting for headers] [Waiting for headers] [Waiting for headers] [2 InRelea\r0% [Waiting for headers] [Waiting for headers] [Waiting for headers] [Connectin\r                                                                               \rHit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,851 kB]\n",
            "Get:8 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,765 kB]\n",
            "Get:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:13 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,159 kB]\n",
            "Get:14 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,138 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,470 kB]\n",
            "Get:16 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [32.9 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [4,976 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [5,163 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,268 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,573 kB]\n",
            "Fetched 33.8 MB in 4s (8,360 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "lsb-release is already the newest version (11.1.0ubuntu4).\n",
            "lsb-release set to manually installed.\n",
            "ca-certificates is already the newest version (20240203~22.04.1).\n",
            "curl is already the newest version (7.81.0-1ubuntu1.20).\n",
            "gnupg is already the newest version (2.2.27-3ubuntu2.4).\n",
            "gnupg set to manually installed.\n",
            "The following NEW packages will be installed:\n",
            "  apt-transport-https\n",
            "0 upgraded, 1 newly installed, 0 to remove and 40 not upgraded.\n",
            "Need to get 1,510 B of archives.\n",
            "After this operation, 170 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 apt-transport-https all 2.4.14 [1,510 B]\n",
            "Fetched 1,510 B in 0s (5,229 B/s)\n",
            "Selecting previously unselected package apt-transport-https.\n",
            "(Reading database ... 126284 files and directories currently installed.)\n",
            "Preparing to unpack .../apt-transport-https_2.4.14_all.deb ...\n",
            "Unpacking apt-transport-https (2.4.14) ...\n",
            "Setting up apt-transport-https (2.4.14) ...\n",
            "Types: deb\n",
            "URIs: https://packages.microsoft.com/repos/azure-cli/\n",
            "Suites: jammy\n",
            "Components: main\n",
            "Architectures: amd64\n",
            "Signed-by: /etc/apt/keyrings/microsoft.gpg\n",
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:3 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 https://packages.microsoft.com/repos/azure-cli jammy InRelease [3,596 B]\n",
            "Hit:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Get:9 https://packages.microsoft.com/repos/azure-cli jammy/main amd64 Packages [2,514 B]\n",
            "Get:10 https://packages.microsoft.com/repos/azure-cli jammy/main all Packages [1,093 B]\n",
            "Hit:11 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:12 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:13 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Fetched 7,203 B in 2s (4,333 B/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  azure-cli\n",
            "0 upgraded, 1 newly installed, 0 to remove and 40 not upgraded.\n",
            "Need to get 54.1 MB of archives.\n",
            "After this operation, 635 MB of additional disk space will be used.\n",
            "Get:1 https://packages.microsoft.com/repos/azure-cli jammy/main amd64 azure-cli amd64 2.75.0-1~jammy [54.1 MB]\n",
            "Fetched 54.1 MB in 6s (8,564 kB/s)\n",
            "Selecting previously unselected package azure-cli.\n",
            "(Reading database ... 126288 files and directories currently installed.)\n",
            "Preparing to unpack .../azure-cli_2.75.0-1~jammy_amd64.deb ...\n",
            "Unpacking azure-cli (2.75.0-1~jammy) ...\n",
            "Setting up azure-cli (2.75.0-1~jammy) ...\n"
          ]
        }
      ],
      "source": [
        "!curl -sL https://aka.ms/InstallAzureCLIDeb | sudo bash"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Interactive login\n",
        "`az login` is a command used with the **Azure CLI (Command Line Interface)** to authenticate and connect your local environment (like Terminal, Command Prompt, or Jupyter Notebook) to your **Microsoft Azure account**.\n",
        "\n",
        "## Requirements\n",
        "\n",
        "- ‚úÖ You must have an **Azure subscription account**.\n",
        "- ‚úÖ **Azure CLI** should be installed (`az` command should work in your terminal or notebook).\n",
        "\n",
        "## When you run `az login`, you will receive a message like:\n",
        "***To sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code SHH9K2G35 to authenticate.***\n",
        "\n",
        "***Click the link, paste the provided code, and follow the login steps to complete authentication.***"
      ],
      "metadata": {
        "id": "ETY8-c5_NJhT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step-by-step Instructions\n",
        "\n",
        "1. Copy and open this link in your browser:  \n",
        "   üëâ [https://microsoft.com/devicelogin](https://microsoft.com/devicelogin)\n",
        "\n",
        "2. Paste the **code** displayed in your terminal (e.g., `SHH9K2G35`) and click **Next**. ‚ö†Ô∏è The code shown will be different each time.\n",
        "\n",
        "3. Sign in using your **Microsoft Azure account credentials**.\n",
        "\n",
        "4. After signing in, you'll be asked to **select your Azure subscription** if you have more than one.\n",
        "\n",
        "5. Once selected, authentication is complete, and you're **ready to use Azure CLI** commands."
      ],
      "metadata": {
        "id": "vrm0OIFGNknk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjtoQVKCBCcg",
        "outputId": "b79a48a3-2db9-4651-e588-6ff9779d4678"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[93mTo sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code AVCA9BL47 to authenticate.\u001b[0m\n",
            "\n",
            "Retrieving tenants and subscriptions for the selection...\n",
            "\n",
            "[Tenant and subscription selection]\n",
            "\n",
            "No     Subscription name              Subscription ID                       Tenant\n",
            "-----  -----------------------------  ------------------------------------  -----------\n",
            "\u001b[96m[1]\u001b[0m *  \u001b[96mMicrosoft Azure LegalGraph AI\u001b[0m  \u001b[96m0d74045d-252c-4b44-856a-71c5dee6b80a\u001b[0m  \u001b[96mPragyaa LLC\u001b[0m\n",
            "\n",
            "The default is marked with an *; the default tenant is 'Pragyaa LLC' and subscription is 'Microsoft Azure LegalGraph AI' (0d74045d-252c-4b44-856a-71c5dee6b80a).\n",
            "\n",
            "Select a subscription and tenant (Type a number or Enter for no changes): 1\n",
            "\n",
            "Tenant: Pragyaa LLC\n",
            "Subscription: Microsoft Azure LegalGraph AI (0d74045d-252c-4b44-856a-71c5dee6b80a)\n",
            "\n",
            "[Announcements]\n",
            "With the new Azure CLI login experience, you can select the subscription you want to use more easily. Learn more about it and its configuration at https://go.microsoft.com/fwlink/?linkid=2271236\n",
            "\n",
            "If you encounter any problem, please open an issue at https://aka.ms/azclibug\n",
            "\n",
            "\u001b[93m[Warning] The login output has been updated. Please be aware that it no longer displays the full list of available subscriptions by default.\n",
            "\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!az login"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Install Required Packages\n",
        "\n",
        "Ok, so now your **first step** is to install the required Python packages. These will enable you to work with **Azure AI services**, handle **document processing**, and build an interactive UI using **Gradio**.\n",
        "\n",
        "Run the following command in your environment:\n",
        "\n",
        "| Package Name        | Description                                                                 |\n",
        "|---------------------|-----------------------------------------------------------------------------|\n",
        "| `azure-ai-projects` | SDK to interact with Azure AI projects and services                         |\n",
        "| `azure-identity`    | Provides Azure Active Directory token authentication for Azure SDKs         |\n",
        "| `python-dotenv`     | Loads environment variables from a `.env` file into the environment          |\n",
        "| `gradio`            | Builds simple and interactive web UIs for ML models and functions            |\n",
        "| `PyPDF2`            | Extracts text, metadata, and handles PDF file reading and manipulation       |\n",
        "| `python-docx`       | Reads, writes, and manipulates Microsoft Word `.docx` files                  |\n",
        "| `openpyxl`          | Reads and writes Excel `.xlsx` files                                         |\n",
        "| `pandas`            | Provides data structures and tools for data manipulation and analysis        |\n"
      ],
      "metadata": {
        "id": "TiRjXt4wPgN-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jYS_I3yI6JU",
        "outputId": "24d1b9a4-1edc-48f3-8d49-325c206764b1",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting azure-ai-projects\n",
            "  Downloading azure_ai_projects-1.0.0b12-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting azure-identity\n",
            "  Downloading azure_identity-1.23.1-py3-none-any.whl.metadata (82 kB)\n",
            "\u001b[?25l     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/82.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m82.4/82.4 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.38.0)\n",
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting python-docx\n",
            "  Downloading python_docx-1.2.0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Collecting isodate>=0.6.1 (from azure-ai-projects)\n",
            "  Downloading isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting azure-core>=1.30.0 (from azure-ai-projects)\n",
            "  Downloading azure_core-1.35.0-py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from azure-ai-projects) (4.14.1)\n",
            "Collecting azure-storage-blob>=12.15.0 (from azure-ai-projects)\n",
            "  Downloading azure_storage_blob-12.26.0-py3-none-any.whl.metadata (26 kB)\n",
            "Collecting azure-ai-agents>=1.0.0 (from azure-ai-projects)\n",
            "  Downloading azure_ai_agents-1.0.2-py3-none-any.whl.metadata (52 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m52.3/52.3 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cryptography>=2.5 in /usr/local/lib/python3.11/dist-packages (from azure-identity) (43.0.3)\n",
            "Collecting msal>=1.30.0 (from azure-identity)\n",
            "  Downloading msal-1.33.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting msal-extensions>=1.2.0 (from azure-identity)\n",
            "  Downloading msal_extensions-1.3.1-py3-none-any.whl.metadata (7.8 kB)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.1.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.116.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.6.0)\n",
            "Requirement already satisfied: gradio-client==1.11.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.11.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.33.4)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.11.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.7)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.12.4)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.47.1)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.16.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.35.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.11.0->gradio) (2025.7.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.11.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (5.4.0)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: requests>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from azure-core>=1.30.0->azure-ai-projects) (2.32.3)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from azure-core>=1.30.0->azure-ai-projects) (1.17.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=2.5->azure-identity) (1.17.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.7.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (1.1.5)\n",
            "Requirement already satisfied: PyJWT<3,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from PyJWT[crypto]<3,>=1.0.0->msal>=1.30.0->azure-identity) (2.10.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=2.5->azure-identity) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.21.0->azure-core>=1.30.0->azure-ai-projects) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.21.0->azure-core>=1.30.0->azure-ai-projects) (2.5.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading azure_ai_projects-1.0.0b12-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m129.8/129.8 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azure_identity-1.23.1-py3-none-any.whl (186 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m186.8/186.8 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_docx-1.2.0-py3-none-any.whl (252 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azure_ai_agents-1.0.2-py3-none-any.whl (189 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m189.8/189.8 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azure_core-1.35.0-py3-none-any.whl (210 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m210.7/210.7 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azure_storage_blob-12.26.0-py3-none-any.whl (412 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m412.9/412.9 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading isodate-0.7.2-py3-none-any.whl (22 kB)\n",
            "Downloading msal-1.33.0-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m116.9/116.9 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading msal_extensions-1.3.1-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: python-dotenv, python-docx, PyPDF2, isodate, azure-core, azure-storage-blob, azure-ai-agents, msal, azure-ai-projects, msal-extensions, azure-identity\n",
            "Successfully installed PyPDF2-3.0.1 azure-ai-agents-1.0.2 azure-ai-projects-1.0.0b12 azure-core-1.35.0 azure-identity-1.23.1 azure-storage-blob-12.26.0 isodate-0.7.2 msal-1.33.0 msal-extensions-1.3.1 python-docx-1.2.0 python-dotenv-1.1.1\n"
          ]
        }
      ],
      "source": [
        "# Install all required packages for Azure AI, document processing, and Gradio interface\n",
        "!pip install azure-ai-projects azure-identity python-dotenv gradio PyPDF2 python-docx openpyxl pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step3: Import Required Libraries\n",
        "\n",
        "Once all packages are installed, import the necessary libraries for:\n",
        "\n",
        "- Working with Azure AI Projects\n",
        "- Document processing (PDF, DOCX, Excel)\n",
        "- Building the Gradio interface\n",
        "- Loading environment variables"
      ],
      "metadata": {
        "id": "qOV8zCkPP-w2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-ZppjY2I_ew",
        "outputId": "b130243a-6552-437b-da12-1929089c5d28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ All libraries imported successfully!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import time\n",
        "import io\n",
        "import pandas as pd\n",
        "import gradio as gr\n",
        "from typing import Optional, Tuple, Dict\n",
        "\n",
        "# Azure AI imports\n",
        "from azure.identity import DefaultAzureCredential\n",
        "from azure.ai.projects import AIProjectClient\n",
        "from azure.ai.projects.models import (\n",
        "    AgentEvaluationRequest,\n",
        "    InputDataset,\n",
        "    EvaluatorIds,\n",
        "    EvaluatorConfiguration,\n",
        "    AgentEvaluationSamplingConfiguration,\n",
        "    AgentEvaluationRedactionConfiguration,\n",
        ")\n",
        "\n",
        "# Document processing imports\n",
        "import PyPDF2\n",
        "from docx import Document\n",
        "import openpyxl\n",
        "\n",
        "# Load environment variables\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "print(\"‚úÖ All libraries imported successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4 : Configure Azure AI Project\n",
        "Next, configure your Azure AI project by setting the required `endpoint` and `model_deployment_name`. These should be replaced with **your actual Azure AI project details**.\n",
        "- Create an Enpoint Azure AI Foundry Guide  : [Click Here](https://learn.microsoft.com/en-us/azure/ai-foundry/how-to/develop/sdk-overview?pivots=programming-language-csharp\n",
        ")\n",
        "- Deploy AI Models in Azure AI Foundry Guide - [Click Here](https://www.linkedin.com/pulse/how-deploy-ai-models-minutes-azure-foundryguide-pradip-tivhale-dpbjc\n",
        ")"
      ],
      "metadata": {
        "id": "xMIUihbPQIsh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wt0CWzYAJARp",
        "outputId": "3028e72d-c8f0-4ff0-91fe-75fbf4e1e727"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Initializing Azure AI configuration...\n",
            "‚ùå Configuration Error: Please replace the placeholder values for 'endpoint' and 'model_deployment_name'.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "# You would typically need these imports for the actual client initialization\n",
        "# from azure.identity import DefaultAzureCredential\n",
        "# from azure.ai.projects import AIProjectClient\n",
        "\n",
        "# Azure AI Project configuration\n",
        "# Replace these with your actual Azure AI project details\n",
        "# Get the Keys from Here : https://learn.microsoft.com/en-us/azure/ai-foundry/how-to/develop/sdk-overview?pivots=programming-language-csharp\n",
        "endpoint = \"INSERT YOUR KEYS HERE\"\n",
        "# Deploy AI Models in Azure AI Foundry Guide : https://www.linkedin.com/pulse/how-deploy-ai-models-minutes-azure-foundryguide-pradip-tivhale-dpbjc\n",
        "model_deployment_name = \"INSERT YOUR KEYS HERE\"\n",
        "\n",
        "# Global variables to store agent and project client\n",
        "project_client = None\n",
        "agent = None\n",
        "extracted_text = \"\"\n",
        "\n",
        "try:\n",
        "    print(\"üöÄ Initializing Azure AI configuration...\")\n",
        "\n",
        "    # 1. Check if placeholder keys are replaced\n",
        "    if \"INSERT YOUR KEYS HERE\" in (endpoint, model_deployment_name):\n",
        "        raise ValueError(\"Please replace the placeholder values for 'endpoint' and 'model_deployment_name'.\")\n",
        "\n",
        "    # 2. The actual client initialization would go here.\n",
        "    #    This is where errors related to authentication or invalid endpoints would be caught.\n",
        "    #    Example:\n",
        "    #    credential = DefaultAzureCredential()\n",
        "    #    project_client = AIProjectClient(endpoint=endpoint, credential=credential)\n",
        "\n",
        "    print(\"‚úÖ Azure AI configuration is valid.\")\n",
        "\n",
        "except ValueError as ve:\n",
        "    # Catches specific configuration errors, like the placeholder issue.\n",
        "    print(f\"‚ùå Configuration Error: {ve}\")\n",
        "\n",
        "except Exception as e:\n",
        "    # Catches any other exceptions during initialization (e.g., connection, authentication).\n",
        "    print(f\"‚ùå An unexpected error occurred during initialization: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5: Define Document Extraction Functions\n",
        "This function is responsible for **extracting text** from documents you upload.  \n",
        "It supports major file types like **PDF**, **DOCX**, and **TXT** formats.\n",
        "\n",
        "---\n",
        "\n",
        "### What It Does this function do :\n",
        "\n",
        "- Reads the uploaded file\n",
        "- Detects the file type\n",
        "- Extracts the text content accordingly\n",
        "- Returns the clean extracted text"
      ],
      "metadata": {
        "id": "feJVregBWP4m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzRYX2upJH7o",
        "outputId": "7d1e08da-4bcc-4e69-e5b8-6d2da0b4b0a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÑ Document extraction functions defined!\n"
          ]
        }
      ],
      "source": [
        "def extract_text_from_pdf(file_path: str) -> str:\n",
        "    \"\"\"\n",
        "    Extract text content from PDF files\n",
        "    Args:\n",
        "        file_path (str): Path to the PDF file\n",
        "    Returns:\n",
        "        str: Extracted text content\n",
        "    \"\"\"\n",
        "    try:\n",
        "        text = \"\"\n",
        "        with open(file_path, 'rb') as file:\n",
        "            pdf_reader = PyPDF2.PdfReader(file)\n",
        "            for page in pdf_reader.pages:\n",
        "                text += page.extract_text() + \"\\n\"\n",
        "        return text.strip()\n",
        "    except Exception as e:\n",
        "        return f\"Error extracting PDF: {str(e)}\"\n",
        "\n",
        "def extract_text_from_docx(file_path: str) -> str:\n",
        "    \"\"\"\n",
        "    Extract text content from Word documents\n",
        "    Args:\n",
        "        file_path (str): Path to the DOCX file\n",
        "    Returns:\n",
        "        str: Extracted text content\n",
        "    \"\"\"\n",
        "    try:\n",
        "        doc = Document(file_path)\n",
        "        text = \"\"\n",
        "        for paragraph in doc.paragraphs:\n",
        "            text += paragraph.text + \"\\n\"\n",
        "        return text.strip()\n",
        "    except Exception as e:\n",
        "        return f\"Error extracting DOCX: {str(e)}\"\n",
        "\n",
        "def extract_text_from_txt(file_path: str) -> str:\n",
        "    \"\"\"\n",
        "    Extract text content from plain text files\n",
        "    Args:\n",
        "        file_path (str): Path to the TXT file\n",
        "    Returns:\n",
        "        str: Extracted text content\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(file_path, 'r', encoding='utf-8') as file:\n",
        "            return file.read().strip()\n",
        "    except Exception as e:\n",
        "        return f\"Error extracting TXT: {str(e)}\"\n",
        "\n",
        "def extract_text_from_document(file_path: str) -> str:\n",
        "    \"\"\"\n",
        "    Main function to extract text from various document formats\n",
        "    Args:\n",
        "        file_path (str): Path to the document file\n",
        "    Returns:\n",
        "        str: Extracted text content\n",
        "    \"\"\"\n",
        "    if not file_path:\n",
        "        return \"No file uploaded\"\n",
        "\n",
        "    file_extension = os.path.splitext(file_path.lower())[1]\n",
        "\n",
        "    if file_extension == '.pdf':\n",
        "        return extract_text_from_pdf(file_path)\n",
        "    elif file_extension == '.docx':\n",
        "        return extract_text_from_docx(file_path)\n",
        "    elif file_extension == '.txt':\n",
        "        return extract_text_from_txt(file_path)\n",
        "    else:\n",
        "        return f\"Unsupported file format: {file_extension}\"\n",
        "\n",
        "print(\"üìÑ Document extraction functions defined!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 6 : Define Azure AI Agent\n",
        "\n",
        "Below are the two main functions used to initialize and create an Azure AI agent that can work with uploaded document content.\n",
        "\n",
        "---\n",
        "\n",
        "### 1. `initialize_azure_client()`\n",
        "\n",
        "**Purpose:**  \n",
        "Authenticates your environment with Azure and returns an instance of the `AIProjectClient`, allowing you to interact with Azure AI services.  \n",
        "It uses `DefaultAzureCredential` for seamless login, including browser-based login if needed.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. `create_agent_with_document_context(document_text: str)`\n",
        "\n",
        "**Purpose:**  \n",
        "Creates a custom AI agent in Azure using the extracted document text as part of its instruction prompt.  \n",
        "This agent can answer questions specifically based on the document's content or fall back to general knowledge when needed.  \n",
        "It ensures responses are clear about whether the information came from the uploaded document or from external knowledge.\n"
      ],
      "metadata": {
        "id": "v0Qo7G2tWp1V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BcSWVgIzJRiz",
        "outputId": "1dc33ac9-cf76-4a1e-d26e-92ccf99efce6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ü§ñ Azure AI agent functions defined!\n"
          ]
        }
      ],
      "source": [
        "def initialize_azure_client():\n",
        "    \"\"\"\n",
        "    Initialize Azure AI Project Client with authentication\n",
        "    Returns:\n",
        "        AIProjectClient: Authenticated Azure AI project client\n",
        "    \"\"\"\n",
        "    try:\n",
        "        credential = DefaultAzureCredential(exclude_interactive_browser_credential=False)\n",
        "        client = AIProjectClient(endpoint=endpoint, credential=credential)\n",
        "        return client\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error initializing Azure client: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "def create_agent_with_document_context(document_text: str):\n",
        "    \"\"\"\n",
        "    Create an Azure AI agent with document context in instructions\n",
        "    Args:\n",
        "        document_text (str): Extracted text from uploaded document\n",
        "    Returns:\n",
        "        tuple: (agent_object, success_message)\n",
        "    \"\"\"\n",
        "    global project_client, agent\n",
        "\n",
        "    try:\n",
        "        # Initialize client if not already done\n",
        "        if project_client is None:\n",
        "            project_client = initialize_azure_client()\n",
        "            if project_client is None:\n",
        "                return None, \"‚ùå Failed to initialize Azure client\"\n",
        "\n",
        "        # Create agent with document context\n",
        "        instructions = f\"\"\"You are a helpful AI assistant with access to the following document content:\n",
        "\n",
        "DOCUMENT CONTENT:\n",
        "{document_text}\n",
        "\n",
        "Instructions:\n",
        "- Use the provided document content to answer user questions accurately\n",
        "- If the question relates to the document, provide specific information from it\n",
        "- If the question is outside the document scope, provide general helpful responses\n",
        "- Always be clear about whether your answer comes from the document or general knowledge\n",
        "\"\"\"\n",
        "\n",
        "        agent = project_client.agents.create_agent(\n",
        "            model=model_deployment_name,\n",
        "            name=\"document-assistant\",\n",
        "            instructions=instructions,\n",
        "        )\n",
        "\n",
        "        return agent, f\"‚úÖ Agent created successfully with ID: {agent.id}\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return None, f\"‚ùå Error creating agent: {str(e)}\"\n",
        "\n",
        "print(\"ü§ñ Azure AI agent functions defined!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 7 : User Query Handling & AI Evaluation\n",
        "\n",
        "### 3. `process_user_query(user_query: str)`\n",
        "\n",
        "**Purpose:**  \n",
        "Processes a user's question using the Azure AI agent and returns a detailed answer along with a simple evaluation summary.\n",
        "\n",
        "This function performs the following:\n",
        "- Starts a new thread and sends the user‚Äôs query.\n",
        "- Runs the Azure AI agent on the query.\n",
        "- Waits for and retrieves the assistant's response.\n",
        "- Submits the response for automated evaluation based on metrics like:\n",
        "  - **Violence** (safety check)\n",
        "  - **Fluency** (language quality)\n",
        "  - **Relevance** (context accuracy)\n",
        "- Returns the AI's answer and a status table showing that evaluation was submitted to Azure.\n",
        "\n",
        "> üìä Detailed evaluation metrics and scores will be available inside **Azure AI Studio**.\n"
      ],
      "metadata": {
        "id": "7vWU_d-sXal-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvS68XRmJSL-",
        "outputId": "74debb9f-eee4-4bfb-bbca-e693599c912e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üí¨ Chat and evaluation functions defined!\n"
          ]
        }
      ],
      "source": [
        "def process_user_query(user_query: str) -> Tuple[str, pd.DataFrame]:\n",
        "    \"\"\"\n",
        "    Process user query through Azure AI agent and return response with evaluations\n",
        "    Args:\n",
        "        user_query (str): User's question/query\n",
        "    Returns:\n",
        "        tuple: (response_text, simple_status_dataframe)\n",
        "    \"\"\"\n",
        "    global project_client, agent\n",
        "\n",
        "    if not project_client or not agent:\n",
        "        return \"‚ùå Agent not initialized. Please upload a document first.\", pd.DataFrame()\n",
        "\n",
        "    try:\n",
        "        # Create a new thread for conversation\n",
        "        thread = project_client.agents.threads.create()\n",
        "        print(f\"Created thread, thread ID: {thread.id}\")\n",
        "\n",
        "        # Create user message\n",
        "        message = project_client.agents.messages.create(\n",
        "            thread_id=thread.id,\n",
        "            role=\"user\",\n",
        "            content=user_query\n",
        "        )\n",
        "        print(f\"Created message, message ID: {message.id}\")\n",
        "\n",
        "        # Create and run the agent\n",
        "        run = project_client.agents.runs.create(\n",
        "            thread_id=thread.id,\n",
        "            agent_id=agent.id\n",
        "        )\n",
        "\n",
        "        # Poll the run as long as run status is queued or in progress - EXACTLY like your original code\n",
        "        while run.status in [\"queued\", \"in_progress\", \"requires_action\"]:\n",
        "            # Wait for a second\n",
        "            time.sleep(1)\n",
        "            run = project_client.agents.runs.get(thread_id=thread.id, run_id=run.id)\n",
        "            print(f\"Run status: {run.status}\")\n",
        "\n",
        "        # List messages - EXACTLY like your original code\n",
        "        messages = project_client.agents.messages.list(thread_id=thread.id)\n",
        "        response_text = \"\"\n",
        "\n",
        "        for msg in messages:\n",
        "            print(f\"Role: {msg.role}, Content: {msg.content}\")\n",
        "            if msg.role == \"assistant\":\n",
        "                response_text = msg.content[0].text.value if msg.content else \"No response\"\n",
        "\n",
        "        # Create evaluation request - EXACTLY like your original code\n",
        "        agent_evaluation_request = AgentEvaluationRequest(\n",
        "            run_id=run.id,\n",
        "            thread_id=thread.id,\n",
        "\n",
        "           evaluators={\n",
        "            \"violence\": EvaluatorConfiguration(\n",
        "                id=EvaluatorIds.VIOLENCE,\n",
        "            ),\n",
        "            \"fluency\": EvaluatorConfiguration(\n",
        "                id=EvaluatorIds.FLUENCY,\n",
        "            ),\n",
        "            \"relevance\": EvaluatorConfiguration(\n",
        "                id=EvaluatorIds.RELEVANCE,\n",
        "            ),\n",
        "            \"coherence\": EvaluatorConfiguration(\n",
        "                id=EvaluatorIds.COHERENCE,\n",
        "            ),\n",
        "            },\n",
        "\n",
        "            sampling_configuration=AgentEvaluationSamplingConfiguration(\n",
        "                name=\"test\",\n",
        "                sampling_percent=100,\n",
        "                max_request_rate=100,\n",
        "            ),\n",
        "            redaction_configuration=AgentEvaluationRedactionConfiguration(\n",
        "                redact_score_properties=False,\n",
        "            ),\n",
        "            app_insights_connection_string=project_client.telemetry.get_connection_string(),\n",
        "        )\n",
        "\n",
        "        # Create evaluation - EXACTLY like your original code\n",
        "        agent_evaluation_response = project_client.evaluations.create_agent_evaluation(\n",
        "            evaluation=agent_evaluation_request\n",
        "        )\n",
        "\n",
        "        # Print evaluation response - EXACTLY like your original code\n",
        "        print(agent_evaluation_response)\n",
        "\n",
        "        # Simple status table for Gradio interface (metrics will show in Azure dashboard)\n",
        "        eval_data = {\n",
        "            # This list has 4 items\n",
        "            \"Metric\": [\"Violence\", \"Fluency\", \"Relevance\",\"Coherence\"],\n",
        "            \"Status\": [\"‚úÖ Submitted to Azure\", \"‚úÖ Submitted to Azure\", \"‚úÖ Submitted to Azure\",\"‚úÖ Submitted to Azure\"],\n",
        "            \"Note\": [\"Check Azure AI Studio\", \"Check Azure AI Studio\", \"Check Azure AI Studio\",\"Check Azure AI Studio\"]\n",
        "        }\n",
        "        eval_df = pd.DataFrame(eval_data)\n",
        "\n",
        "        return response_text, eval_df\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in process_user_query: {str(e)}\")\n",
        "        error_df = pd.DataFrame({\"Error\": [str(e)]})\n",
        "        return f\"‚ùå Error processing query: {str(e)}\", error_df\n",
        "\n",
        "print(\"üí¨ Chat and evaluation functions defined!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 8 :  Gradio File & Chat Interaction Handlers\n",
        "\n",
        "### `handle_file_upload(file)`\n",
        "\n",
        "**Purpose**:  \n",
        "Handles file uploads from the Gradio UI.  \n",
        "It performs the following steps:\n",
        "- Validates the file.\n",
        "- Extracts text from the uploaded document (PDF, DOCX, or TXT).\n",
        "- Creates an Azure AI agent with the document content as its knowledge base.\n",
        "- Returns a preview of the document text, a success/error message, and agent creation status.\n",
        "\n",
        "---\n",
        "\n",
        "### `handle_chat_query(query, chat_history)`\n",
        "\n",
        "**Purpose**:  \n",
        "Handles the user‚Äôs chat query using the previously created Azure agent.  \n",
        "It performs the following steps:\n",
        "- Validates the input query.\n",
        "- Sends the query to the Azure agent and waits for a response.\n",
        "- Appends the Q&A pair to the chat history.\n",
        "- Returns the updated history and evaluation results.\n"
      ],
      "metadata": {
        "id": "BCliPYPmamwc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5aRoKIwJVDx",
        "outputId": "adfc59ab-ea1c-45a2-83fd-d1c0fcc420df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üéõÔ∏è Gradio interface functions defined!\n"
          ]
        }
      ],
      "source": [
        "def handle_file_upload(file):\n",
        "    \"\"\"\n",
        "    Handle document upload and extract text content\n",
        "    Args:\n",
        "        file: Gradio file upload object\n",
        "    Returns:\n",
        "        tuple: (extracted_text, status_message, agent_status)\n",
        "    \"\"\"\n",
        "    global extracted_text\n",
        "\n",
        "    if file is None:\n",
        "        return \"\", \"‚ùå No file uploaded\", \"Agent not ready\"\n",
        "\n",
        "    try:\n",
        "        # Extract text from uploaded document\n",
        "        extracted_text = extract_text_from_document(file.name)\n",
        "\n",
        "        if extracted_text.startswith(\"Error\") or extracted_text.startswith(\"Unsupported\"):\n",
        "            return extracted_text, extracted_text, \"Agent not ready\"\n",
        "\n",
        "        # Create agent with document context\n",
        "        agent_obj, agent_status = create_agent_with_document_context(extracted_text)\n",
        "\n",
        "        if agent_obj:\n",
        "            preview_text = extracted_text\n",
        "            return preview_text, \"‚úÖ Document processed successfully!\", agent_status\n",
        "        else:\n",
        "            return extracted_text, agent_status, \"Agent creation failed\"\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"‚ùå Error processing file: {str(e)}\"\n",
        "        return \"\", error_msg, \"Agent not ready\"\n",
        "\n",
        "def handle_chat_query(query, chat_history):\n",
        "    \"\"\"\n",
        "    Handle user chat query and update conversation history\n",
        "    Args:\n",
        "        query (str): User's question\n",
        "        chat_history (list): Previous conversation history\n",
        "    Returns:\n",
        "        tuple: (updated_chat_history, empty_query, evaluation_dataframe)\n",
        "    \"\"\"\n",
        "    if not query.strip():\n",
        "        return chat_history, \"\", pd.DataFrame()\n",
        "\n",
        "    # Process the query\n",
        "    response, eval_df = process_user_query(query)\n",
        "\n",
        "    # Update chat history\n",
        "    chat_history.append([query, response])\n",
        "\n",
        "    return chat_history, \"\", eval_df\n",
        "\n",
        "print(\"üéõÔ∏è Gradio interface functions defined!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 9 : Gradio Interface Overview\n",
        "\n",
        "The create_gradio_interface function defines and configures a user interface using Gradio for an Azure AI Document Chat Assistant. This assistant allows users to upload documents and interact with an AI that can answer questions based on the document content. Here's what the interface includes:\n",
        "\n",
        "### Interface Sections\n",
        "**1. Document Upload Section**\n",
        "- Allows users to upload files in PDF, DOCX, or TXT format.\n",
        "- Displays upload and agent readiness status.\n",
        "- Shows a preview of the extracted text from the uploaded document.\n",
        "\n",
        "**2. Chat Section**\n",
        "- Enables users to chat with the AI assistant after uploading a document.\n",
        "- Includes a chat window to view conversations.\n",
        "- Provides a text input and Send button for submitting questions.\n",
        "\n",
        "**3. Evaluation Metrics**\n",
        "- Shows automated evaluation results for each AI response\n",
        "- Metrics include:\n",
        "    - Violence: Ensures responses are safe.\n",
        "    - Fluency: Checks how well-written the response is.\n",
        "    - Relevance: Measures how closely the response matches the user's query.\n",
        "\n",
        "**4. Usage Instructions**\n",
        "- Provides a step-by-step guide on how to use the app.\n",
        "- Describes what each evaluation metric means.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3q5I3SL9bQYl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4qh3630JaDW",
        "outputId": "f1221ec2-d4f1-4a02-b7ca-2f8ceec6c333"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üé® Gradio interface creation function defined!\n"
          ]
        }
      ],
      "source": [
        "def create_gradio_interface():\n",
        "    \"\"\"\n",
        "    Create and configure the Gradio interface for the document chat application\n",
        "    Returns:\n",
        "        gr.Blocks: Configured Gradio interface\n",
        "    \"\"\"\n",
        "\n",
        "    with gr.Blocks(title=\"Azure AI Document Chat Assistant\", theme=gr.themes.Soft()) as interface:\n",
        "\n",
        "        gr.Markdown(\"\"\"\n",
        "        # ü§ñ Azure AI Document Chat Assistant\n",
        "\n",
        "        Upload a document and chat with an AI assistant that has knowledge of your document content.\n",
        "        Get real-time evaluation metrics for safety, fluency, and relevance.\n",
        "        \"\"\")\n",
        "\n",
        "        with gr.Row():\n",
        "            with gr.Column(scale=1):\n",
        "                # Document Upload Section\n",
        "                gr.Markdown(\"## üìÑ Step 1: Upload Document\")\n",
        "                file_upload = gr.File(\n",
        "                    label=\"Upload Document (PDF, DOCX, TXT)\",\n",
        "                    file_types=[\".pdf\", \".docx\", \".txt\"]\n",
        "                )\n",
        "\n",
        "                upload_status = gr.Textbox(\n",
        "                    label=\"Upload Status\",\n",
        "                    value=\"No file uploaded\",\n",
        "                    interactive=False\n",
        "                )\n",
        "\n",
        "                agent_status = gr.Textbox(\n",
        "                    label=\"Agent Status\",\n",
        "                    value=\"Agent not ready\",\n",
        "                    interactive=False\n",
        "                )\n",
        "\n",
        "                # Document Preview\n",
        "                gr.Markdown(\"## üëÄ Document Preview\")\n",
        "                document_preview = gr.Textbox(\n",
        "                    label=\"Extracted Text Preview\",\n",
        "                    lines=8,\n",
        "                    interactive=False,\n",
        "                    placeholder=\"Upload a document to see preview...\"\n",
        "                )\n",
        "\n",
        "            with gr.Column(scale=2):\n",
        "                # Chat Section\n",
        "                gr.Markdown(\"## üí¨ Step 2: Chat with Your Document\")\n",
        "\n",
        "                chatbot = gr.Chatbot(\n",
        "                    label=\"Conversation\",\n",
        "                    height=400,\n",
        "                    placeholder=\"Upload a document first, then start chatting!\"\n",
        "                )\n",
        "\n",
        "                with gr.Row():\n",
        "                    query_input = gr.Textbox(\n",
        "                        label=\"Your Question\",\n",
        "                        placeholder=\"Ask a question about your document...\",\n",
        "                        scale=4\n",
        "                    )\n",
        "                    send_button = gr.Button(\"Send\", variant=\"primary\", scale=1)\n",
        "\n",
        "                # Evaluation Results Section\n",
        "                gr.Markdown(\"## üìä Step 3: Evaluation Metrics\")\n",
        "                evaluation_table = gr.Dataframe(\n",
        "                    label=\"Response Evaluation Scores\",\n",
        "                    headers=[\"Metric\", \"Score\", \"Status\"],\n",
        "                    interactive=False\n",
        "                )\n",
        "\n",
        "        # Event handlers\n",
        "        file_upload.change(\n",
        "            fn=handle_file_upload,\n",
        "            inputs=[file_upload],\n",
        "            outputs=[document_preview, upload_status, agent_status]\n",
        "        )\n",
        "\n",
        "        send_button.click(\n",
        "            fn=handle_chat_query,\n",
        "            inputs=[query_input, chatbot],\n",
        "            outputs=[chatbot, query_input, evaluation_table]\n",
        "        )\n",
        "\n",
        "        query_input.submit(\n",
        "            fn=handle_chat_query,\n",
        "            inputs=[query_input, chatbot],\n",
        "            outputs=[chatbot, query_input, evaluation_table]\n",
        "        )\n",
        "\n",
        "        # Example usage section\n",
        "        gr.Markdown(\"\"\"\n",
        "        ## üìù How to Use:\n",
        "        1. **Upload**: Select and upload a document (PDF, DOCX, or TXT)\n",
        "        2. **Wait**: Wait for the document to be processed and agent to be created\n",
        "        3. **Chat**: Ask questions about your document content\n",
        "        4. **Review**: Check the evaluation metrics for each response\n",
        "\n",
        "        ## üîç Evaluation Metrics:\n",
        "        - **Violence**: Checks for violent or harmful content\n",
        "        - **Fluency**: Measures how well-written and coherent the response is\n",
        "        - **Relevance**: Evaluates how relevant the response is to your query\n",
        "        \"\"\")\n",
        "\n",
        "    return interface\n",
        "\n",
        "print(\"üé® Gradio interface creation function defined!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 10 : Launching the Gradio Interface\n",
        "This section of the code is responsible for creating and starting the Gradio application for the Azure AI Document Chat Assistant."
      ],
      "metadata": {
        "id": "GBVhTr_VcDDC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 853
        },
        "id": "7Amk0CLcJck0",
        "outputId": "df2a590d-a2d2-490a-80f9-522c763e81ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Creating Gradio interface...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-37-385249032.py:51: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
            "  chatbot = gr.Chatbot(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Interface created successfully!\n",
            "üåê Launching application...\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://ce15b818e61caaf3eb.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://ce15b818e61caaf3eb.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created thread, thread ID: thread_ycx4ApTQAIDF3eckxzoYJdzK\n",
            "Created message, message ID: msg_JonuLQX6wMahmRY0DHawmXFD\n",
            "Run status: RunStatus.IN_PROGRESS\n",
            "Run status: RunStatus.COMPLETED\n",
            "Role: MessageRole.AGENT, Content: [{'type': 'text', 'text': {'value': 'India', 'annotations': []}}]\n",
            "Role: MessageRole.USER, Content: [{'type': 'text', 'text': {'value': 'give me the governing law in one word', 'annotations': []}}]\n",
            "{'id': 'thread_ycx4ApTQAIDF3eckxzoYJdzK;run_sfEtJ61YH9xWjfh4DjloMxVu', 'status': 'Running', 'result': None, 'error': None, 'requestIdentifiers': None}\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 0.0.0.0:7860 <> https://ce15b818e61caaf3eb.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "# Create and launch the Gradio interface\n",
        "print(\"üöÄ Creating Gradio interface...\")\n",
        "app = create_gradio_interface()\n",
        "\n",
        "print(\"‚úÖ Interface created successfully!\")\n",
        "print(\"üåê Launching application...\")\n",
        "\n",
        "# Launch the interface\n",
        "# Use share=True to create a public link, or share=False for local only\n",
        "app.launch(\n",
        "    share=True,  # Set to False if you don't want a public link\n",
        "    server_name=\"0.0.0.0\",  # Allow external connections in Colab\n",
        "    server_port=7860,  # Port number\n",
        "    debug=True  # Enable debug mode\n",
        ")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}