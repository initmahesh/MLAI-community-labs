{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJdEc5U1fZzL"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WADfrUNwfjwB"
      },
      "source": [
        "# **Understanding Agentic RAG: Building Intelligent Document Assistants with ChromaDB(Vectore DB) & LangChain(Framework)**\n",
        "\n",
        "### **What You'll Achieve** 🎯\n",
        "\n",
        "By the end of this lab, you'll gain a deep understanding of **Agentic RAG (Retrieval-Augmented Generation)** and how it revolutionizes the way we interact with documents. Here's what you'll learn:\n",
        "\n",
        "---\n",
        "\n",
        "#### **1. Storing Documents Intelligently Using Vector Embeddings** 🗂️\n",
        "- **What**: Learn how to convert documents into numerical representations (vector embeddings) that capture their meaning.\n",
        "- **How**: Use **ChromaDB**, a vector database, to store and organize these embeddings efficiently.\n",
        "- **Why**: This allows the system to understand and retrieve information based on semantic meaning, not just keywords.\n",
        "\n",
        "---\n",
        "\n",
        "#### **2. Retrieving Information with Semantic Understanding** 🔍\n",
        "- **What**: Discover how to fetch relevant information from a large document collection using semantic search.\n",
        "- **How**: Leverage **LangChain** to query ChromaDB and retrieve the most contextually relevant chunks.\n",
        "- **Why**: This ensures that the system understands the intent behind your questions, not just the literal words.\n",
        "\n",
        "---\n",
        "\n",
        "#### **3. Generating Context-Aware Answers Using Agentic Decision-Making** 🤖\n",
        "- **What**: Explore how **Agentic RAG** makes smart decisions about how to answer questions.\n",
        "- **How**: Implement a decision-making agent that evaluates the confidence of retrieved information and chooses the best response strategy.\n",
        "- **Why**: This allows the system to provide accurate and contextually appropriate answers, even when the information is incomplete or ambiguous.\n",
        "\n",
        "---\n",
        "\n",
        "#### **4. Optimizing Responses Through Knowledge Graph Enhancements** 🧠\n",
        "- **What**: Learn how to enhance answers by connecting related concepts using a knowledge graph.\n",
        "- **How**: Build a knowledge graph that maps terms and relationships (e.g., \"Master Agreement\" → \"Contract\") to improve understanding.\n",
        "- **Why**: This enables the system to provide more comprehensive and insightful answers by leveraging contextual connections.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### **Let's Get Started!** 🚀\n",
        "Ready to dive in? Follow the steps in the lab to see how these concepts come to life in code. By the end, you'll not only understand **Agentic RAG** but also know how to implement it in real-world applications."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "id": "p1YBrA6HRnoG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcd8c3ab-2f24-4f21-deb4-cf3e8a76fdbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting chromadb\n",
            "  Downloading chromadb-1.0.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.23)\n",
            "Collecting pypdf2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Collecting pyboxen\n",
            "  Downloading pyboxen-1.3.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting build>=1.0.3 (from chromadb)\n",
            "  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (2.11.2)\n",
            "Collecting chroma-hnswlib==0.7.6 (from chromadb)\n",
            "  Downloading chroma_hnswlib-0.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n",
            "Collecting fastapi==0.115.9 (from chromadb)\n",
            "  Downloading fastapi-0.115.9-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.11/dist-packages (from chromadb) (2.0.2)\n",
            "Collecting posthog>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-3.24.1-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.13.1)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.21.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.31.1)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.32.0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.53b0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.31.1)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.21.1)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.67.1)\n",
            "Collecting overrides>=7.3.1 (from chromadb)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.71.0)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.15.2)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-32.0.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (9.1.2)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.0.2)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.10.16)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.23.0)\n",
            "Collecting starlette<0.46.0,>=0.40.0 (from fastapi==0.115.9->chromadb)\n",
            "  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.51 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.51)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.24)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.50.3)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.14.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.30.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.1.0)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (24.2)\n",
            "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
            "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.24.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.3.0)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (1.33)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.18)\n",
            "Requirement already satisfied: importlib-metadata<8.7.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.6.1)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.69.2)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.32.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.32.0-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting opentelemetry-proto==1.32.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_proto-1.32.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_sdk-1.32.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.53b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.53b0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting opentelemetry-instrumentation==0.53b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation-0.53b0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.53b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_semantic_conventions-0.53b0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting opentelemetry-util-http==0.53b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_util_http-0.53b0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation==0.53b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.2)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.53b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_api-1.32.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (2.18.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-1.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain) (3.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
            "Downloading chromadb-1.0.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m68.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chroma_hnswlib-0.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m68.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.115.9-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyboxen-1.3.0-py3-none-any.whl (6.8 kB)\n",
            "Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl (284 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
            "Downloading kubernetes-32.0.1-py2.py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.21.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.32.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.32.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.32.0-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.53b0-py3-none-any.whl (12 kB)\n",
            "Downloading opentelemetry_instrumentation-0.53b0-py3-none-any.whl (30 kB)\n",
            "Downloading opentelemetry_instrumentation_asgi-0.53b0-py3-none-any.whl (16 kB)\n",
            "Downloading opentelemetry_semantic_conventions-0.53b0-py3-none-any.whl (188 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.4/188.4 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.32.0-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.3/65.3 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_util_http-0.53b0-py3-none-any.whl (7.3 kB)\n",
            "Downloading opentelemetry_sdk-1.32.0-py3-none-any.whl (118 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.0/119.0 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading posthog-3.24.1-py2.py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m81.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading durationpy-0.9-py3-none-any.whl (3.5 kB)\n",
            "Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading starlette-0.45.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m99.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (454 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.8/454.8 kB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
            "Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53800 sha256=40b72ff5290b6bdf8f9881840ddde392f1449000a635ebdf81b51b3e57b37f69\n",
            "  Stored in directory: /root/.cache/pip/wheels/a3/01/bd/4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, monotonic, durationpy, uvloop, uvicorn, python-dotenv, pyproject_hooks, pypdf2, overrides, opentelemetry-util-http, opentelemetry-proto, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, mmh3, humanfriendly, httptools, chroma-hnswlib, bcrypt, backoff, asgiref, watchfiles, starlette, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, nvidia-cusparse-cu12, nvidia-cudnn-cu12, coloredlogs, build, pyboxen, opentelemetry-semantic-conventions, onnxruntime, nvidia-cusolver-cu12, kubernetes, fastapi, opentelemetry-sdk, opentelemetry-instrumentation, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, chromadb\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: opentelemetry-api\n",
            "    Found existing installation: opentelemetry-api 1.31.1\n",
            "    Uninstalling opentelemetry-api-1.31.1:\n",
            "      Successfully uninstalled opentelemetry-api-1.31.1\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: opentelemetry-semantic-conventions\n",
            "    Found existing installation: opentelemetry-semantic-conventions 0.52b1\n",
            "    Uninstalling opentelemetry-semantic-conventions-0.52b1:\n",
            "      Successfully uninstalled opentelemetry-semantic-conventions-0.52b1\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: opentelemetry-sdk\n",
            "    Found existing installation: opentelemetry-sdk 1.31.1\n",
            "    Uninstalling opentelemetry-sdk-1.31.1:\n",
            "      Successfully uninstalled opentelemetry-sdk-1.31.1\n",
            "Successfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.3.0 build-1.2.2.post1 chroma-hnswlib-0.7.6 chromadb-1.0.4 coloredlogs-15.0.1 durationpy-0.9 fastapi-0.115.9 httptools-0.6.4 humanfriendly-10.0 kubernetes-32.0.1 mmh3-5.1.0 monotonic-1.6 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 onnxruntime-1.21.0 opentelemetry-api-1.32.0 opentelemetry-exporter-otlp-proto-common-1.32.0 opentelemetry-exporter-otlp-proto-grpc-1.32.0 opentelemetry-instrumentation-0.53b0 opentelemetry-instrumentation-asgi-0.53b0 opentelemetry-instrumentation-fastapi-0.53b0 opentelemetry-proto-1.32.0 opentelemetry-sdk-1.32.0 opentelemetry-semantic-conventions-0.53b0 opentelemetry-util-http-0.53b0 overrides-7.7.0 posthog-3.24.1 pyboxen-1.3.0 pypdf2-3.0.1 pypika-0.48.9 pyproject_hooks-1.2.0 python-dotenv-1.1.0 starlette-0.45.3 uvicorn-0.34.0 uvloop-0.21.0 watchfiles-1.0.5\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Install required libraries\n",
        "! pip install chromadb langchain pypdf2 sentence-transformers pyboxen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mURYH1rugGdk"
      },
      "source": [
        "### 🌐 **About LangChain (In Simple Terms)**\n",
        "LangChain is a framework that helps developers **connect AI models with external data sources** like databases or APIs. In this project, we use LangChain to:\n",
        "- Embed text for efficient search.\n",
        "- Retrieve relevant information from the database.\n",
        "- Generate answers using OpenAI’s model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "id": "WbLlwKiMmAQE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9ae0e96-d222-434b-a72b-715fa1744aea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.21-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.51 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.51)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.23 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.23)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.1.2)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.8.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.24)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.3.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.23->langchain-community) (0.3.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.23->langchain-community) (2.11.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain-community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain-community) (4.13.1)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.16)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2025.1.31)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.23->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.23->langchain-community) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.23->langchain-community) (0.4.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n",
            "Downloading langchain_community-0.3.21-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading pydantic_settings-2.8.1-py3-none-any.whl (30 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-community\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-community-0.3.21 marshmallow-3.26.1 mypy-extensions-1.0.0 pydantic-settings-2.8.1 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "# Step 1.1 Intsall this package as well\n",
        "! pip install -U langchain-community"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNfSJPCdnM3y"
      },
      "source": [
        "# Step 3: Setting Up the Lab 🧪\n",
        "\n",
        "---\n",
        "## Import necessary modules\n",
        "Before we start, we need to install the necessary tools. These packages are like the ingredients for our recipe – without them, the lab won't work!\n",
        "\n",
        "# 📌 Explanation of Imported Modules  \n",
        "\n",
        "## 🔹 UI Components  \n",
        "- **`ipywidgets`** → Provides interactive widgets like buttons, text boxes, and dropdowns.  \n",
        "- **`IPython.display`** → Used to display widgets, clear output, and update UI dynamically.  \n",
        "\n",
        "## 🔹 Data Processing & Utility  \n",
        "- **`random`** → Generates random numbers, useful for testing and sampling.  \n",
        "- **`typing (List, Dict)`** → Provides type hints for better code readability and debugging.  \n",
        "- **`io.BytesIO`** → Handles in-memory file operations without saving to disk.  \n",
        "- **`os`** → Interacts with the operating system (e.g., file paths, environment variables).  \n",
        "\n",
        "## 🔹 LangChain Components  \n",
        "- **`langchain.vectorstores.Chroma`** → Stores and retrieves document embeddings efficiently.  \n",
        "- **`langchain.embeddings.HuggingFaceEmbeddings`** → Uses Hugging Face models for text embeddings.  \n",
        "- **`langchain.text_splitter.RecursiveCharacterTextSplitter`** → Splits text into manageable chunks for processing.  \n",
        "- **`langchain.llms.OpenAI`** → Connects to OpenAI’s LLM for generating responses.  \n",
        "- **`langchain.agents.initialize_agent`** → Creates an AI agent with tools for querying documents.  \n",
        "- **`langchain.tools.Tool`** → Defines custom tools for AI agents.  \n",
        "- **`langchain.tools.StructuredTool`** → Provides structured tools for better AI responses.  \n",
        "- **`langchain.prompts.ChatPromptTemplate`** → Creates structured prompts for AI interactions.  \n",
        "- **`langchain.schema.runnable.RunnablePassthrough`** → Allows passing data through AI models without modification.  \n",
        "\n",
        "## 🔹 PDF Handling  \n",
        "- **`PyPDF2.PdfReader`** → Reads and extracts text from PDF documents.  \n",
        "\n",
        "## 🔹 Database & Storage  \n",
        "- **`chromadb`** → A fast and scalable vector database for storing and retrieving embeddings.  \n",
        "\n",
        "## 🔹 UI Styling  \n",
        "- **`pyboxen.boxen`** → Formats text in visually appealing boxed outputs.  \n",
        "\n",
        "## 🔹 Data Validation  \n",
        "- **`pydantic.BaseModel, Field`** → Ensures structured and validated data inputs.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xt7L9rR0UrbR"
      },
      "outputs": [],
      "source": [
        "# Step 2: Import necessary modules\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "import random\n",
        "from typing import List, Dict\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.agents import initialize_agent, Tool\n",
        "from langchain.tools import StructuredTool\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.schema.runnable import RunnablePassthrough\n",
        "from pydantic import BaseModel, Field\n",
        "from PyPDF2 import PdfReader\n",
        "import chromadb\n",
        "from pyboxen import boxen\n",
        "import os\n",
        "from io import BytesIO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xypvDMdbggis"
      },
      "source": [
        "### 📌 **Step 3: Initializing Components - Setting Up AI-Powered Document Processing: Embeddings, Vector Storage, and LLM Integration**\n",
        "```python\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "chroma_client = chromadb.PersistentClient(path=\"./chroma_db\")\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"YOUR_API_KEY\"\n",
        "llm = OpenAI(temperature=0)\n",
        "```\n",
        "- **Embeddings:** We use `HuggingFaceEmbeddings` to convert text into numerical format.\n",
        "- **ChromaDB Client:** Creates a database at `./chroma_db` to store text embeddings.\n",
        "- **OpenAI API:** We set the API key to access OpenAI’s language model.\n",
        "[Generate Your OpenAI API Key](https://github.com/initmahesh/MLAI-community-labs/tree/main/Class-Labs/Lab-0(Pre-requisites))\n",
        "\n",
        "- **LLM Initialization:** We set the temperature to `0` for more deterministic responses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "-P9jwcSyUvdv"
      },
      "outputs": [],
      "source": [
        "# Step 3: Initialize components\n",
        "# Initialize embedding model\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# Initialize ChromaDB client\n",
        "chroma_client = chromadb.PersistentClient(path=\"./chroma_db\")\n",
        "\n",
        "# Initialize LLM (Replace with your API key)\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
        "llm = OpenAI(temperature=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ld1FlCazgsgP"
      },
      "source": [
        "# 📌 Step 4: Upload & Process a PDF Document  \n",
        "\n",
        "This step allows users to upload a PDF file, extract its text, split it into smaller chunks, and store it in a vector database for AI processing.  \n",
        "\n",
        "## 🔹 How It Works  \n",
        "1. **File Upload Widget**  \n",
        "   - A button appears that lets you upload a **PDF file**.  \n",
        "   - The system only accepts **one file at a time**.  \n",
        "\n",
        "2. **Processing the File**  \n",
        "   - When you click the **\"Process File\"** button:  \n",
        "     - The system checks if a file is uploaded.  \n",
        "     - If no file is found, it shows a message: **\"No file uploaded!\"**  \n",
        "     - If a file is uploaded, the system reads the PDF and extracts its text.  \n",
        "     - The text is split into smaller **chunks** (for efficient processing).  \n",
        "     - Each chunk is assigned a **random confidence score**.  \n",
        "     - The data is stored in **ChromaDB**, a special AI-ready database.  \n",
        "\n",
        "3. **Success Message**  \n",
        "   - If everything works, you’ll see a **green notification box**:  \n",
        "     ```\n",
        "     File processed with confidence scores!\n",
        "     ```  \n",
        "   - This means your file was successfully processed and stored.  \n",
        "\n",
        "## 🔹 Steps to Use  \n",
        "✅ **Step 1** → Click on **\"Upload Document\"** and select a PDF file.  \n",
        "✅ **Step 2** → Click **\"Process File\"** to analyze and store it.  \n",
        "✅ **Step 3** → Wait for the **success message** confirming the file is processed.  \n",
        "\n",
        "**✅ NOTE** : [📄 **Reference Document You Can Use**](https://drive.google.com/file/d/1WWa_TgI49HIAGFuXTNvMLtkFBU6ZduHq/view?usp=sharing)\n",
        "\n",
        "This setup makes it easy to upload and process PDFs with AI-powered storage. 🚀  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "SPaM1w24U1tF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155,
          "referenced_widgets": [
            "61fa487e09f146df858e5ff852852817",
            "fcd2c04e736747f9a4aaefd2e3a8e5d8",
            "42009fd475574ef48de40ebe36f4961f",
            "234000427b2041f0a625cdc99ed45372",
            "208e2d02c0774f04bb470be2d81e1bfa",
            "3701175e40864740989bb733401f6ca4",
            "643332e54133406ea09ec5c7a36b3c16",
            "99a9dcae2e874181ab7cea927ec48a11"
          ]
        },
        "outputId": "3d1eb7e8-50e6-4eb0-e2fd-de236fb160b1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "FileUpload(value={}, accept='.pdf', description='Upload')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "61fa487e09f146df858e5ff852852817"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Button(description='Process File', style=ButtonStyle())"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "234000427b2041f0a625cdc99ed45372"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "643332e54133406ea09ec5c7a36b3c16"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Step 4: File upload widget with value storage\n",
        "import random\n",
        "uploader = widgets.FileUpload(accept='.pdf', multiple=False)\n",
        "process_btn = widgets.Button(description=\"Process File\")\n",
        "process_output = widgets.Output()\n",
        "\n",
        "def process_file(b):\n",
        "    with process_output:\n",
        "        clear_output()\n",
        "        if not uploader.value:\n",
        "            print(\"No file uploaded!\")\n",
        "            return\n",
        "\n",
        "        for filename, file_info in uploader.value.items():\n",
        "            pdf = PdfReader(BytesIO(file_info['content']))\n",
        "            break\n",
        "\n",
        "        text = \"\\n\".join([page.extract_text() for page in pdf.pages])\n",
        "        text_splitter = RecursiveCharacterTextSplitter(\n",
        "            chunk_size=1000, chunk_overlap=100\n",
        "        )\n",
        "        chunks = text_splitter.split_text(text)\n",
        "        metadatas = [{\"value\": random.uniform(0, 1)} for _ in chunks]\n",
        "\n",
        "        Chroma.from_texts(\n",
        "            chunks, embeddings,\n",
        "            client=chroma_client,\n",
        "            collection_name=\"doc_collection\",\n",
        "            metadatas=metadatas\n",
        "        )\n",
        "        print(boxen(\"File processed with confidence scores!\", title=\"Success\", color=\"green\"))\n",
        "\n",
        "display(uploader, process_btn, process_output)\n",
        "process_btn.on_click(process_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsnCbBlhg-sv"
      },
      "source": [
        "# 📝 Step 5: Enhanced Query Processing with an Agent  \n",
        "\n",
        "This step enhances **query processing** by implementing an **AI agent** that decides how to answer user queries based on **confidence scores**. It retrieves relevant document chunks and determines whether the response should be **directly generated** or **refined using a knowledge graph** for better accuracy.  \n",
        "\n",
        "---\n",
        "## 🔹 Overview of the Query Processing Flow  \n",
        "\n",
        "### 1️⃣ **User Query Retrieval**  \n",
        "- The user submits a **query**.\n",
        "- The system **retrieves relevant document chunks** using ChromaDB.\n",
        "- Each retrieved chunk has an **associated confidence score**.\n",
        "\n",
        "### 2️⃣ **Confidence Score Evaluation**  \n",
        "- If the confidence score is **high (≥ 0.5)** → Use a **direct answer** approach.\n",
        "- If the confidence score is **low (< 0.3)** → Use a **knowledge-enhanced answer**.\n",
        "\n",
        "### 3️⃣ **Knowledge Graph Enhancement** (for low-confidence cases)  \n",
        "- Some terms in the query are mapped to **more meaningful alternatives** using a **knowledge graph**.\n",
        "- The query is **rewritten** with these enhancements.\n",
        "- A new document search is performed using the improved query.\n",
        "\n",
        "### 4️⃣ **Generating the Final Answer**  \n",
        "- The system **chooses the best response strategy** using an autonomous agent.\n",
        "- The **final answer is generated** based on the refined context and confidence evaluation.\n",
        "\n",
        "---\n",
        "\n",
        "## 🔍 **Understanding Confidence Scores**  \n",
        "\n",
        "A **confidence score** is a measure of **how relevant** a retrieved document chunk is to the user's query.  \n",
        "- **Higher confidence (≥ 0.5)** → The retrieved text is **relevant and reliable**.  \n",
        "- **Lower confidence (< 0.3)** → The retrieved text **may not be relevant or sufficient**.  \n",
        "\n",
        "### 📌 **How is the Confidence Score Used?**  \n",
        "- If the retrieved document chunk has a **high confidence score**, the system can **directly answer the query**.  \n",
        "- If the retrieved document chunk has a **low confidence score**, the AI **enhances the query** using a **knowledge graph** and **retrieves better chunks**.\n",
        "\n",
        "---\n",
        "\n",
        "## 🤖 **Role of the AI Agent**  \n",
        "\n",
        "The **AI Agent** acts as a **decision-maker** that chooses the **best answering approach** based on **confidence scores**.  \n",
        "\n",
        "### 🔹 **How the Agent Works**\n",
        "1. **User submits a query**.\n",
        "2. **Document chunks are retrieved** from the database.\n",
        "3. **Each chunk has an associated confidence score**.\n",
        "4. The AI agent **analyzes the confidence scores** and chooses:\n",
        "   - ✅ **Direct Answer** → If confidence is **high (≥ 0.5)**.\n",
        "   - 🔄 **Enhanced Answer** → If confidence is **low (< 0.3)**, it **rewrites the query** and **retrieves better chunks**.\n",
        "5. The chosen **answering tool is executed**, and the **final response** is provided.  \n",
        "\n",
        "---\n",
        "\n",
        "# What is Knowledge Graph\n",
        "\n",
        "A **Knowledge Graph** is a structured representation of information that connects data points using relationships. It organizes and links concepts, entities, and facts in a way that allows machines (like AI) to understand and reason about the data.\n",
        "\n",
        "## Key Components of a Knowledge Graph\n",
        "1. **Entities (Nodes)** – Objects or concepts (e.g., a company, a contract, a product).\n",
        "2. **Relationships (Edges)** – Connections between entities (e.g., \"Customer **has** a Master Agreement\").\n",
        "3. **Attributes (Properties)** – Details about entities (e.g., \"Contract Start Date: Jan 2024\").\n",
        "\n",
        "## Example of a Simple Knowledge Graph\n",
        "\n",
        "### 📌 Entities:\n",
        "- **Customer**: ABC Corp\n",
        "- **Master Agreement**: Contract\n",
        "- **Service Order**: Specific service agreement\n",
        "\n",
        "### 📌 Relationships:\n",
        "- `ABC Corp → has → Master Agreement`\n",
        "- `Master Agreement → includes → Service Order`\n",
        "\n",
        "## Why Use a Knowledge Graph?\n",
        "- 🚀 Helps AI understand context better\n",
        "- 🔍 Improves search and query responses\n",
        "- 🔗 Connects scattered information for better decision-making\n",
        "\n",
        "# NOTE\n",
        "# We are using a dummy knowledge graph with respect to three terms:\n",
        "\n",
        "- **Customer**:\n",
        "- **Master Agreement**:\n",
        "- **Service Order**:\n",
        "\n",
        "# If you are using a query different from it, then you have to provide your context to the knowledge graph as well.\n",
        "---\n",
        "\n",
        "# 🎯 **Final Outcome**\n",
        "- If the retrieved document is **relevant**, the AI answers immediately.  \n",
        "- If the information is **uncertain**, the AI **optimizes** the search before answering.  \n",
        "- The AI agent makes **independent decisions** for the best response. 🚀  \n",
        "\n",
        "This **smart decision-making** process makes the AI **more intelligent and reliable** for answering document-based queries. 📖✨\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ZfeLdybzU5VW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c00e9e81-a00b-45f6-8547-902ad06e9dd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-19fd28b9f0ed>:90: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
            "  agent = initialize_agent(\n"
          ]
        }
      ],
      "source": [
        "# Step 5: Enhanced query processing with autonomous agent\n",
        "class QueryInput(BaseModel):\n",
        "    query: str = Field(description=\"User's original question\")\n",
        "    chunks: List[Dict] = Field(description=\"Retrieved document chunks with confidence scores\")\n",
        "\n",
        "def retrieve_chunks(query: str) -> List[Dict]:\n",
        "    collection = chroma_client.get_collection(\"doc_collection\")\n",
        "    results = collection.query(\n",
        "        query_texts=[query],\n",
        "        n_results=1,\n",
        "        include=['documents', 'metadatas']\n",
        "    )\n",
        "\n",
        "    # Ensure metadata is returned and handle cases where it's missing\n",
        "    documents = results['documents'][0]\n",
        "    metadatas = results.get('metadatas', [[{}] * len(documents)])[0]  # Default to empty dicts if metadata is missing\n",
        "\n",
        "    # Create chunks with actual metadata and confidence scores\n",
        "    chunks = [\n",
        "        {\"text\": doc, \"metadata\": meta}\n",
        "        for doc, meta in zip(documents, metadatas)\n",
        "    ]\n",
        "\n",
        "    return chunks\n",
        "\n",
        "def knowledge_graph(query: str) -> str:\n",
        "    # Enhanced knowledge graph mappings\n",
        "    kg_mappings = {\n",
        "        \"customer\": \"Company Name Referenced in Master Agreement Only\",\n",
        "        \"Master Agreement\": \"Contract\",\n",
        "        \"Service Order\": \"Service Agreement\",\n",
        "        \"name of the Customer\": \"Company Name Referenced in Master Agreement Only\",\n",
        "        # Add case variations or use case-insensitive comparison\n",
        "        \"Name Of the Customer\": \"Company Name Referenced in Master Agreement Only\"\n",
        "    }\n",
        "\n",
        "    # Alternatively, use case-insensitive replacement:\n",
        "    enhanced_query = query\n",
        "    for term, replacement in kg_mappings.items():\n",
        "        pattern = re.compile(re.escape(term), re.IGNORECASE)\n",
        "        enhanced_query = pattern.sub(replacement, enhanced_query)\n",
        "\n",
        "    return enhanced_query\n",
        "\n",
        "def base_answer(input: QueryInput) -> str:\n",
        "    context = \"\\n\\n\".join([chunk[\"text\"] for chunk in input.chunks])\n",
        "    prompt = f\"Answer: {input.query}\\nContext:\\n{context}\"\n",
        "    answer = llm(prompt)\n",
        "    return f\"Answer: {answer}\"\n",
        "\n",
        "def enhanced_answer(input: QueryInput) -> str:\n",
        "    enhanced_query = knowledge_graph(input.query)\n",
        "    enhanced_chunks = retrieve_chunks(enhanced_query)\n",
        "    context = \"\\n\\n\".join([chunk[\"text\"] for chunk in enhanced_chunks])\n",
        "    prompt = f\"Answer: {enhanced_query}\\nContext:\\n{context}\"\n",
        "    answer = llm(prompt)\n",
        "    return f\"Optimized Answer: {answer}\"\n",
        "\n",
        "\n",
        "# Define Tools\n",
        "tools = [\n",
        "    StructuredTool.from_function(\n",
        "        name=\"DirectAnswer\",\n",
        "        description=\"Use this when the retrieved chunks have high confidence scores (>= 0.5) and sufficient context to directly answer the query.\",\n",
        "        func=base_answer\n",
        "    ),\n",
        "    StructuredTool.from_function(\n",
        "        name=\"EnhancedAnswer\",\n",
        "        description=\"Use this when the retrieved chunks have low confidence scores (< 0.3) or insufficient context, and the query needs to be enhanced using a knowledge graph.\",\n",
        "        func=enhanced_answer\n",
        "    )\n",
        "]\n",
        "\n",
        "# Initialize the agent with a custom prompt\n",
        "agent_prompt = \"\"\"You are an intelligent assistant that decides how to answer user queries based on the context and confidence scores of retrieved document chunks.\n",
        "\n",
        "Here are the tools available to you:\n",
        "1. DirectAnswer: Use this when the retrieved chunks have high confidence scores (>= 0.5) and sufficient context to directly answer the query.\n",
        "2. EnhancedAnswer: Use this when the retrieved chunks have low confidence scores (< 0.3) or insufficient context, and the query needs to be enhanced using a knowledge graph.\n",
        "\n",
        "Your task is to analyze the query, retrieved chunks, and their confidence scores, and decide which tool to use. Provide a reason for your decision.\n",
        "\n",
        "Query: {query}\n",
        "Retrieved Chunks: {chunks}\n",
        "\n",
        "Decision: Which tool should be used? Respond in the following format:\n",
        "Tool: [DirectAnswer or EnhancedAnswer]\n",
        "Reason: [Your reasoning]\"\"\"\n",
        "\n",
        "agent = initialize_agent(\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    agent=\"structured-chat-zero-shot-react-description\",\n",
        "    verbose=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_aaAiW68hiqJ"
      },
      "source": [
        "# 📝 **Step 6: Query Interface with Autonomous Decision-Making**  \n",
        "\n",
        "This step introduces an **interactive query interface** that allows users to input their questions.  \n",
        "The AI agent **analyzes** the query, **retrieves relevant document chunks**, and **decides how to answer**  \n",
        "based on confidence scores. The decision-making is fully **autonomous**, ensuring **optimized responses**.\n",
        "\n",
        "---\n",
        "\n",
        "## 🎯 **How the Query Interface Works**  \n",
        "\n",
        "### 🔹 **User Input & Query Submission**  \n",
        "- You have to enters their query in the input field (`query_input`).\n",
        "- Clicking the \"Submit\" button (`submit_btn`) triggers the `handle_query` function.\n",
        "\n",
        "# 🔍 Step-by-Step Query Processing Flow\n",
        "**1️⃣ Step 1: Query Asked**\n",
        "- The user inputs a query.\n",
        "- The query is displayed in a notification box for reference.\n",
        "\n",
        "**2️⃣ Step 2: Retrieve Relevant Chunks**\n",
        "- The query is searched in the document database (ChromaDB).\n",
        "- The most relevant text chunks are retrieved, along with their confidence scores.\n",
        "- Retrieved chunks are displayed in a green notification box.\n",
        "\n",
        "**3️⃣ Step 3: Generate an Initial (Poor) Answer**\n",
        "- The system tries to generate an answer from the retrieved chunks.\n",
        "- This is an unoptimized response that might be incorrect due to low confidence scores.\n",
        "- The poor answer is displayed in a red notification box.\n",
        "\n",
        "**4️⃣ Step 4: AI Agent Decision**\n",
        "- The AI agent analyzes the retrieved chunks and confidence scores.\n",
        "- It decides whether to:\n",
        "  - Use the DirectAnswer tool (if confidence scores are high).\n",
        "  - Use the EnhancedAnswer tool (if confidence scores are low).\n",
        "- The agent's decision is displayed in a magenta notification box.\n",
        "\n",
        "**5️⃣ Step 5: Generate the Final Answer**\n",
        "\n",
        "✅ If the agent chooses \"DirectAnswer\"\n",
        "- The initial answer is used without modifications.\n",
        "\n",
        "✅ If the agent chooses \"EnhancedAnswer\"\n",
        "- The query is refined by agnet using a Knowledge Graph.\n",
        "-A new set of relevant document chunks is retrieved.\n",
        "- A more optimized answer is generated.\n",
        "\n",
        "# 🏁 How to Use the Query Interface?\n",
        "1️⃣ Enter your question in the input box.\n",
        "\n",
        "```text\n",
        "What is the name of the Customer ?\n",
        "```\n",
        "\n",
        "2️⃣ Click \"Submit\" to process the query.\n",
        "\n",
        "3️⃣ The system will retrieve relevant document chunks and evaluate confidence scores.\n",
        "\n",
        "4️⃣ The AI agent decides whether to give a direct answer or enhance the query using a Knowledge Graph.\n",
        "\n",
        "5️⃣ The final answer is displayed, either as a Direct Answer or an Optimized Answer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "1751d890cd77404384a73db788133cef",
            "a4632857da764d15a814b50ccba5b8f7",
            "371640502d514cfebf473c51ddcbb73a",
            "4170071a9f3149c8a18c0d25708d5558",
            "fe11a6ec32cb455bb5bd0f19e44a7f5d",
            "0e88e470f6634ddf9c928569ba30f0a8",
            "f6a68b0221b14c979183b2a4b0ef510a",
            "e851fb6833b74bf4bbec4cc23e72ae12"
          ]
        },
        "collapsed": true,
        "id": "JORFQMonVaFK",
        "outputId": "e881f7fa-6080-49ef-c2e5-a81d3f859b18"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Text(value='', placeholder='Enter your query')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1751d890cd77404384a73db788133cef"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Button(description='Submit', style=ButtonStyle())"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4170071a9f3149c8a18c0d25708d5558"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f6a68b0221b14c979183b2a4b0ef510a"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import re\n",
        "# Step 6: Query interface with autonomous decision-making\n",
        "query_input = widgets.Text(placeholder=\"Enter your query\")\n",
        "submit_btn = widgets.Button(description=\"Submit\")\n",
        "query_output = widgets.Output()\n",
        "\n",
        "def handle_query(b):\n",
        "    with query_output:\n",
        "        clear_output()\n",
        "        query = query_input.value\n",
        "\n",
        "        # Step 1: Query Asked\n",
        "        print(boxen(f\"QUERY ASKED:\\n{query}\", title=\"Step 1: Query Asked\", color=\"blue\"))\n",
        "\n",
        "        # Step 2: Retrieve Chunks\n",
        "        chunks = retrieve_chunks(query)\n",
        "        print(boxen(\n",
        "            f\"RETRIEVED CHUNKS:\\n\" +\n",
        "            \"\\n\".join([f\"Chunk {i+1}: {chunk['text']}\"\n",
        "                       for i, chunk in enumerate(chunks)]),\n",
        "            title=\"Step 2: Retrieved Chunks\", color=\"green\"\n",
        "        ))\n",
        "\n",
        "        # Step 3: Generate and Display Poor Answer\n",
        "        poor_answer = base_answer(QueryInput(query=query, chunks=chunks))\n",
        "        print(boxen(\n",
        "            f\"POOR ANSWER (Initial Attempt):\\n{poor_answer}\",\n",
        "            title=\"Step 3: Poor Answer\", color=\"red\"\n",
        "        ))\n",
        "\n",
        "        # Step 4: Let the Agent Decide Which Tool to Use\n",
        "        decision_output = llm(agent_prompt.format(query=query, chunks=chunks))\n",
        "        decision = decision_output.split(\"Tool: \")[1].split(\"\\n\")[0].strip()  # Extract tool\n",
        "        reason = decision_output.split(\"Reason: \")[1].strip()  # Extract reason\n",
        "        print(boxen(\n",
        "            f\"AGENT DECISION:\\nTool: KNOWLEDGE GRAPH\\nReason: {reason}\",\n",
        "            title=\"Step 4: Agent Decision\", color=\"magenta\"\n",
        "        ))\n",
        "\n",
        "        # Step 5: Execute the Chosen Tool\n",
        "        if \"DirectAnswer\" in decision:\n",
        "            response = base_answer(QueryInput(query=query, chunks=chunks))\n",
        "            print(boxen(\n",
        "                f\"DIRECT ANSWER:\\n{response}\",\n",
        "                title=\"Step 5: Direct Answer\", color=\"yellow\"\n",
        "            ))\n",
        "        elif \"EnhancedAnswer\" in decision:\n",
        "            print(boxen(\n",
        "                \"USING KNOWLEDGE GRAPH TO ENHANCE QUERY...\",\n",
        "                title=\"Step 5: Knowledge Graph Enhancement\", color=\"cyan\"\n",
        "            ))\n",
        "            enhanced_query = knowledge_graph(query)\n",
        "            print(boxen(\n",
        "                f\"ENHANCED QUERY:\\n{enhanced_query}\",\n",
        "                title=\"Step 5: Enhanced Query\", color=\"cyan\"\n",
        "            ))\n",
        "            enhanced_chunks = retrieve_chunks(enhanced_query)\n",
        "            response = enhanced_answer(QueryInput(query=enhanced_query, chunks=enhanced_chunks))\n",
        "            print(boxen(\n",
        "                f\"FINAL OPTIMIZED ANSWER:\\n{response}\",\n",
        "                title=\"Step 5: Final Optimized Answer\", color=\"green\"\n",
        "            ))\n",
        "        else:\n",
        "            print(boxen(\n",
        "                \"Unable to determine the appropriate tool. Using default answer.\",\n",
        "                title=\"Step 5: Default Answer\", color=\"red\"\n",
        "            ))\n",
        "\n",
        "\n",
        "display(query_input, submit_btn, query_output)\n",
        "submit_btn.on_click(handle_query)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "61fa487e09f146df858e5ff852852817": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FileUploadModel",
          "model_module_version": "1.5.0",
          "state": {
            "_counter": 1,
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FileUploadModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "FileUploadView",
            "accept": ".pdf",
            "button_style": "",
            "data": [
              null
            ],
            "description": "Upload",
            "description_tooltip": null,
            "disabled": false,
            "error": "",
            "icon": "upload",
            "layout": "IPY_MODEL_fcd2c04e736747f9a4aaefd2e3a8e5d8",
            "metadata": [
              {
                "name": "Morningstar Inc MSA.pdf",
                "type": "application/pdf",
                "size": 248159,
                "lastModified": 1744443511642
              }
            ],
            "multiple": false,
            "style": "IPY_MODEL_42009fd475574ef48de40ebe36f4961f"
          }
        },
        "fcd2c04e736747f9a4aaefd2e3a8e5d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42009fd475574ef48de40ebe36f4961f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "234000427b2041f0a625cdc99ed45372": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Process File",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_208e2d02c0774f04bb470be2d81e1bfa",
            "style": "IPY_MODEL_3701175e40864740989bb733401f6ca4",
            "tooltip": ""
          }
        },
        "208e2d02c0774f04bb470be2d81e1bfa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3701175e40864740989bb733401f6ca4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "643332e54133406ea09ec5c7a36b3c16": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_99a9dcae2e874181ab7cea927ec48a11",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
                },
                "metadata": {}
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "\u001b[32m╭─\u001b[0m\u001b[32m Success \u001b[0m\u001b[32m───────────────────────────\u001b[0m\u001b[32m─╮\u001b[0m                                                                           \n",
                  "\u001b[32m│\u001b[0mFile processed with confidence scores!\u001b[32m│\u001b[0m                                                                           \n",
                  "\u001b[32m╰──────────────────────────────────────╯\u001b[0m                                                                           \n",
                  "\n"
                ]
              }
            ]
          }
        },
        "99a9dcae2e874181ab7cea927ec48a11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1751d890cd77404384a73db788133cef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_a4632857da764d15a814b50ccba5b8f7",
            "placeholder": "Enter your query",
            "style": "IPY_MODEL_371640502d514cfebf473c51ddcbb73a",
            "value": "What is the name of the Customer ?"
          }
        },
        "a4632857da764d15a814b50ccba5b8f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "371640502d514cfebf473c51ddcbb73a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4170071a9f3149c8a18c0d25708d5558": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Submit",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_fe11a6ec32cb455bb5bd0f19e44a7f5d",
            "style": "IPY_MODEL_0e88e470f6634ddf9c928569ba30f0a8",
            "tooltip": ""
          }
        },
        "fe11a6ec32cb455bb5bd0f19e44a7f5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e88e470f6634ddf9c928569ba30f0a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "f6a68b0221b14c979183b2a4b0ef510a": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_e851fb6833b74bf4bbec4cc23e72ae12",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
                },
                "metadata": {}
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "\u001b[34m╭─\u001b[0m\u001b[34m Step 1: Query Asked \u001b[0m\u001b[34m───────────\u001b[0m\u001b[34m─╮\u001b[0m                                                                               \n",
                  "\u001b[34m│\u001b[0mQUERY ASKED:                      \u001b[34m│\u001b[0m                                                                               \n",
                  "\u001b[34m│\u001b[0mWhat is the name of the Customer ?\u001b[34m│\u001b[0m                                                                               \n",
                  "\u001b[34m╰──────────────────────────────────╯\u001b[0m                                                                               \n",
                  "\n"
                ]
              },
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
                },
                "metadata": {}
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "\u001b[32m╭─\u001b[0m\u001b[32m Step 2: Retrieved Chunks \u001b[0m\u001b[32m────────────────────────────────────────────────────────────────────────────────────\u001b[0m\u001b[32m─╮\u001b[0m \n",
                  "\u001b[32m│\u001b[0mRETRIEVED CHUNKS:                                                                                               \u001b[32m│\u001b[0m \n",
                  "\u001b[32m│\u001b[0mChunk 1: purpose described in this Master Agreement and that Product License Agreement; and/or                  \u001b[32m│\u001b[0m \n",
                  "\u001b[32m│\u001b[0m(2)Execute one or more Morningstar Service Orders (each a \"Service Order'') by which Morningstar Provider       \u001b[32m│\u001b[0m \n",
                  "\u001b[32m│\u001b[0mmakes available, and Company Recipient is allowed to use pursuant to the terms of that Service Order and        \u001b[32m│\u001b[0m \n",
                  "\u001b[32m│\u001b[0mthis Master Agreement, certain extra-cost customization, development, consulting, research  related             \u001b[32m│\u001b[0m \n",
                  "\u001b[32m│\u001b[0mservices and/01'.back office services (individually and collectively, \"Special Services\"), all as more fully    \u001b[32m│\u001b[0m \n",
                  "\u001b[32m│\u001b[0mdescribed in the applicable Service Order.                                                                      \u001b[32m│\u001b[0m \n",
                  "\u001b[32m│\u001b[0m(b)Attribution and Use: Subject to Section 1(e) below and any additional terms contained in the relevant Product\u001b[32m│\u001b[0m \n",
                  "\u001b[32m│\u001b[0mLicense Agreement/Service Order, Company Recipient will clearly reference the Morningstar Provider as the       \u001b[32m│\u001b[0m \n",
                  "\u001b[32m│\u001b[0mprovider of the Product/Special Services in all Company Recipient advertising and marketing materials and       \u001b[32m│\u001b[0m \n",
                  "\u001b[32m│\u001b[0mpublic communications referencing the Product/Special Services. If Company Recipient displays all or a          \u001b[32m│\u001b[0m \n",
                  "\u001b[32m╰────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m \n",
                  "\n"
                ]
              },
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
                },
                "metadata": {}
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "\u001b[31m╭─\u001b[0m\u001b[31m Step 3: Poor Answer \u001b[0m\u001b[31m───────────────────────────────────────────────────────────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m       \n",
                  "\u001b[31m│\u001b[0mPOOR ANSWER (Initial Attempt):                                                                            \u001b[31m│\u001b[0m       \n",
                  "\u001b[31m│\u001b[0mAnswer:                                                                                                   \u001b[31m│\u001b[0m       \n",
                  "\u001b[31m│\u001b[0mportion of the Product/Special Services on a Company Recipient website, Company Recipient will provide    \u001b[31m│\u001b[0m       \n",
                  "\u001b[31m│\u001b[0mappropriate attribution to Morningstar Provider on the same webpage(s) as the Product/Special Services are\u001b[31m│\u001b[0m       \n",
                  "\u001b[31m│\u001b[0mdisplayed.                                                                                                \u001b[31m│\u001b[0m       \n",
                  "\u001b[31m│\u001b[0m                                                                                                          \u001b[31m│\u001b[0m       \n",
                  "\u001b[31m│\u001b[0mWho is the Customer?                                                                                      \u001b[31m│\u001b[0m       \n",
                  "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m       \n",
                  "\n"
                ]
              },
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
                },
                "metadata": {}
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "\u001b[35m╭─\u001b[0m\u001b[35m Step 4: Agent Decision \u001b[0m\u001b[35m───────────────────────────────────────────────────────────────────────────────────────\u001b[0m\u001b[35m─╮\u001b[0m\n",
                  "\u001b[35m│\u001b[0mAGENT DECISION:                                                                                                  \u001b[35m│\u001b[0m\n",
                  "\u001b[35m│\u001b[0mTool: KNOWLEDGE GRAPH                                                                                            \u001b[35m│\u001b[0m\n",
                  "\u001b[35m│\u001b[0mReason: The retrieved chunk has a low confidence score of 0.0415, indicating that it may not have enough context \u001b[35m│\u001b[0m\n",
                  "\u001b[35m│\u001b[0mto directly answer the query. Additionally, the chunk contains a lot of technical and legal jargon, making it    \u001b[35m│\u001b[0m\n",
                  "\u001b[35m│\u001b[0mdifficult for a direct answer to be extracted. Using a knowledge graph to enhance the query would provide more   \u001b[35m│\u001b[0m\n",
                  "\u001b[35m│\u001b[0maccurate and relevant information for the user.                                                                  \u001b[35m│\u001b[0m\n",
                  "\u001b[35m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
                  "\n"
                ]
              },
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
                },
                "metadata": {}
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "\u001b[36m╭─\u001b[0m\u001b[36m Step 5: Knowledge Graph Enhancement \u001b[0m\u001b[36m──\u001b[0m\u001b[36m─╮\u001b[0m                                                                        \n",
                  "\u001b[36m│\u001b[0mUSING KNOWLEDGE GRAPH TO ENHANCE QUERY...\u001b[36m│\u001b[0m                                                                        \n",
                  "\u001b[36m╰─────────────────────────────────────────╯\u001b[0m                                                                        \n",
                  "\n"
                ]
              },
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
                },
                "metadata": {}
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "\u001b[36m╭─\u001b[0m\u001b[36m Step 5: Enhanced Query \u001b[0m\u001b[36m────────────────────────────────────────\u001b[0m\u001b[36m─╮\u001b[0m                                               \n",
                  "\u001b[36m│\u001b[0mENHANCED QUERY:                                                   \u001b[36m│\u001b[0m                                               \n",
                  "\u001b[36m│\u001b[0mWhat is the name of the Company Name Referenced in Contract Only ?\u001b[36m│\u001b[0m                                               \n",
                  "\u001b[36m╰──────────────────────────────────────────────────────────────────╯\u001b[0m                                               \n",
                  "\n"
                ]
              },
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
                },
                "metadata": {}
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "\u001b[32m╭─\u001b[0m\u001b[32m Step 5: Final Optimized Answer \u001b[0m\u001b[32m─────────────────────────\u001b[0m\u001b[32m─╮\u001b[0m                                                      \n",
                  "\u001b[32m│\u001b[0mFINAL OPTIMIZED ANSWER:                                    \u001b[32m│\u001b[0m                                                      \n",
                  "\u001b[32m│\u001b[0mOptimized Answer:                                          \u001b[32m│\u001b[0m                                                      \n",
                  "\u001b[32m│\u001b[0m                                                           \u001b[32m│\u001b[0m                                                      \n",
                  "\u001b[32m│\u001b[0mThe company name referenced in the contract is Morningstar.\u001b[32m│\u001b[0m                                                      \n",
                  "\u001b[32m╰───────────────────────────────────────────────────────────╯\u001b[0m                                                      \n",
                  "\n"
                ]
              }
            ]
          }
        },
        "e851fb6833b74bf4bbec4cc23e72ae12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}