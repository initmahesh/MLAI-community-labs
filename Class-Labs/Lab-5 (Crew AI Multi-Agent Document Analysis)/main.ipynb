{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install crewai PyPDF2 openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install --upgrade PyPDF2 crewai gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install ratelimit bleach python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key Elements\n",
    "\n",
    "Enterprise-grade document analysis system leveraging state-of-the-art LLMs and agent-based architecture.\n",
    "This system implements a sophisticated multi-agent approach for document processing, analysis, and interactive querying.\n",
    "\n",
    "Key Features:\n",
    "- Distributed agent-based processing\n",
    "- Real-time analysis pipeline\n",
    "- Fault-tolerant error handling\n",
    "- Stateful document chat capabilities\n",
    "- Progress monitoring and callback system\n",
    "\n",
    "Architecture Overview:\n",
    "1. Document Extraction Layer\n",
    "2. Analysis Pipeline Layer\n",
    "3. Interactive Query Layer\n",
    "4. Presentation Layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required installations - run in a cell:\n",
    "! pip install agentops plotly ipywidgets PyPDF2 crewai pandas\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U agentops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install --upgrade agentops\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import traceback\n",
    "from crewai import Agent, Task, Crew\n",
    "import PyPDF2\n",
    "import json\n",
    "import gradio as gr\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Any\n",
    "from queue import Queue\n",
    "from threading import Thread\n",
    "\n",
    "def extract_text_from_pdf(pdf_file):\n",
    "    \"\"\"Extract text from a PDF file.\"\"\"\n",
    "    try:\n",
    "        pdf_reader = PyPDF2.PdfReader(pdf_file.name)\n",
    "        text = \"\"\n",
    "        for page in pdf_reader.pages:\n",
    "            text += page.extract_text()\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Error extracting text from PDF: {str(e)}\")\n",
    "\n",
    "\n",
    "# Default reference data\n",
    "reference_data = {\n",
    "    \"limitation of liability\": \"30 days\",\n",
    "    \"owner expiry date\": \"30 days\",\n",
    "    \"notice period\": \"30 days\",\n",
    "    \"agreement duration\": \"12 months\",\n",
    "    \"payment terms\": \"30 days\",\n",
    "    \"confidentiality period\": \"3 years\",\n",
    "    \"insurance coverage\": \"$1,000,000\",\n",
    "    \"maximum monthly hours\": \"120\"\n",
    "}\n",
    "\n",
    "class OutputManager:\n",
    "    def __init__(self):\n",
    "        self.output_queue = Queue()\n",
    "        self.agent_progress_queue = Queue()\n",
    "        self.verbose_queue = Queue()  # New queue for verbose output\n",
    "        self.process_flow_queue = Queue()  # New queue for process flow\n",
    "        self.is_running = True\n",
    "        self.output_thread = Thread(target=self._process_output)\n",
    "        self.output_thread.start()\n",
    "        self.callbacks = []\n",
    "        self.agent_progress_callbacks = []\n",
    "        self.verbose_callbacks = []  # New callbacks for verbose output\n",
    "        self.process_flow_callbacks = []  # New callbacks for process flow\n",
    "\n",
    "    def _process_output(self):\n",
    "        while self.is_running:\n",
    "            # Process regular output\n",
    "            if not self.output_queue.empty():\n",
    "                output = self.output_queue.get()\n",
    "                for callback in self.callbacks:\n",
    "                    callback(output)\n",
    "            \n",
    "            # Process agent progress\n",
    "            if not self.agent_progress_queue.empty():\n",
    "                progress = self.agent_progress_queue.get()\n",
    "                for callback in self.agent_progress_callbacks:\n",
    "                    callback(progress)\n",
    "            \n",
    "            # Process verbose output\n",
    "            if not self.verbose_queue.empty():\n",
    "                verbose = self.verbose_queue.get()\n",
    "                for callback in self.verbose_callbacks:\n",
    "                    callback(verbose)\n",
    "            \n",
    "            # Process flow visualization\n",
    "            if not self.process_flow_queue.empty():\n",
    "                flow = self.process_flow_queue.get()\n",
    "                for callback in self.process_flow_callbacks:\n",
    "                    callback(flow)\n",
    "            \n",
    "            time.sleep(0.1)\n",
    "\n",
    "    def add_output(self, output: str):\n",
    "        self.output_queue.put(output)\n",
    "\n",
    "    def add_agent_progress(self, progress: str):\n",
    "        self.agent_progress_queue.put(progress)\n",
    "\n",
    "    def add_verbose_output(self, verbose: str):\n",
    "        self.verbose_queue.put(f\"[{datetime.now().strftime('%H:%M:%S')}] {verbose}\")\n",
    "\n",
    "    def add_process_flow(self, flow: str):\n",
    "        self.process_flow_queue.put(f\"‚Üí {flow}\")\n",
    "\n",
    "    def register_callback(self, callback):\n",
    "        self.callbacks.append(callback)\n",
    "\n",
    "    def register_agent_progress_callback(self, callback):\n",
    "        self.agent_progress_callbacks.append(callback)\n",
    "\n",
    "    def register_verbose_callback(self, callback):\n",
    "        self.verbose_callbacks.append(callback)\n",
    "\n",
    "    def register_process_flow_callback(self, callback):\n",
    "        self.process_flow_callbacks.append(callback)\n",
    "\n",
    "    def stop(self):\n",
    "        self.is_running = False\n",
    "        self.output_thread.join()\n",
    "\n",
    "class MemoryTracker:\n",
    "    def __init__(self):\n",
    "        self.memory_logs: Dict[str, List[Dict[str, Any]]] = {}\n",
    "        \n",
    "    def log_memory_event(self, agent_name: str, event_type: str, content: str):\n",
    "        timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        \n",
    "        if agent_name not in self.memory_logs:\n",
    "            self.memory_logs[agent_name] = []\n",
    "            \n",
    "        event = {\n",
    "            \"timestamp\": timestamp,\n",
    "            \"type\": event_type,\n",
    "            \"content\": content\n",
    "        }\n",
    "        \n",
    "        self.memory_logs[agent_name].append(event)\n",
    "        return event\n",
    "    \n",
    "    def get_memory_summary(self, agent_name: str = None) -> str:\n",
    "        if agent_name:\n",
    "            if agent_name not in self.memory_logs:\n",
    "                return f\"No memory events logged for {agent_name}\"\n",
    "            \n",
    "            summary = f\"Memory Events for {agent_name}:\\n\\n\"\n",
    "            for event in self.memory_logs[agent_name]:\n",
    "                summary += f\"[{event['timestamp']}] {event['type']}\\n{event['content']}\\n\\n\"\n",
    "            return summary\n",
    "        else:\n",
    "            full_summary = \"Complete Memory Status:\\n\\n\"\n",
    "            for agent in self.memory_logs.keys():\n",
    "                full_summary += f\"=== {agent} ===\\n\"\n",
    "                full_summary += self.get_memory_summary(agent) + \"\\n\"\n",
    "            return full_summary\n",
    "\n",
    "class DocumentAnalyzerCrew:\n",
    "    def __init__(self, document_text, reference_data, api_key, output_manager):\n",
    "        os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "        self.output_manager = output_manager\n",
    "        self.memory_tracker = MemoryTracker()\n",
    "        \n",
    "        self.text_extraction_agent = Agent(\n",
    "            role=\"Text Extraction Specialist\",\n",
    "            goal=\"Extract precise key information from documents\",\n",
    "            backstory=\"An expert in parsing complex documents and identifying critical information with high accuracy\",\n",
    "            verbose=True,\n",
    "            allow_delegation=False,\n",
    "            memory=True\n",
    "        )\n",
    "\n",
    "        self.comparison_agent = Agent(\n",
    "            role=\"Document Comparison Expert\",\n",
    "            goal=\"Compare extracted document data against reference standards\",\n",
    "            backstory=\"A meticulous analyst specializing in identifying discrepancies between document contents and expected standards\",\n",
    "            verbose=True,\n",
    "            allow_delegation=False,\n",
    "            memory=True\n",
    "        )\n",
    "\n",
    "        self.reporting_agent = Agent(\n",
    "            role=\"Detailed Report Generator\",\n",
    "            goal=\"Create comprehensive and clear analysis reports\",\n",
    "            backstory=\"A skilled communicator who transforms technical findings into clear, actionable insights\",\n",
    "            verbose=True,\n",
    "            allow_delegation=False,\n",
    "            memory=True\n",
    "        )\n",
    "\n",
    "        self.document_text = document_text\n",
    "        self.reference_data = reference_data\n",
    "\n",
    "    def analyze_document(self):\n",
    "        try:\n",
    "            # Extraction Phase\n",
    "            self.output_manager.add_output(\"üîç Starting Text Extraction Phase...\")\n",
    "            self.output_manager.add_agent_progress(\"ü§ñ Text Extraction Agent: Beginning document analysis...\")\n",
    "            self.output_manager.add_process_flow(\"Initiating Text Extraction Phase\")\n",
    "            \n",
    "            event = self.memory_tracker.log_memory_event(\n",
    "                self.text_extraction_agent.role,\n",
    "                \"Task Start\",\n",
    "                \"Initiating document extraction\"\n",
    "            )\n",
    "            self.output_manager.add_verbose_output(f\"Memory Event: {event['type']} - {event['content']}\")\n",
    "\n",
    "            extraction_task = Task(\n",
    "                description=f\"\"\"\n",
    "                Extract key information from the document text:\n",
    "                Document Content (first 2000 chars): {self.document_text[:2000]}\n",
    "                \n",
    "                Focus on these key points:\n",
    "                {', '.join(self.reference_data.keys())}\n",
    "                \"\"\",\n",
    "                agent=self.text_extraction_agent,\n",
    "                expected_output=\"Dictionary containing extracted key-value pairs from the document\"\n",
    "            )\n",
    "\n",
    "            extraction_crew = Crew(\n",
    "                agents=[self.text_extraction_agent],\n",
    "                tasks=[extraction_task],\n",
    "                verbose=True\n",
    "            )\n",
    "\n",
    "            self.output_manager.add_agent_progress(\"üìù Text Extraction Agent: Processing document content...\")\n",
    "            self.output_manager.add_process_flow(\"Executing Text Extraction\")\n",
    "            extraction_result = extraction_crew.kickoff()\n",
    "            self.output_manager.add_output(\"‚úÖ Text Extraction Complete\")\n",
    "            self.output_manager.add_agent_progress(\"‚úÖ Text Extraction Agent: Completed extraction process\")\n",
    "            self.output_manager.add_process_flow(\"Text Extraction Complete\")\n",
    "            \n",
    "            event = self.memory_tracker.log_memory_event(\n",
    "                self.text_extraction_agent.role,\n",
    "                \"Task Complete\",\n",
    "                f\"Extraction Results: {str(extraction_result)[:200]}...\"\n",
    "            )\n",
    "            self.output_manager.add_verbose_output(f\"Memory Event: {event['type']} - {event['content']}\")\n",
    "\n",
    "            # Comparison Phase\n",
    "            self.output_manager.add_output(\"üî¨ Starting Comparison Analysis...\")\n",
    "            self.output_manager.add_agent_progress(\"ü§ñ Comparison Agent: Starting comparison analysis...\")\n",
    "            self.output_manager.add_process_flow(\"Initiating Comparison Phase\")\n",
    "            \n",
    "            event = self.memory_tracker.log_memory_event(\n",
    "                self.comparison_agent.role,\n",
    "                \"Task Start\",\n",
    "                \"Initiating comparison analysis\"\n",
    "            )\n",
    "            self.output_manager.add_verbose_output(f\"Memory Event: {event['type']} - {event['content']}\")\n",
    "\n",
    "            comparison_task = Task(\n",
    "                description=f\"\"\"\n",
    "                Compare extracted data against reference standards:\n",
    "                Reference Data: {json.dumps(self.reference_data, indent=2)}\n",
    "                Extracted Data: {extraction_result}\n",
    "                \"\"\",\n",
    "                agent=self.comparison_agent,\n",
    "                expected_output=\"Detailed comparison report highlighting matches and discrepancies\"\n",
    "            )\n",
    "\n",
    "            comparison_crew = Crew(\n",
    "                agents=[self.comparison_agent],\n",
    "                tasks=[comparison_task],\n",
    "                verbose=True\n",
    "            )\n",
    "\n",
    "            self.output_manager.add_agent_progress(\"üìä Comparison Agent: Analyzing data differences...\")\n",
    "            self.output_manager.add_process_flow(\"Executing Comparison Analysis\")\n",
    "            comparison_result = comparison_crew.kickoff()\n",
    "            self.output_manager.add_output(\"‚úÖ Comparison Analysis Complete\")\n",
    "            self.output_manager.add_agent_progress(\"‚úÖ Comparison Agent: Completed analysis\")\n",
    "            self.output_manager.add_process_flow(\"Comparison Analysis Complete\")\n",
    "            \n",
    "            event = self.memory_tracker.log_memory_event(\n",
    "                self.comparison_agent.role,\n",
    "                \"Task Complete\",\n",
    "                f\"Comparison Results: {str(comparison_result)[:200]}...\"\n",
    "            )\n",
    "            self.output_manager.add_verbose_output(f\"Memory Event: {event['type']} - {event['content']}\")\n",
    "\n",
    "            # Reporting Phase\n",
    "            self.output_manager.add_output(\"üìù Generating Final Report...\")\n",
    "            self.output_manager.add_agent_progress(\"ü§ñ Report Generator: Starting report creation...\")\n",
    "            self.output_manager.add_process_flow(\"Initiating Report Generation\")\n",
    "            \n",
    "            event = self.memory_tracker.log_memory_event(\n",
    "                self.reporting_agent.role,\n",
    "                \"Task Start\",\n",
    "                \"Generating comprehensive report\"\n",
    "            )\n",
    "            self.output_manager.add_verbose_output(f\"Memory Event: {event['type']} - {event['content']}\")\n",
    "\n",
    "            reporting_task = Task(\n",
    "                description=f\"\"\"\n",
    "                Generate a comprehensive analysis report based on:\n",
    "                Extraction Results: {extraction_result}\n",
    "                Comparison Analysis: {comparison_result}\n",
    "                \n",
    "                Include:\n",
    "                1. Executive Summary\n",
    "                2. Key Findings\n",
    "                3. Detailed Analysis\n",
    "                4. Recommendations\n",
    "                \"\"\",\n",
    "                agent=self.reporting_agent,\n",
    "                expected_output=\"Comprehensive analysis report with findings and recommendations\"\n",
    "            )\n",
    "\n",
    "            reporting_crew = Crew(\n",
    "                agents=[self.reporting_agent],\n",
    "                tasks=[reporting_task],\n",
    "                verbose=True\n",
    "            )\n",
    "\n",
    "            self.output_manager.add_agent_progress(\"üìä Report Generator: Compiling findings and recommendations...\")\n",
    "            self.output_manager.add_process_flow(\"Executing Report Generation\")\n",
    "            final_report = reporting_crew.kickoff()\n",
    "            self.output_manager.add_output(\"‚úÖ Final Report Generated\")\n",
    "            self.output_manager.add_agent_progress(\"‚úÖ Report Generator: Report completed\")\n",
    "            self.output_manager.add_process_flow(\"Report Generation Complete\")\n",
    "            \n",
    "            event = self.memory_tracker.log_memory_event(\n",
    "                self.reporting_agent.role,\n",
    "                \"Task Complete\",\n",
    "                f\"Final Report: {str(final_report)[:200]}...\"\n",
    "            )\n",
    "            self.output_manager.add_verbose_output(f\"Memory Event: {event['type']} - {event['content']}\")\n",
    "\n",
    "            return str(extraction_result), str(comparison_result), str(final_report)\n",
    "\n",
    "        except Exception as e:\n",
    "            error_msg = f\"Analysis Error: {str(e)}\\n{traceback.format_exc()}\"\n",
    "            self.output_manager.add_output(f\"‚ùå Error: {error_msg}\")\n",
    "            self.output_manager.add_agent_progress(\"‚ùå Error occurred during analysis\")\n",
    "            self.output_manager.add_process_flow(\"Error in Analysis Process\")\n",
    "            self.output_manager.add_verbose_output(f\"Error: {error_msg}\")\n",
    "            return error_msg, error_msg, error_msg\n",
    "\n",
    "class DocumentChatCrew:\n",
    "    def __init__(self, document_report, api_key, output_manager):\n",
    "        os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "        self.output_manager = output_manager\n",
    "        self.memory_tracker = MemoryTracker()\n",
    "        \n",
    "        self.chat_agent = Agent(\n",
    "            role=\"Document Chat Specialist\",\n",
    "            goal=\"Provide accurate and contextual responses about the document\",\n",
    "            backstory=f\"\"\"Expert AI assistant analyzing this document report:\n",
    "            {document_report}\"\"\",\n",
    "            verbose=True,\n",
    "            allow_delegation=False,\n",
    "            memory=True\n",
    "        )\n",
    "        \n",
    "        self.document_report = document_report\n",
    "\n",
    "    def chat_with_document(self, user_message):\n",
    "        try:\n",
    "            self.output_manager.add_agent_progress(\"ü§ñ Chat Agent: Starting to process your question...\")\n",
    "            self.output_manager.add_process_flow(\"Initiating Chat Processing\")\n",
    "            \n",
    "            event = self.memory_tracker.log_memory_event(\n",
    "                self.chat_agent.role,\n",
    "                \"Chat Query\",\n",
    "                f\"User Question: {user_message}\"\n",
    "            )\n",
    "            self.output_manager.add_verbose_output(f\"Memory Event: {event['type']} - {event['content']}\")\n",
    "            \n",
    "            self.output_manager.add_agent_progress(\"ü§î Chat Agent: Analyzing document context and formulating response...\")\n",
    "            self.output_manager.add_process_flow(\"Analyzing Document Context\")\n",
    "            \n",
    "            chat_task = Task(\n",
    "                description=f\"\"\"\n",
    "                Based on this document context:\n",
    "                {self.document_report}\n",
    "                \n",
    "                Answer this user query:\n",
    "                {user_message}\n",
    "                \"\"\",\n",
    "                agent=self.chat_agent,\n",
    "                expected_output=\"Detailed response to user query based on document context\"\n",
    "            )\n",
    "\n",
    "            chat_crew = Crew(\n",
    "                agents=[self.chat_agent],\n",
    "                tasks=[chat_task],\n",
    "                verbose=True\n",
    "            )\n",
    "\n",
    "            self.output_manager.add_agent_progress(\"‚úçÔ∏è Chat Agent: Generating detailed response...\")\n",
    "            self.output_manager.add_process_flow(\"Generating Response\")\n",
    "            response = chat_crew.kickoff()\n",
    "            self.output_manager.add_agent_progress(\"‚úÖ Chat Agent: Response generated successfully!\")\n",
    "            self.output_manager.add_process_flow(\"Response Generation Complete\")\n",
    "            \n",
    "            event = self.memory_tracker.log_memory_event(\n",
    "                self.chat_agent.role,\n",
    "                \"Chat Response\",\n",
    "                f\"Response: {str(response)[:200]}...\"\n",
    "            )\n",
    "            self.output_manager.add_verbose_output(f\"Memory Event: {event['type']} - {event['content']}\")\n",
    "            \n",
    "            return str(response), self.memory_tracker.get_memory_summary(self.chat_agent.role)\n",
    "\n",
    "        except Exception as e:\n",
    "            error_msg = f\"Chat Error: {str(e)}\\n{traceback.format_exc()}\"\n",
    "            self.output_manager.add_agent_progress(\"‚ùå Chat Agent: Error occurred during processing\")\n",
    "            self.output_manager.add_process_flow(\"Error in Chat Process\")\n",
    "def launch_gradio_interface():\n",
    "    output_manager = OutputManager()\n",
    "    \n",
    "    with gr.Blocks(title=\"üìë Advanced Document Analysis System\", theme=gr.themes.Soft()) as demo:\n",
    "        # States\n",
    "        document_state = gr.State(None)\n",
    "        output_state = gr.State(\"\")\n",
    "        memory_state = gr.State(\"\")\n",
    "        verbose_state = gr.State(\"\")  # New state for verbose output\n",
    "        process_flow_state = gr.State(\"\")  # New state for process flow\n",
    "        \n",
    "        with gr.Tabs():\n",
    "            # Document Analysis Tab\n",
    "            with gr.TabItem(\"üìÑ Document Analysis\"):\n",
    "                gr.Markdown(\"\"\"\n",
    "                # üìÑ Intelligent Document Analysis\n",
    "                Upload a PDF document and let our AI agents analyze it in detail.\n",
    "                \"\"\")\n",
    "                \n",
    "                with gr.Row():\n",
    "                    with gr.Column(scale=1):\n",
    "                        api_key = gr.Textbox(\n",
    "                            label=\"OpenAI API Key\",\n",
    "                            type=\"password\",\n",
    "                            placeholder=\"Enter your OpenAI API key\"\n",
    "                        )\n",
    "                        pdf_file = gr.File(\n",
    "                            label=\"Upload PDF Document\",\n",
    "                            file_types=[\".pdf\"]\n",
    "                        )\n",
    "                        analyze_btn = gr.Button(\n",
    "                            \"üöÄ Start Analysis\",\n",
    "                            variant=\"primary\"\n",
    "                        )\n",
    "                \n",
    "                with gr.Row():\n",
    "                    with gr.Column(scale=2):\n",
    "                        with gr.Group():\n",
    "                            gr.Markdown(\"### üìä Analysis Progress\")\n",
    "                            extraction_status = gr.Textbox(\n",
    "                                label=\"Extraction Phase\",\n",
    "                                placeholder=\"Waiting to start...\",\n",
    "                                lines=2\n",
    "                            )\n",
    "                            comparison_status = gr.Textbox(\n",
    "                                label=\"Comparison Phase\",\n",
    "                                placeholder=\"Waiting to start...\",\n",
    "                                lines=2\n",
    "                            )\n",
    "                            report_status = gr.Textbox(\n",
    "                                label=\"Final Report\",\n",
    "                                placeholder=\"Waiting to start...\",\n",
    "                                lines=4\n",
    "                            )\n",
    "                \n",
    "                with gr.Row():\n",
    "                    with gr.Column(scale=1):\n",
    "                        verbose_output = gr.TextArea(\n",
    "                            label=\"üîç Real-time Agent Activity\",\n",
    "                            placeholder=\"Agent activities will appear here in real-time...\",\n",
    "                            lines=10,\n",
    "                            max_lines=15,\n",
    "                            interactive=False\n",
    "                        )\n",
    "                    with gr.Column(scale=1):\n",
    "                        memory_output = gr.TextArea(\n",
    "                            label=\"üß† Agent Memory Status\",\n",
    "                            placeholder=\"Agent memory events will be tracked here...\",\n",
    "                            lines=10,\n",
    "                            max_lines=15,\n",
    "                            interactive=False\n",
    "                        )\n",
    "                    with gr.Column(scale=1):\n",
    "                        agent_progress = gr.TextArea(\n",
    "                            label=\"üîÑ Agent Progress\",\n",
    "                            placeholder=\"Step-by-step agent progress will appear here...\",\n",
    "                            lines=10,\n",
    "                            max_lines=15,\n",
    "                            interactive=False\n",
    "                        )\n",
    "                \n",
    "                # New section for process flow visualization\n",
    "                with gr.Row():\n",
    "                    process_flow = gr.TextArea(\n",
    "                        label=\"‚ö° Process Flow Visualization\",\n",
    "                        placeholder=\"Step-by-step process flow will be shown here...\",\n",
    "                        lines=5,\n",
    "                        max_lines=10,\n",
    "                        interactive=False\n",
    "                    )\n",
    "            \n",
    "            # Document Chat Tab\n",
    "            with gr.TabItem(\"üí¨ Chat with Document\"):\n",
    "                gr.Markdown(\"\"\"\n",
    "                # üí¨ Interactive Document Chat\n",
    "                Ask questions about the analyzed document and get detailed responses.\n",
    "                \"\"\")\n",
    "                \n",
    "                with gr.Row():\n",
    "                    with gr.Column(scale=1):\n",
    "                        chat_message = gr.Textbox(\n",
    "                            label=\"Your Question\",\n",
    "                            placeholder=\"Ask anything about the document...\"\n",
    "                        )\n",
    "                        chat_btn = gr.Button(\n",
    "                            \"ü§ñ Ask Question\",\n",
    "                            variant=\"primary\"\n",
    "                        )\n",
    "                    \n",
    "                    with gr.Column(scale=2):\n",
    "                        chat_response = gr.TextArea(\n",
    "                            label=\"üí¨ AI Response\",\n",
    "                            placeholder=\"AI responses will appear here...\",\n",
    "                            lines=8\n",
    "                        )\n",
    "                        chat_memory = gr.TextArea(\n",
    "                            label=\"üß† Chat Memory Log\",\n",
    "                            placeholder=\"Chat agent memory events will be tracked here...\",\n",
    "                            lines=8\n",
    "                        )\n",
    "                        chat_agent_progress = gr.TextArea(\n",
    "                            label=\"üîÑ Chat Agent Progress\",\n",
    "                            placeholder=\"Step-by-step chat agent progress will appear here...\",\n",
    "                            lines=8,\n",
    "                            interactive=False\n",
    "                        )\n",
    "                \n",
    "                # New section for chat process flow visualization\n",
    "                with gr.Row():\n",
    "                    chat_process_flow = gr.TextArea(\n",
    "                        label=\"‚ö° Chat Process Flow\",\n",
    "                        placeholder=\"Step-by-step chat process flow will be shown here...\",\n",
    "                        lines=5,\n",
    "                        max_lines=10,\n",
    "                        interactive=False\n",
    "                    )\n",
    "\n",
    "        # Update functions\n",
    "        def update_output(output):\n",
    "            output_state.value += f\"\\n{output}\"\n",
    "            return output_state.value\n",
    "\n",
    "        def update_verbose(verbose):\n",
    "            verbose_state.value += f\"\\n{verbose}\"\n",
    "            return verbose_state.value\n",
    "\n",
    "        def update_process_flow(flow):\n",
    "            process_flow_state.value += f\"\\n{flow}\"\n",
    "            return process_flow_state.value\n",
    "\n",
    "        def update_agent_progress(progress):\n",
    "            return progress\n",
    "\n",
    "        # Register callbacks\n",
    "        output_manager.register_callback(lambda x: gr.update(value=update_output(x)))\n",
    "        output_manager.register_agent_progress_callback(lambda x: gr.update(value=x))\n",
    "        output_manager.register_verbose_callback(lambda x: gr.update(value=update_verbose(x)))\n",
    "        output_manager.register_process_flow_callback(lambda x: gr.update(value=update_process_flow(x)))\n",
    "\n",
    "        # Analysis workflow\n",
    "        def analyze_document(api_key, pdf_file):\n",
    "            try:\n",
    "                # Reset states\n",
    "                output_state.value = \"\"\n",
    "                verbose_state.value = \"\"\n",
    "                process_flow_state.value = \"\"\n",
    "                \n",
    "                document_text = extract_text_from_pdf(pdf_file)\n",
    "                analyzer = DocumentAnalyzerCrew(\n",
    "                    document_text=document_text,\n",
    "                    reference_data={},  # Add your reference data here\n",
    "                    api_key=api_key,\n",
    "                    output_manager=output_manager\n",
    "                )\n",
    "                \n",
    "                extraction, comparison, report = analyzer.analyze_document()\n",
    "                document_state.value = report\n",
    "                \n",
    "                return (\n",
    "                    extraction,\n",
    "                    comparison,\n",
    "                    report,\n",
    "                    analyzer.memory_tracker.get_memory_summary(),\n",
    "                    verbose_state.value,\n",
    "                    process_flow_state.value,\n",
    "                    gr.update(value=\"Analysis complete!\")\n",
    "                )\n",
    "            except Exception as e:\n",
    "                error_msg = f\"Analysis Error: {str(e)}\\n{traceback.format_exc()}\"\n",
    "                return error_msg, error_msg, error_msg, error_msg, error_msg, error_msg, error_msg\n",
    "\n",
    "        # Chat workflow\n",
    "        def chat_with_document(api_key, message):\n",
    "            try:\n",
    "                if not document_state.value:\n",
    "                    return \"Please analyze a document first.\", \"\", \"\", \"No document analyzed yet.\"\n",
    "                \n",
    "                # Reset states for chat\n",
    "                process_flow_state.value = \"\"\n",
    "                \n",
    "                chat_crew = DocumentChatCrew(\n",
    "                    document_report=document_state.value,\n",
    "                    api_key=api_key,\n",
    "                    output_manager=output_manager\n",
    "                )\n",
    "                \n",
    "                response, memory = chat_crew.chat_with_document(message)\n",
    "                return response, memory, process_flow_state.value, \"Chat processing complete!\"\n",
    "            except Exception as e:\n",
    "                error_msg = f\"Chat Error: {str(e)}\"\n",
    "                return error_msg, error_msg, error_msg, error_msg\n",
    "\n",
    "        # Event handlers\n",
    "        analyze_btn.click(\n",
    "            fn=analyze_document,\n",
    "            inputs=[api_key, pdf_file],\n",
    "            outputs=[\n",
    "                extraction_status,\n",
    "                comparison_status,\n",
    "                report_status,\n",
    "                memory_output,\n",
    "                verbose_output,\n",
    "                process_flow,\n",
    "                agent_progress\n",
    "            ],\n",
    "            show_progress=True\n",
    "        )\n",
    "\n",
    "        chat_btn.click(\n",
    "            fn=chat_with_document,\n",
    "            inputs=[api_key, chat_message],\n",
    "            outputs=[\n",
    "                chat_response,\n",
    "                chat_memory,\n",
    "                chat_process_flow,\n",
    "                chat_agent_progress\n",
    "            ],\n",
    "            show_progress=True\n",
    "        )\n",
    "\n",
    "    return demo\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo = launch_gradio_interface()\n",
    "    demo.queue()\n",
    "    demo.launch(share=False, debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
