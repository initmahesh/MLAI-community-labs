# Lab 1.3: Supervised Fine-Tuning (SFT) with Microsoft Phi-1.5

## **Objective**

In this lab, we will perform **Supervised Fine-Tuning (SFT)** on the **Microsoft Phi-1.5** Large Language Model (LLM).

---

## **The Scenario**

Pre-trained models like Phi-1.5 have broad general knowledge but lack **domain-specific details**, especially for legal or contractual content.

To demonstrate this limitation, we will fine-tune the model on a **Kaseya Master Agreement (MSA)** PDF/TXT file.  

This will teach the model to recall **specific contractual terms** such as limitation periods, payment terms, automatic renewals, and termination clauses that are **unique to this contract**.

---

## **Learning Outcomes**

By the end of this lab, you will be able to:

- Understand the concept and importance of Supervised Fine-Tuning (SFT)
- Fine-tune the Microsoft Phi-1.5 model on domain-specific data
- Prepare legal/contractual documents for fine-tuning
- Evaluate the model's ability to recall specific contractual terms
- Compare the performance of the base model vs. the fine-tuned model

---
