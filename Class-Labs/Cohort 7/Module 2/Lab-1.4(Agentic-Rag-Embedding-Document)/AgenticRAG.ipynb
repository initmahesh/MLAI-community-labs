{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJdEc5U1fZzL"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WADfrUNwfjwB"
      },
      "source": [
        "# **Understanding Agentic RAG: Building Intelligent Document Assistants with ChromaDB(Vectore DB) & LangChain(Framework)**\n",
        "\n",
        "### **What You'll Achieve** üéØ\n",
        "\n",
        "By the end of this lab, you'll gain a deep understanding of **Agentic RAG (Retrieval-Augmented Generation)** and how it revolutionizes the way we interact with documents. Here's what you'll learn:\n",
        "\n",
        "---\n",
        "\n",
        "#### **1. Storing Documents Intelligently Using Vector Embeddings** üóÇÔ∏è\n",
        "- **What**: Learn how to convert documents into numerical representations (vector embeddings) that capture their meaning.\n",
        "- **How**: Use **ChromaDB**, a vector database, to store and organize these embeddings efficiently.\n",
        "- **Why**: This allows the system to understand and retrieve information based on semantic meaning, not just keywords.\n",
        "\n",
        "---\n",
        "\n",
        "#### **2. Retrieving Information with Semantic Understanding** üîç\n",
        "- **What**: Discover how to fetch relevant information from a large document collection using semantic search.\n",
        "- **How**: Leverage **LangChain** to query ChromaDB and retrieve the most contextually relevant chunks.\n",
        "- **Why**: This ensures that the system understands the intent behind your questions, not just the literal words.\n",
        "\n",
        "---\n",
        "\n",
        "#### **3. Generating Context-Aware Answers Using Agentic Decision-Making** ü§ñ\n",
        "- **What**: Explore how **Agentic RAG** makes smart decisions about how to answer questions.\n",
        "- **How**: Implement a decision-making agent that evaluates the confidence of retrieved information and chooses the best response strategy.\n",
        "- **Why**: This allows the system to provide accurate and contextually appropriate answers, even when the information is incomplete or ambiguous.\n",
        "\n",
        "---\n",
        "\n",
        "#### **4. Optimizing Responses Through Knowledge Graph Enhancements** üß†\n",
        "- **What**: Learn how to enhance answers by connecting related concepts using a knowledge graph.\n",
        "- **How**: Build a knowledge graph that maps terms and relationships (e.g., \"Master Agreement\" ‚Üí \"Contract\") to improve understanding.\n",
        "- **Why**: This enables the system to provide more comprehensive and insightful answers by leveraging contextual connections.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### **Let's Get Started!** üöÄ\n",
        "Ready to dive in? Follow the steps in the lab to see how these concepts come to life in code. By the end, you'll not only understand **Agentic RAG** but also know how to implement it in real-world applications."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "p1YBrA6HRnoG",
        "outputId": "4c9a0520-bc74-4d50-b5c0-89a6ebe16dbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: langchain 1.0.5\n",
            "Uninstalling langchain-1.0.5:\n",
            "  Successfully uninstalled langchain-1.0.5\n",
            "Found existing installation: langchain-community 0.4.1\n",
            "Uninstalling langchain-community-0.4.1:\n",
            "  Successfully uninstalled langchain-community-0.4.1\n",
            "Found existing installation: langchain-core 1.0.4\n",
            "Uninstalling langchain-core-1.0.4:\n",
            "  Successfully uninstalled langchain-core-1.0.4\n",
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.12/dist-packages (1.3.4)\n",
            "Collecting langchain\n",
            "  Using cached langchain-1.0.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: pypdf2 in /usr/local/lib/python3.12/dist-packages (3.0.1)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.2)\n",
            "Requirement already satisfied: pyboxen in /usr/local/lib/python3.12/dist-packages (1.3.0)\n",
            "Collecting langchain-community\n",
            "  Using cached langchain_community-0.4.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: langchain-text-splitters in /usr/local/lib/python3.12/dist-packages (1.0.0)\n",
            "Collecting langchain_experimental\n",
            "  Downloading langchain_experimental-0.4.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.3.0)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.12/dist-packages (from chromadb) (2.11.10)\n",
            "Requirement already satisfied: pybase64>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.4.2)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.38.0)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.12/dist-packages (from chromadb) (2.0.2)\n",
            "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (5.4.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.15.0)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.23.2)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.38.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.38.0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.38.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.22.1)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.76.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (5.0.0)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.20.0)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (34.1.0)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from chromadb) (8.5.0)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (6.0.3)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (5.2.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.12/dist-packages (from chromadb) (3.11.4)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.25.1)\n",
            "Collecting langchain-core<2.0.0,>=1.0.4 (from langchain)\n",
            "  Using cached langchain_core-1.0.4-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.0.3)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.57.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.8.0+cu126)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.36.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (1.0.0)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.44)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.32.5 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.32.5)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.13.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.12.0)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.42)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb) (25.0)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.28.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: urllib3<2.4.0,>=1.24.2 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.3.0)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (0.10)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.4->langchain) (1.33)\n",
            "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.0.1)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.2)\n",
            "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.2.9)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.25.0)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.9.23)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.3)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.72.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.38.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.38.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.38.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.38.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.59b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.59b0)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (0.4.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.4.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.2.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (8.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.7.1)\n",
            "Requirement already satisfied: uvloop>=0.15.1 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.22.1)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.1)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.4->langchain) (3.0.0)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.12.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.12/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb) (3.3.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
            "Using cached langchain-1.0.5-py3-none-any.whl (93 kB)\n",
            "Using cached langchain_community-0.4.1-py3-none-any.whl (2.5 MB)\n",
            "Downloading langchain_experimental-0.4.0-py3-none-any.whl (209 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m209.6/209.6 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached langchain_core-1.0.4-py3-none-any.whl (471 kB)\n",
            "Installing collected packages: langchain-core, langchain-community, langchain_experimental, langchain\n",
            "Successfully installed langchain-1.0.5 langchain-community-0.4.1 langchain-core-1.0.4 langchain_experimental-0.4.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "langchain",
                  "langchain_community",
                  "langchain_core"
                ]
              },
              "id": "182b0a2f8be048578a11ed7a65929f89"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Step 1: Install required libraries\n",
        "! pip uninstall -y langchain langchain-community langchain-core || true\n",
        "! pip install -U chromadb langchain pypdf2 sentence-transformers pyboxen langchain-community langchain-text-splitters langchain_experimental"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mURYH1rugGdk"
      },
      "source": [
        "### üåê **About LangChain (In Simple Terms)**\n",
        "LangChain is a framework that helps developers **connect AI models with external data sources** like databases or APIs. In this project, we use LangChain to:\n",
        "- Embed text for efficient search.\n",
        "- Retrieve relevant information from the database.\n",
        "- Generate answers using OpenAI‚Äôs model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "WbLlwKiMmAQE"
      },
      "outputs": [],
      "source": [
        "# Step 1.1 Intsall this package as well\n",
        "#! pip install -U langchain-community"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNfSJPCdnM3y"
      },
      "source": [
        "# Step 3: Setting Up the Lab üß™\n",
        "\n",
        "---\n",
        "## Import necessary modules\n",
        "Before we start, we need to install the necessary tools. These packages are like the ingredients for our recipe ‚Äì without them, the lab won't work!\n",
        "\n",
        "# üìå Explanation of Imported Modules  \n",
        "\n",
        "## üîπ UI Components  \n",
        "- **`ipywidgets`** ‚Üí Provides interactive widgets like buttons, text boxes, and dropdowns.  \n",
        "- **`IPython.display`** ‚Üí Used to display widgets, clear output, and update UI dynamically.  \n",
        "\n",
        "## üîπ Data Processing & Utility  \n",
        "- **`random`** ‚Üí Generates random numbers, useful for testing and sampling.  \n",
        "- **`typing (List, Dict)`** ‚Üí Provides type hints for better code readability and debugging.  \n",
        "- **`io.BytesIO`** ‚Üí Handles in-memory file operations without saving to disk.  \n",
        "- **`os`** ‚Üí Interacts with the operating system (e.g., file paths, environment variables).  \n",
        "\n",
        "## üîπ LangChain Components  \n",
        "- **`langchain.vectorstores.Chroma`** ‚Üí Stores and retrieves document embeddings efficiently.  \n",
        "- **`langchain.embeddings.HuggingFaceEmbeddings`** ‚Üí Uses Hugging Face models for text embeddings.  \n",
        "- **`langchain.text_splitter.RecursiveCharacterTextSplitter`** ‚Üí Splits text into manageable chunks for processing.  \n",
        "- **`langchain.llms.OpenAI`** ‚Üí Connects to OpenAI‚Äôs LLM for generating responses.  \n",
        "- **`langchain.agents.initialize_agent`** ‚Üí Creates an AI agent with tools for querying documents.  \n",
        "- **`langchain.tools.Tool`** ‚Üí Defines custom tools for AI agents.  \n",
        "- **`langchain.tools.StructuredTool`** ‚Üí Provides structured tools for better AI responses.  \n",
        "- **`langchain.prompts.ChatPromptTemplate`** ‚Üí Creates structured prompts for AI interactions.  \n",
        "- **`langchain.schema.runnable.RunnablePassthrough`** ‚Üí Allows passing data through AI models without modification.  \n",
        "\n",
        "## üîπ PDF Handling  \n",
        "- **`PyPDF2.PdfReader`** ‚Üí Reads and extracts text from PDF documents.  \n",
        "\n",
        "## üîπ Database & Storage  \n",
        "- **`chromadb`** ‚Üí A fast and scalable vector database for storing and retrieving embeddings.  \n",
        "\n",
        "## üîπ UI Styling  \n",
        "- **`pyboxen.boxen`** ‚Üí Formats text in visually appealing boxed outputs.  \n",
        "\n",
        "## üîπ Data Validation  \n",
        "- **`pydantic.BaseModel, Field`** ‚Üí Ensures structured and validated data inputs.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xt7L9rR0UrbR"
      },
      "outputs": [],
      "source": [
        "# Step 2: Import necessary modules\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "import random\n",
        "from typing import List, Dict\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_community.llms import OpenAI\n",
        "# Removed: from langchain_experimental.agents import initialize_agent (deprecated)\n",
        "# Removed: from langchain.agents import Tool (not directly used, only StructuredTool is)\n",
        "from langchain_core.tools import StructuredTool\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from pydantic import BaseModel, Field\n",
        "from PyPDF2 import PdfReader\n",
        "import chromadb\n",
        "from pyboxen import boxen\n",
        "import os\n",
        "from io import BytesIO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xypvDMdbggis"
      },
      "source": [
        "### üìå **Step 3: Initializing Components - Setting Up AI-Powered Document Processing: Embeddings, Vector Storage, and LLM Integration**\n",
        "```python\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "chroma_client = chromadb.PersistentClient(path=\"./chroma_db\")\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"YOUR_API_KEY\"\n",
        "llm = OpenAI(temperature=0)\n",
        "```\n",
        "- **Embeddings:** We use `HuggingFaceEmbeddings` to convert text into numerical format.\n",
        "- **ChromaDB Client:** Creates a database at `./chroma_db` to store text embeddings.\n",
        "- **OpenAI API:** We set the API key to access OpenAI‚Äôs language model.\n",
        "[Generate Your OpenAI API Key](https://youtu.be/CzO_AT9dkC8?si=6HsOpOGLoZH-kz-F)\n",
        "\n",
        "- **LLM Initialization:** We set the temperature to `0` for more deterministic responses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "-P9jwcSyUvdv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a983399-5845-4ffe-f21c-78c0cbe4a2f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2023025514.py:10: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the `langchain-openai package and should be used instead. To use it run `pip install -U `langchain-openai` and import as `from `langchain_openai import OpenAI``.\n",
            "  llm = OpenAI(temperature=0)\n"
          ]
        }
      ],
      "source": [
        "# Step 3: Initialize components\n",
        "# Initialize embedding model\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# Initialize ChromaDB client\n",
        "chroma_client = chromadb.PersistentClient(path=\"./chroma_db\")\n",
        "\n",
        "# Initialize LLM (Replace with your API key)\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"Your API Key\"\n",
        "llm = OpenAI(temperature=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ld1FlCazgsgP"
      },
      "source": [
        "# üìå Step 4: Upload & Process a PDF Document  \n",
        "\n",
        "This step allows users to upload a PDF file, extract its text, split it into smaller chunks, and store it in a vector database for AI processing.  \n",
        "\n",
        "## üîπ How It Works  \n",
        "1. **File Upload Widget**  \n",
        "   - A button appears that lets you upload a **PDF file**.  \n",
        "   - The system only accepts **one file at a time**.  \n",
        "\n",
        "2. **Processing the File**  \n",
        "   - When you click the **\"Process File\"** button:  \n",
        "     - The system checks if a file is uploaded.  \n",
        "     - If no file is found, it shows a message: **\"No file uploaded!\"**  \n",
        "     - If a file is uploaded, the system reads the PDF and extracts its text.  \n",
        "     - The text is split into smaller **chunks** (for efficient processing).  \n",
        "     - Each chunk is assigned a **random confidence score**.  \n",
        "     - The data is stored in **ChromaDB**, a special AI-ready database.  \n",
        "\n",
        "3. **Success Message**  \n",
        "   - If everything works, you‚Äôll see a **green notification box**:  \n",
        "     ```\n",
        "     File processed with confidence scores!\n",
        "     ```  \n",
        "   - This means your file was successfully processed and stored.  \n",
        "\n",
        "## üîπ Steps to Use  \n",
        "‚úÖ **Step 1** ‚Üí Click on **\"Upload Document\"** and select a PDF file.  \n",
        "‚úÖ **Step 2** ‚Üí Click **\"Process File\"** to analyze and store it.  \n",
        "‚úÖ **Step 3** ‚Üí Wait for the **success message** confirming the file is processed.  \n",
        "\n",
        "**‚úÖ NOTE** : [üìÑ **Reference Document You Can Use**](https://drive.google.com/file/d/1WWa_TgI49HIAGFuXTNvMLtkFBU6ZduHq/view?usp=sharing)\n",
        "\n",
        "This setup makes it easy to upload and process PDFs with AI-powered storage. üöÄ  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 152,
          "referenced_widgets": [
            "1deb938c28fa4e799d65c71c5ac13fdc",
            "879ac9eea2644301820817a86190cab5",
            "56a8d1c55c08425cac036ba774e3789f",
            "e74d241ce35b4b68b8ede841fad78a85",
            "74dad460516a4e6e9598a6e0c3f56792",
            "b182d9317cca4bbc89d05a885136ad1f",
            "81b0c7b942f241bab554a7fa84ee2ab7",
            "ff15a23923544983b0bda7037a565964"
          ]
        },
        "id": "SPaM1w24U1tF",
        "outputId": "1fbae420-9497-437e-a7bf-5609291cf4ea"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "FileUpload(value={}, accept='.pdf', description='Upload')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1deb938c28fa4e799d65c71c5ac13fdc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Button(description='Process File', style=ButtonStyle())"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e74d241ce35b4b68b8ede841fad78a85"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "81b0c7b942f241bab554a7fa84ee2ab7"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Step 4: File upload widget with value storage\n",
        "import random\n",
        "uploader = widgets.FileUpload(accept='.pdf', multiple=False)\n",
        "process_btn = widgets.Button(description=\"Process File\")\n",
        "process_output = widgets.Output()\n",
        "\n",
        "def process_file(b):\n",
        "    with process_output:\n",
        "        clear_output()\n",
        "        if not uploader.value:\n",
        "            print(\"No file uploaded!\")\n",
        "            return\n",
        "\n",
        "        for filename, file_info in uploader.value.items():\n",
        "            pdf = PdfReader(BytesIO(file_info['content']))\n",
        "            break\n",
        "\n",
        "        text = \"\\n\".join([page.extract_text() for page in pdf.pages])\n",
        "        text_splitter = RecursiveCharacterTextSplitter(\n",
        "            chunk_size=1000, chunk_overlap=100\n",
        "        )\n",
        "        chunks = text_splitter.split_text(text)\n",
        "        metadatas = [{\"value\": random.uniform(0, 1)} for _ in chunks]\n",
        "\n",
        "        Chroma.from_texts(\n",
        "            chunks, embeddings,\n",
        "            client=chroma_client,\n",
        "            collection_name=\"doc_collection\",\n",
        "            metadatas=metadatas\n",
        "        )\n",
        "        print(boxen(\"File processed with confidence scores!\", title=\"Success\", color=\"green\"))\n",
        "\n",
        "display(uploader, process_btn, process_output)\n",
        "process_btn.on_click(process_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsnCbBlhg-sv"
      },
      "source": [
        "# üìù Step 5: Enhanced Query Processing with an Agent  \n",
        "\n",
        "This step enhances **query processing** by implementing an **AI agent** that decides how to answer user queries based on **confidence scores**. It retrieves relevant document chunks and determines whether the response should be **directly generated** or **refined using a knowledge graph** for better accuracy.  \n",
        "\n",
        "---\n",
        "## üîπ Overview of the Query Processing Flow  \n",
        "\n",
        "### 1Ô∏è‚É£ **User Query Retrieval**  \n",
        "- The user submits a **query**.\n",
        "- The system **retrieves relevant document chunks** using ChromaDB.\n",
        "- Each retrieved chunk has an **associated confidence score**.\n",
        "\n",
        "### 2Ô∏è‚É£ **Confidence Score Evaluation**  \n",
        "- If the confidence score is **high (‚â• 0.5)** ‚Üí Use a **direct answer** approach.\n",
        "- If the confidence score is **low (< 0.3)** ‚Üí Use a **knowledge-enhanced answer**.\n",
        "\n",
        "### 3Ô∏è‚É£ **Knowledge Graph Enhancement** (for low-confidence cases)  \n",
        "- Some terms in the query are mapped to **more meaningful alternatives** using a **knowledge graph**.\n",
        "- The query is **rewritten** with these enhancements.\n",
        "- A new document search is performed using the improved query.\n",
        "\n",
        "### 4Ô∏è‚É£ **Generating the Final Answer**  \n",
        "- The system **chooses the best response strategy** using an autonomous agent.\n",
        "- The **final answer is generated** based on the refined context and confidence evaluation.\n",
        "\n",
        "---\n",
        "\n",
        "## üîç **Understanding Confidence Scores**  \n",
        "\n",
        "A **confidence score** is a measure of **how relevant** a retrieved document chunk is to the user's query.  \n",
        "- **Higher confidence (‚â• 0.5)** ‚Üí The retrieved text is **relevant and reliable**.  \n",
        "- **Lower confidence (< 0.3)** ‚Üí The retrieved text **may not be relevant or sufficient**.  \n",
        "\n",
        "### üìå **How is the Confidence Score Used?**  \n",
        "- If the retrieved document chunk has a **high confidence score**, the system can **directly answer the query**.  \n",
        "- If the retrieved document chunk has a **low confidence score**, the AI **enhances the query** using a **knowledge graph** and **retrieves better chunks**.\n",
        "\n",
        "---\n",
        "\n",
        "## ü§ñ **Role of the AI Agent**  \n",
        "\n",
        "The **AI Agent** acts as a **decision-maker** that chooses the **best answering approach** based on **confidence scores**.  \n",
        "\n",
        "### üîπ **How the Agent Works**\n",
        "1. **User submits a query**.\n",
        "2. **Document chunks are retrieved** from the database.\n",
        "3. **Each chunk has an associated confidence score**.\n",
        "4. The AI agent **analyzes the confidence scores** and chooses:\n",
        "   - ‚úÖ **Direct Answer** ‚Üí If confidence is **high (‚â• 0.5)**.\n",
        "   - üîÑ **Enhanced Answer** ‚Üí If confidence is **low (< 0.3)**, it **rewrites the query** and **retrieves better chunks**.\n",
        "5. The chosen **answering tool is executed**, and the **final response** is provided.  \n",
        "\n",
        "---\n",
        "\n",
        "# What is Knowledge Graph\n",
        "\n",
        "A **Knowledge Graph** is a structured representation of information that connects data points using relationships. It organizes and links concepts, entities, and facts in a way that allows machines (like AI) to understand and reason about the data.\n",
        "\n",
        "## Key Components of a Knowledge Graph\n",
        "1. **Entities (Nodes)** ‚Äì Objects or concepts (e.g., a company, a contract, a product).\n",
        "2. **Relationships (Edges)** ‚Äì Connections between entities (e.g., \"Customer **has** a Master Agreement\").\n",
        "3. **Attributes (Properties)** ‚Äì Details about entities (e.g., \"Contract Start Date: Jan 2024\").\n",
        "\n",
        "## Example of a Simple Knowledge Graph\n",
        "\n",
        "### üìå Entities:\n",
        "- **Customer**: ABC Corp\n",
        "- **Master Agreement**: Contract\n",
        "- **Service Order**: Specific service agreement\n",
        "\n",
        "### üìå Relationships:\n",
        "- `ABC Corp ‚Üí has ‚Üí Master Agreement`\n",
        "- `Master Agreement ‚Üí includes ‚Üí Service Order`\n",
        "\n",
        "## Why Use a Knowledge Graph?\n",
        "- üöÄ Helps AI understand context better\n",
        "- üîç Improves search and query responses\n",
        "- üîó Connects scattered information for better decision-making\n",
        "\n",
        "# NOTE\n",
        "# We are using a dummy knowledge graph with respect to three terms:\n",
        "\n",
        "- **Customer**:\n",
        "- **Master Agreement**:\n",
        "- **Service Order**:\n",
        "\n",
        "# If you are using a query different from it, then you have to provide your context to the knowledge graph as well.\n",
        "---\n",
        "\n",
        "# üéØ **Final Outcome**\n",
        "- If the retrieved document is **relevant**, the AI answers immediately.  \n",
        "- If the information is **uncertain**, the AI **optimizes** the search before answering.  \n",
        "- The AI agent makes **independent decisions** for the best response. üöÄ  \n",
        "\n",
        "This **smart decision-making** process makes the AI **more intelligent and reliable** for answering document-based queries. üìñ‚ú®\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZfeLdybzU5VW"
      },
      "outputs": [],
      "source": [
        "# Step 5: Enhanced query processing with autonomous agent\n",
        "class QueryInput(BaseModel):\n",
        "    query: str = Field(description=\"User's original question\")\n",
        "    chunks: List[Dict] = Field(description=\"Retrieved document chunks with confidence scores\")\n",
        "\n",
        "def retrieve_chunks(query: str) -> List[Dict]:\n",
        "    collection = chroma_client.get_collection(\"doc_collection\")\n",
        "    results = collection.query(\n",
        "        query_texts=[query],\n",
        "        n_results=1,\n",
        "        include=['documents', 'metadatas']\n",
        "    )\n",
        "\n",
        "    # Ensure metadata is returned and handle cases where it's missing\n",
        "    documents = results['documents'][0]\n",
        "    metadatas = results.get('metadatas', [[{}] * len(documents)])[0]  # Default to empty dicts if metadata is missing\n",
        "\n",
        "    # Create chunks with actual metadata and confidence scores\n",
        "    chunks = [\n",
        "        {\"text\": doc, \"metadata\": meta}\n",
        "        for doc, meta in zip(documents, metadatas)\n",
        "    ]\n",
        "\n",
        "    return chunks\n",
        "\n",
        "def knowledge_graph(query: str) -> str:\n",
        "    # Enhanced knowledge graph mappings\n",
        "    kg_mappings = {\n",
        "        \"customer\": \"Company Name Referenced in Master Agreement Only\",\n",
        "        \"Master Agreement\": \"Contract\",\n",
        "        \"Service Order\": \"Service Agreement\",\n",
        "        \"name of the Customer\": \"Company Name Referenced in Master Agreement Only\",\n",
        "        # Add case variations or use case-insensitive comparison\n",
        "        \"Name Of the Customer\": \"Company Name Referenced in Master Agreement Only\"\n",
        "    }\n",
        "\n",
        "    # Alternatively, use case-insensitive replacement:\n",
        "    enhanced_query = query\n",
        "    for term, replacement in kg_mappings.items():\n",
        "        pattern = re.compile(re.escape(term), re.IGNORECASE)\n",
        "        enhanced_query = pattern.sub(replacement, enhanced_query)\n",
        "\n",
        "    return enhanced_query\n",
        "\n",
        "def base_answer(input: QueryInput) -> str:\n",
        "    context = \"\\n\\n\".join([chunk[\"text\"] for chunk in input.chunks])\n",
        "    prompt = f\"Answer: {input.query}\\nContext:\\n{context}\"\n",
        "    answer = llm.invoke(prompt)\n",
        "    return f\"Answer: {answer}\"\n",
        "\n",
        "def enhanced_answer(input: QueryInput) -> str:\n",
        "    enhanced_query = knowledge_graph(input.query)\n",
        "    enhanced_chunks = retrieve_chunks(enhanced_query)\n",
        "    context = \"\\n\\n\".join([chunk[\"text\"] for chunk in enhanced_chunks])\n",
        "    prompt = f\"Answer: {enhanced_query}\\nContext:\\n{context}\"\n",
        "    answer = llm.invoke(prompt)\n",
        "    return f\"Optimized Answer: {answer}\"\n",
        "\n",
        "\n",
        "# Define Tools\n",
        "tools = [\n",
        "    StructuredTool.from_function(\n",
        "        name=\"DirectAnswer\",\n",
        "        description=\"Use this when the retrieved chunks have high confidence scores (>= 0.5) and sufficient context to directly answer the query.\",\n",
        "        func=base_answer\n",
        "    ),\n",
        "    StructuredTool.from_function(\n",
        "        name=\"EnhancedAnswer\",\n",
        "        description=\"Use this when the retrieved chunks have low confidence scores (< 0.3) or insufficient context, and the query needs to be enhanced using a knowledge graph.\",\n",
        "        func=enhanced_answer\n",
        "    )\n",
        "]\n",
        "\n",
        "# Initialize the agent with a custom prompt\n",
        "agent_prompt = \"\"\"You are an intelligent assistant that decides how to answer user queries based on the context and confidence scores of retrieved document chunks.\n",
        "\n",
        "Here are the tools available to you:\n",
        "1. DirectAnswer: Use this when the retrieved chunks have high confidence scores (>= 0.5) and sufficient context to directly answer the query.\n",
        "2. EnhancedAnswer: Use this when the retrieved chunks have low confidence scores (< 0.3) or insufficient context, and the query needs to be enhanced using a knowledge graph.\n",
        "\n",
        "Your task is to analyze the query, retrieved chunks, and their confidence scores, and decide which tool to use. Provide a reason for your decision.\n",
        "\n",
        "Query: {query}\n",
        "Retrieved Chunks: {chunks}\n",
        "\n",
        "Decision: Which tool should be used? Respond in the following format:\n",
        "Tool: [DirectAnswer or EnhancedAnswer]\n",
        "Reason: [Your reasoning]\"\"\"\n",
        "\n",
        "# Removed the `initialize_agent` call as it's deprecated and not used in `handle_query`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_aaAiW68hiqJ"
      },
      "source": [
        "# üìù **Step 6: Query Interface with Autonomous Decision-Making**  \n",
        "\n",
        "This step introduces an **interactive query interface** that allows users to input their questions.  \n",
        "The AI agent **analyzes** the query, **retrieves relevant document chunks**, and **decides how to answer**  \n",
        "based on confidence scores. The decision-making is fully **autonomous**, ensuring **optimized responses**.\n",
        "\n",
        "---\n",
        "\n",
        "## üéØ **How the Query Interface Works**  \n",
        "\n",
        "### üîπ **User Input & Query Submission**  \n",
        "- You have to enters their query in the input field (`query_input`).\n",
        "- Clicking the \"Submit\" button (`submit_btn`) triggers the `handle_query` function.\n",
        "\n",
        "# üîç Step-by-Step Query Processing Flow\n",
        "**1Ô∏è‚É£ Step 1: Query Asked**\n",
        "- The user inputs a query.\n",
        "- The query is displayed in a notification box for reference.\n",
        "\n",
        "**2Ô∏è‚É£ Step 2: Retrieve Relevant Chunks**\n",
        "- The query is searched in the document database (ChromaDB).\n",
        "- The most relevant text chunks are retrieved, along with their confidence scores.\n",
        "- Retrieved chunks are displayed in a green notification box.\n",
        "\n",
        "**3Ô∏è‚É£ Step 3: Generate an Initial (Poor) Answer**\n",
        "- The system tries to generate an answer from the retrieved chunks.\n",
        "- This is an unoptimized response that might be incorrect due to low confidence scores.\n",
        "- The poor answer is displayed in a red notification box.\n",
        "\n",
        "**4Ô∏è‚É£ Step 4: AI Agent Decision**\n",
        "- The AI agent analyzes the retrieved chunks and confidence scores.\n",
        "- It decides whether to:\n",
        "  - Use the DirectAnswer tool (if confidence scores are high).\n",
        "  - Use the EnhancedAnswer tool (if confidence scores are low).\n",
        "- The agent's decision is displayed in a magenta notification box.\n",
        "\n",
        "**5Ô∏è‚É£ Step 5: Generate the Final Answer**\n",
        "\n",
        "‚úÖ If the agent chooses \"DirectAnswer\"\n",
        "- The initial answer is used without modifications.\n",
        "\n",
        "‚úÖ If the agent chooses \"EnhancedAnswer\"\n",
        "- The query is refined by agnet using a Knowledge Graph.\n",
        "-A new set of relevant document chunks is retrieved.\n",
        "- A more optimized answer is generated.\n",
        "\n",
        "# üèÅ How to Use the Query Interface?\n",
        "1Ô∏è‚É£ Enter your question in the input box.\n",
        "\n",
        "```text\n",
        "What is the name of the Customer ?\n",
        "```\n",
        "\n",
        "2Ô∏è‚É£ Click \"Submit\" to process the query.\n",
        "\n",
        "3Ô∏è‚É£ The system will retrieve relevant document chunks and evaluate confidence scores.\n",
        "\n",
        "4Ô∏è‚É£ The AI agent decides whether to give a direct answer or enhance the query using a Knowledge Graph.\n",
        "\n",
        "5Ô∏è‚É£ The final answer is displayed, either as a Direct Answer or an Optimized Answer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "6f4aceca8fed4dc79e0f1fb5384ebd86",
            "9b0f3ee48a6243d8996a13c0336f1bef",
            "6de0e1c04eef4414a45be92ee97911fe",
            "baa668fc185e448588728e005171ac44",
            "29f7723b36c04cc09c151a7a872eb10c",
            "0a0da3523a91437ab4c2dd91235ad923",
            "1b1c12bbc6194dd1adbc5dca17c75e27",
            "0ee6e41eb38a460da8233684418c73c1"
          ]
        },
        "id": "JORFQMonVaFK",
        "outputId": "6b04b187-05cb-48c4-c9d1-db576d221b49"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Text(value='', placeholder='Enter your query')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6f4aceca8fed4dc79e0f1fb5384ebd86"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Button(description='Submit', style=ButtonStyle())"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "baa668fc185e448588728e005171ac44"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1b1c12bbc6194dd1adbc5dca17c75e27"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import re\n",
        "# Step 6: Query interface with autonomous decision-making\n",
        "query_input = widgets.Text(placeholder=\"Enter your query\")\n",
        "submit_btn = widgets.Button(description=\"Submit\")\n",
        "query_output = widgets.Output()\n",
        "\n",
        "def handle_query(b):\n",
        "    with query_output:\n",
        "        clear_output()\n",
        "        query = query_input.value\n",
        "\n",
        "        # Step 1: Query Asked\n",
        "        print(boxen(f\"QUERY ASKED:\\n{query}\", title=\"Step 1: Query Asked\", color=\"blue\"))\n",
        "\n",
        "        # Step 2: Retrieve Chunks\n",
        "        chunks = retrieve_chunks(query)\n",
        "        print(boxen(\n",
        "            f\"RETRIEVED CHUNKS:\\n\" +\n",
        "            \"\\n\".join([f\"Chunk {i+1}: {chunk['text']}\"\n",
        "                       for i, chunk in enumerate(chunks)]),\n",
        "            title=\"Step 2: Retrieved Chunks\", color=\"green\"\n",
        "        ))\n",
        "\n",
        "        # Step 3: Generate and Display Poor Answer\n",
        "        poor_answer = base_answer(QueryInput(query=query, chunks=chunks))\n",
        "        print(boxen(\n",
        "            f\"POOR ANSWER (Initial Attempt):\\n{poor_answer}\",\n",
        "            title=\"Step 3: Poor Answer\", color=\"red\"\n",
        "        ))\n",
        "\n",
        "        # Step 4: Let the Agent Decide Which Tool to Use\n",
        "        decision_output = llm.invoke(agent_prompt.format(query=query, chunks=chunks))\n",
        "        decision = decision_output.split(\"Tool: \")[1].split(\"\\n\")[0].strip()  # Extract tool\n",
        "        reason = decision_output.split(\"Reason: \")[1].strip()  # Extract reason\n",
        "        print(boxen(\n",
        "            f\"AGENT DECISION:\\nTool: {decision}\\nReason: {reason}\",\n",
        "            title=\"Step 4: Agent Decision\", color=\"magenta\"\n",
        "        ))\n",
        "\n",
        "        # Step 5: Execute the Chosen Tool\n",
        "        if \"DirectAnswer\" in decision:\n",
        "            response = base_answer(QueryInput(query=query, chunks=chunks))\n",
        "            print(boxen(\n",
        "                f\"DIRECT ANSWER:\\n{response}\",\n",
        "                title=\"Step 5: Direct Answer\", color=\"yellow\"\n",
        "            ))\n",
        "        elif \"EnhancedAnswer\" in decision:\n",
        "            print(boxen(\n",
        "                \"USING KNOWLEDGE GRAPH TO ENHANCE QUERY...\",\n",
        "                title=\"Step 5: Knowledge Graph Enhancement\", color=\"cyan\"\n",
        "            ))\n",
        "            enhanced_query = knowledge_graph(query)\n",
        "            print(boxen(\n",
        "                f\"ENHANCED QUERY:\\n{enhanced_query}\",\n",
        "                title=\"Step 5: Enhanced Query\", color=\"cyan\"\n",
        "            ))\n",
        "            enhanced_chunks = retrieve_chunks(enhanced_query)\n",
        "            response = enhanced_answer(QueryInput(query=enhanced_query, chunks=enhanced_chunks))\n",
        "            print(boxen(\n",
        "                f\"FINAL OPTIMIZED ANSWER:\\n{response}\",\n",
        "                title=\"Step 5: Final Optimized Answer\", color=\"green\"\n",
        "            ))\n",
        "        else:\n",
        "            print(boxen(\n",
        "                \"Unable to determine the appropriate tool. Using default answer.\",\n",
        "                title=\"Step 5: Default Answer\", color=\"red\"\n",
        "            ))\n",
        "\n",
        "\n",
        "display(query_input, submit_btn, query_output)\n",
        "submit_btn.on_click(handle_query)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1deb938c28fa4e799d65c71c5ac13fdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FileUploadModel",
          "model_module_version": "1.5.0",
          "state": {
            "_counter": 1,
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FileUploadModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "FileUploadView",
            "accept": ".pdf",
            "button_style": "",
            "data": [
              null
            ],
            "description": "Upload",
            "description_tooltip": null,
            "disabled": false,
            "error": "",
            "icon": "upload",
            "layout": "IPY_MODEL_879ac9eea2644301820817a86190cab5",
            "metadata": [
              {
                "name": "Reference MSA Document from the Basic Prompt Engineering Lab (4).pdf",
                "type": "application/pdf",
                "size": 351118,
                "lastModified": 1762372681311
              }
            ],
            "multiple": false,
            "style": "IPY_MODEL_56a8d1c55c08425cac036ba774e3789f"
          }
        },
        "879ac9eea2644301820817a86190cab5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56a8d1c55c08425cac036ba774e3789f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "e74d241ce35b4b68b8ede841fad78a85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Process File",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_74dad460516a4e6e9598a6e0c3f56792",
            "style": "IPY_MODEL_b182d9317cca4bbc89d05a885136ad1f",
            "tooltip": ""
          }
        },
        "74dad460516a4e6e9598a6e0c3f56792": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b182d9317cca4bbc89d05a885136ad1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "81b0c7b942f241bab554a7fa84ee2ab7": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_ff15a23923544983b0bda7037a565964",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
                },
                "metadata": {}
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "\u001b[32m‚ï≠‚îÄ\u001b[0m\u001b[32m Success \u001b[0m\u001b[32m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m\u001b[32m‚îÄ‚ïÆ\u001b[0m                                                                           \n",
                  "\u001b[32m‚îÇ\u001b[0mFile processed with confidence scores!\u001b[32m‚îÇ\u001b[0m                                                                           \n",
                  "\u001b[32m‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ\u001b[0m                                                                           \n",
                  "\n"
                ]
              }
            ]
          }
        },
        "ff15a23923544983b0bda7037a565964": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f4aceca8fed4dc79e0f1fb5384ebd86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_9b0f3ee48a6243d8996a13c0336f1bef",
            "placeholder": "Enter your query",
            "style": "IPY_MODEL_6de0e1c04eef4414a45be92ee97911fe",
            "value": "what is the customer name?"
          }
        },
        "9b0f3ee48a6243d8996a13c0336f1bef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6de0e1c04eef4414a45be92ee97911fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "baa668fc185e448588728e005171ac44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Submit",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_29f7723b36c04cc09c151a7a872eb10c",
            "style": "IPY_MODEL_0a0da3523a91437ab4c2dd91235ad923",
            "tooltip": ""
          }
        },
        "29f7723b36c04cc09c151a7a872eb10c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a0da3523a91437ab4c2dd91235ad923": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "1b1c12bbc6194dd1adbc5dca17c75e27": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_0ee6e41eb38a460da8233684418c73c1",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
                },
                "metadata": {}
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "\u001b[34m‚ï≠‚îÄ\u001b[0m\u001b[34m Step 1: Query Asked \u001b[0m\u001b[34m‚îÄ‚îÄ‚îÄ\u001b[0m\u001b[34m‚îÄ‚ïÆ\u001b[0m                                                                                       \n",
                  "\u001b[34m‚îÇ\u001b[0mQUERY ASKED:              \u001b[34m‚îÇ\u001b[0m                                                                                       \n",
                  "\u001b[34m‚îÇ\u001b[0mwhat is the customer name?\u001b[34m‚îÇ\u001b[0m                                                                                       \n",
                  "\u001b[34m‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ\u001b[0m                                                                                       \n",
                  "\n"
                ]
              },
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
                },
                "metadata": {}
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "\u001b[32m‚ï≠‚îÄ\u001b[0m\u001b[32m Step 2: Retrieved Chunks \u001b[0m\u001b[32m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m\u001b[32m‚îÄ‚ïÆ\u001b[0m\n",
                  "\u001b[32m‚îÇ\u001b[0mRETRIEVED CHUNKS:                                                                                                \u001b[32m‚îÇ\u001b[0m\n",
                  "\u001b[32m‚îÇ\u001b[0mChunk 1: monitored in connection with any Product. End User may also be referred to in certain Product Terms of  \u001b[32m‚îÇ\u001b[0m\n",
                  "\u001b[32m‚îÇ\u001b[0mUse, Portals or Speci\u0000cations as                                                                                  \u001b[32m‚îÇ\u001b[0m\n",
                  "\u001b[32m‚îÇ\u001b[0mCustomer, Content Owner, Network Owner or Client.                                                                \u001b[32m‚îÇ\u001b[0m\n",
                  "\u001b[32m‚îÇ\u001b[0m‚ÄúEnd User Terms‚Äù means terms related to certain Products and the substance of which must be included in a valid, \u001b[32m‚îÇ\u001b[0m\n",
                  "\u001b[32m‚îÇ\u001b[0menforceable contract                                                                                             \u001b[32m‚îÇ\u001b[0m\n",
                  "\u001b[32m‚îÇ\u001b[0mbetween a you and an End User.¬† End User Terms are typically identi\u0000ed in the applicable Product Terms of Use.    \u001b[32m‚îÇ\u001b[0m\n",
                  "\u001b[32m‚îÇ\u001b[0m‚ÄúFees‚Äù means subscription fees, hardware pricing, and other such fees and pricing set forth in this Agreement, an\u001b[32m‚îÇ\u001b[0m\n",
                  "\u001b[32m‚îÇ\u001b[0mOrder (including a SOW),                                                                                         \u001b[32m‚îÇ\u001b[0m\n",
                  "\u001b[32m‚îÇ\u001b[0mor other such documentation for the purchase and license of Products.                                            \u001b[32m‚îÇ\u001b[0m\n",
                  "\u001b[32m‚îÇ\u001b[0m‚ÄúKaseya Marks‚Äù means Kaseya‚Äôs trademarks, service marks, trade names, brands, domain names, URLs, logos and other\u001b[32m‚îÇ\u001b[0m\n",
                  "\u001b[32m‚îÇ\u001b[0mproprietary indicia                                                                                              \u001b[32m‚îÇ\u001b[0m\n",
                  "\u001b[32m‚îÇ\u001b[0m(whether or not registered).                                                                                     \u001b[32m‚îÇ\u001b[0m\n",
                  "\u001b[32m‚îÇ\u001b[0m‚ÄúKaseya Services‚Äù means all services provided by or on behalf of Kaseya, including without limitation, the       \u001b[32m‚îÇ\u001b[0m\n",
                  "\u001b[32m‚îÇ\u001b[0mbusiness continuity, backup,                                                                                     \u001b[32m‚îÇ\u001b[0m\n",
                  "\u001b[32m‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ\u001b[0m\n",
                  "\n"
                ]
              },
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
                },
                "metadata": {}
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "\u001b[31m‚ï≠‚îÄ\u001b[0m\u001b[31m Step 3: Poor Answer \u001b[0m\u001b[31m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m\u001b[31m‚îÄ‚ïÆ\u001b[0m\n",
                  "\u001b[31m‚îÇ\u001b[0mPOOR ANSWER (Initial Attempt):                                                                                   \u001b[31m‚îÇ\u001b[0m\n",
                  "\u001b[31m‚îÇ\u001b[0mAnswer:  disaster                                                                                                \u001b[31m‚îÇ\u001b[0m\n",
                  "\u001b[31m‚îÇ\u001b[0mrecovery, and other services provided by Kaseya as part of the Products.                                         \u001b[31m‚îÇ\u001b[0m\n",
                  "\u001b[31m‚îÇ\u001b[0m                                                                                                                 \u001b[31m‚îÇ\u001b[0m\n",
                  "\u001b[31m‚îÇ\u001b[0m                                                                                                                 \u001b[31m‚îÇ\u001b[0m\n",
                  "\u001b[31m‚îÇ\u001b[0mThe customer name is the name of the individual or organization who is purchasing and using the Product. It may  \u001b[31m‚îÇ\u001b[0m\n",
                  "\u001b[31m‚îÇ\u001b[0malso be referred to as the End User, Content Owner, Network Owner, or Client. The specific name of the customer  \u001b[31m‚îÇ\u001b[0m\n",
                  "\u001b[31m‚îÇ\u001b[0mwill be identified in the End User Terms and in the applicable Product Terms of Use.                             \u001b[31m‚îÇ\u001b[0m\n",
                  "\u001b[31m‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ\u001b[0m\n",
                  "\n"
                ]
              },
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
                },
                "metadata": {}
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "\u001b[35m‚ï≠‚îÄ\u001b[0m\u001b[35m Step 4: Agent Decision \u001b[0m\u001b[35m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m\u001b[35m‚îÄ‚ïÆ\u001b[0m\n",
                  "\u001b[35m‚îÇ\u001b[0mAGENT DECISION:                                                                                                  \u001b[35m‚îÇ\u001b[0m\n",
                  "\u001b[35m‚îÇ\u001b[0mTool: EnhancedAnswer                                                                                             \u001b[35m‚îÇ\u001b[0m\n",
                  "\u001b[35m‚îÇ\u001b[0mReason: The retrieved chunks have a low confidence score of 0.04159173334418475, indicating that they may not    \u001b[35m‚îÇ\u001b[0m\n",
                  "\u001b[35m‚îÇ\u001b[0mcontain enough relevant information to directly answer the query. Additionally, the context provided in the      \u001b[35m‚îÇ\u001b[0m\n",
                  "\u001b[35m‚îÇ\u001b[0mretrieved chunks is not directly related to the query, as it discusses terms and services related to a product.  \u001b[35m‚îÇ\u001b[0m\n",
                  "\u001b[35m‚îÇ\u001b[0mTherefore, using a knowledge graph to enhance the query and provide more relevant information would be more      \u001b[35m‚îÇ\u001b[0m\n",
                  "\u001b[35m‚îÇ\u001b[0meffective in this scenario.                                                                                      \u001b[35m‚îÇ\u001b[0m\n",
                  "\u001b[35m‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ\u001b[0m\n",
                  "\n"
                ]
              },
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
                },
                "metadata": {}
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "\u001b[36m‚ï≠‚îÄ\u001b[0m\u001b[36m Step 5: Knowledge Graph Enhancement \u001b[0m\u001b[36m‚îÄ‚îÄ\u001b[0m\u001b[36m‚îÄ‚ïÆ\u001b[0m                                                                        \n",
                  "\u001b[36m‚îÇ\u001b[0mUSING KNOWLEDGE GRAPH TO ENHANCE QUERY...\u001b[36m‚îÇ\u001b[0m                                                                        \n",
                  "\u001b[36m‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ\u001b[0m                                                                        \n",
                  "\n"
                ]
              },
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
                },
                "metadata": {}
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "\u001b[36m‚ï≠‚îÄ\u001b[0m\u001b[36m Step 5: Enhanced Query \u001b[0m\u001b[36m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m\u001b[36m‚îÄ‚ïÆ\u001b[0m                                                       \n",
                  "\u001b[36m‚îÇ\u001b[0mENHANCED QUERY:                                           \u001b[36m‚îÇ\u001b[0m                                                       \n",
                  "\u001b[36m‚îÇ\u001b[0mwhat is the Company Name Referenced in Contract Only name?\u001b[36m‚îÇ\u001b[0m                                                       \n",
                  "\u001b[36m‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ\u001b[0m                                                       \n",
                  "\n"
                ]
              },
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
                },
                "metadata": {}
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "\u001b[32m‚ï≠‚îÄ\u001b[0m\u001b[32m Step 5: Final Optimized Answer \u001b[0m\u001b[32m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m\u001b[32m‚îÄ‚ïÆ\u001b[0m\n",
                  "\u001b[32m‚îÇ\u001b[0mFINAL OPTIMIZED ANSWER:                                                                                          \u001b[32m‚îÇ\u001b[0m\n",
                  "\u001b[32m‚îÇ\u001b[0mOptimized Answer:                                                                                                \u001b[32m‚îÇ\u001b[0m\n",
                  "\u001b[32m‚îÇ\u001b[0minformation for the purposes of this Agreement; (ii) been informed of the con\u0000dential nature of the information;  \u001b[32m‚îÇ\u001b[0m\n",
                  "\u001b[32m‚îÇ\u001b[0mand (iii) agreed to                                                                                              \u001b[32m‚îÇ\u001b[0m\n",
                  "\u001b[32m‚îÇ\u001b[0mbe bound by the terms of this Agreement.                                                                         \u001b[32m‚îÇ\u001b[0m\n",
                  "\u001b[32m‚îÇ\u001b[0m                                                                                                                 \u001b[32m‚îÇ\u001b[0m\n",
                  "\u001b[32m‚îÇ\u001b[0mThe company name referenced in this contract is Kaseya.                                                          \u001b[32m‚îÇ\u001b[0m\n",
                  "\u001b[32m‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ\u001b[0m\n",
                  "\n"
                ]
              }
            ]
          }
        },
        "0ee6e41eb38a460da8233684418c73c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}